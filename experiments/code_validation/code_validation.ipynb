{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: need to install psycopg2 from source if using in production environment\n",
    "# https://www.psycopg.org/docs/install.html\n",
    "# %pip install sqlglot sqlvalidator sqlalchemy psycopg2-binary sqlfluff mysql-connector-python pyodbc google-cloud-bigquery\n",
    "# %pip install pyflakes pylint parso flake8 mypy ruff\n",
    "# %pip install docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'python_parsers' from '/mnt/foundation-shared/nina_xu_gretel_ai/navigator-helpers/experiments/code_validation/python_parsers.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import sql_parsers\n",
    "reload(sql_parsers)\n",
    "\n",
    "import python_parsers\n",
    "reload(python_parsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from python_parsers import *\n",
    "from sql_parsers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sql_queries_w_dialect_1000.csv')\n",
    "sql_queries_googlesql = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sql_queries_googlesql_200.csv')\n",
    "sql_queries = pd.concat([sql_queries, sql_queries_googlesql], ignore_index=True)\n",
    "python_typscript_codes = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/python_typescript_codes.csv')\n",
    "python_codes = pd.read_json('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/text_to_python_v1.json')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Give each row a unique db name because otherwise BigQuery struggles with the same db name\n",
    "sql_queries['id_tmp'] = sql_queries.index\n",
    "sql_queries['db_name'] = sql_queries.apply(lambda x: f\"db_{x.id_tmp}\", axis=1)\n",
    "\n",
    "# Basic cleaning. At least BigQuery errors out if there are newlines like 'CREATE\\nTABLE'\n",
    "sql_queries['SQL Query'] = sql_queries['SQL Query'].apply(lambda x: x.replace('\\n', ' '))\n",
    "sql_queries['Context'] = sql_queries['Context'].apply(lambda x: x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Code Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialect\n",
      "SQL Server            230\n",
      "PostgreSQL            220\n",
      "SQLite                209\n",
      "GoogleSQL             209\n",
      "MySQL                 196\n",
      "Oracle SQL             42\n",
      "OracleSQL              42\n",
      "Oracle                 37\n",
      "Oracle SQL Dialect      1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Natural Language Prompt</th>\n",
       "      <th>Context</th>\n",
       "      <th>SQL Query</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Dialect</th>\n",
       "      <th>Complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>745d3e2c-8f57-4a3a-a7a5-d1f225a575de</td>\n",
       "      <td>What is the average performance score by\\ndepartment for the past year?</td>\n",
       "      <td>CREATE TABLE performance_reviews (     review_id\\nSTRING NOT NULL,     employee_id STRING NOT NULL,\\ndepartment STRING NOT NULL,     review_date DATE\\nNOT NULL,     performance_score INTEGER NOT NULL\\n);  CREATE TABLE employees (     employee_id\\nSTRING NOT NULL,     first_name STRING NOT NULL,\\nlast_name STRING NOT NULL,     hire_date DATE NOT\\nNULL,     department STRING NOT NULL );</td>\n",
       "      <td>SELECT department, AVG(performance_score) as\\naverage_score  FROM performance_reviews  WHERE\\nreview_date BETWEEN DATE_SUB(CURRENT_DATE(),\\nINTERVAL 1 YEAR) AND CURRENT_DATE()  GROUP BY\\ndepartment;</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Performance Management</td>\n",
       "      <td>GoogleSQL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID  \\\n",
       "1185  745d3e2c-8f57-4a3a-a7a5-d1f225a575de   \n",
       "\n",
       "                                                      Natural Language Prompt  \\\n",
       "1185  What is the average performance score by\\ndepartment for the past year?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                  Context  \\\n",
       "1185  CREATE TABLE performance_reviews (     review_id\\nSTRING NOT NULL,     employee_id STRING NOT NULL,\\ndepartment STRING NOT NULL,     review_date DATE\\nNOT NULL,     performance_score INTEGER NOT NULL\\n);  CREATE TABLE employees (     employee_id\\nSTRING NOT NULL,     first_name STRING NOT NULL,\\nlast_name STRING NOT NULL,     hire_date DATE NOT\\nNULL,     department STRING NOT NULL );   \n",
       "\n",
       "                                                                                                                                                                                                   SQL Query  \\\n",
       "1185  SELECT department, AVG(performance_score) as\\naverage_score  FROM performance_reviews  WHERE\\nreview_date BETWEEN DATE_SUB(CURRENT_DATE(),\\nINTERVAL 1 YEAR) AND CURRENT_DATE()  GROUP BY\\ndepartment;   \n",
       "\n",
       "               Domain                   Topic    Dialect  Complexity  \n",
       "1185  Human Resources  Performance Management  GoogleSQL           4  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_queries.head(1)\n",
    "print(sql_queries.Dialect.value_counts())\n",
    "\n",
    "sql_queries.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complexity\n",
       "3    689\n",
       "2    447\n",
       "4     35\n",
       "1     15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_queries.Complexity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.17.0.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Have a PostgreSQL database running in a Docker container. In command line, run the following commands:\n",
    "# Grant access to non-root users so that the python client will work\n",
    "> sudo groupadd docker\n",
    "> sudo usermod -aG docker $USER\n",
    "> newgrp docker\n",
    "\n",
    "> docker pull postgres\n",
    "> docker run --name my-postgres \\\n",
    "  -e POSTGRES_USER=myuser \\\n",
    "  -e POSTGRES_PASSWORD=mypassword \\\n",
    "  -e POSTGRES_DB=mydatabase \\\n",
    "  -p 5433:5432 \\\n",
    "  -d postgres\n",
    "\n",
    "\"\"\"\n",
    "client = docker.from_env()\n",
    "\n",
    "# List all running containers\n",
    "containers = client.containers.list(all=False)\n",
    "# Get the postgres container\n",
    "postgres_container = client.containers.get('my-postgres')\n",
    "# Get container's gateway, not that it's not the \"IPAddress\" field\n",
    "postgres_container_gateway = postgres_container.attrs['NetworkSettings']['Gateway']\n",
    "print(postgres_container_gateway)\n",
    "\n",
    "postgres_db_creds = {\n",
    "        \"host\": postgres_container_gateway,\n",
    "        \"port\": 5433, # the default port is 5432, but that was already in use for me\n",
    "        \"user\": \"myuser\",\n",
    "        \"password\": \"mypassword\",\n",
    "        \"dbname\": \"my-postgres\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.17.0.3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Have a MySQL database running in a Docker container. In command line, run the following commands:\n",
    "> docker pull mysql\n",
    "> docker run --name my-mysql \\\n",
    "  -e MYSQL_ROOT_PASSWORD=myrootpassword \\\n",
    "  -d mysql\n",
    "\"\"\"\n",
    "\n",
    "mysql_container = client.containers.get('my-mysql')\n",
    "mysql_container_ip = mysql_container.attrs['NetworkSettings']['IPAddress']\n",
    "print(mysql_container_ip)\n",
    "\n",
    "mysql_db_creds = {\n",
    "    \"host\": mysql_container_ip,\n",
    "    \"port\": 3306, # default port for mysql\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"myrootpassword\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.17.0.4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Have a Microsoft SQL Server database running in a Docker container. In command line, run the following commands:\n",
    "$ docker pull mcr.microsoft.com/mssql/server\n",
    "$ docker run --name my-sqlserver \\\n",
    "  -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=myRoot(!)Password' \\\n",
    "  -p 1433:1433 \\\n",
    "  -d mcr.microsoft.com/mssql/server\n",
    "\n",
    "$ sudo apt install unixodbc-dev\n",
    "\n",
    "Install the SQL Server command-line tool (sqlcmd) inside the container:\n",
    "$ docker exec -it --user root my-sqlserver bash\n",
    "# apt-get update\n",
    "# apt-get install -y mssql-tools unixodbc-dev\n",
    "\"\"\"\n",
    "          \n",
    "sqlserver_container = client.containers.get('my-sqlserver')\n",
    "sqlserver_container_ip = sqlserver_container.attrs['NetworkSettings']['IPAddress']\n",
    "print(sqlserver_container_ip)\n",
    "\n",
    "sqlserver_db_creds = {\n",
    "    \"host\": sqlserver_container_ip,\n",
    "    \"port\": 1433, # default port for sql server,\n",
    "    \"user\": \"sa\",\n",
    "    \"password\": \"myRoot(!)Password\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Have a BigQuery emulator running in a Docker container. The official BigQuery image requires authentication \n",
    "to Google Cloud and would actually interact with BigQuery. In command line, run the following commands:\n",
    "\n",
    "$ docker pull ghcr.io/goccy/bigquery-emulator:latest\n",
    "$ docker run -it -p 9050:9050 ghcr.io/goccy/bigquery-emulator:latest --project=test-project\n",
    "\n",
    "Note: if running the same SQL queries again, kill the container and start a fresh one because \n",
    "the deleting dataset functionality was not working as expected.\n",
    "\"\"\"\n",
    "\n",
    "biquery_db_creds = {\n",
    "     \"port\": 9050,\n",
    "     \"project\": \"test-project\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Apply different SQL validators to the SQL queries\n",
    "def is_valid_query_and_schema(row, func):\n",
    "    query_check = func(row['SQL Query'])\n",
    "    schema_check = func(row['Context'])\n",
    "    is_valid_schema = schema_check[0]\n",
    "    is_valid_query = query_check[0]\n",
    "    is_valid_sql = is_valid_schema and is_valid_query\n",
    "    error_messages = f\"***Schema error: {schema_check[1]}\" if not is_valid_schema else ''\n",
    "    error_messages += f\"***Query error: {query_check[1]}\" if not is_valid_query else ''\n",
    "    return is_valid_sql, is_valid_schema, is_valid_query, error_messages\n",
    "\n",
    "def is_valid_query_and_schema_with_sqlfluff(row):\n",
    "    dialect_map = {\n",
    "        'SQLite': 'sqlite',\n",
    "        'PostgreSQL': 'postgres',\n",
    "        'MySQL': 'mysql',\n",
    "        'SQL Server': 'tsql',\n",
    "        'GoogleSQL': 'bigquery',\n",
    "        'Oracle': 'oracle',\n",
    "    }\n",
    "    if 'Oracle' in row['Dialect']:\n",
    "        dialect = 'oracle'\n",
    "    else:\n",
    "        dialect = dialect_map.get(row['Dialect'], 'ansi')\n",
    "    query_check = SimpleSqlValidator.is_valid_sql_with_sqlfluff(row['SQL Query'], dialect)\n",
    "    schema_check = SimpleSqlValidator.is_valid_sql_with_sqlfluff(row['Context'], dialect)\n",
    "    is_valid_schema = schema_check[0]\n",
    "    is_valid_query = query_check[0]\n",
    "    is_valid_sql = is_valid_schema and is_valid_query\n",
    "    error_messages = f\"***Schema error: {schema_check[1]}\" if not is_valid_schema else ''\n",
    "    error_messages += f\"***Query error: {query_check[1]}\" if not is_valid_query else ''\n",
    "    return is_valid_sql, is_valid_schema, is_valid_query, error_messages\n",
    "\n",
    "def check_query_and_schema_separately(sql_queries, method):\n",
    "    start_time = time.time()\n",
    "    functions_to_apply = {\n",
    "        'sqlglot': partial(is_valid_query_and_schema, func=SimpleSqlValidator.is_valid_sql_with_sqlglot),\n",
    "        'sqlquery': partial(is_valid_query_and_schema, func=SimpleSqlValidator.is_valid_sql_with_sqlquery),\n",
    "        'sqlfluff': is_valid_query_and_schema_with_sqlfluff,\n",
    "    }\n",
    "\n",
    "    result = sql_queries.apply(functions_to_apply[method], axis=1).apply(list)\n",
    "    sql_queries[f'is_valid_sql_with_{method}'] = result.apply(lambda x: x[0])\n",
    "    sql_queries[f'is_valid_schema_with_{method}'] = result.apply(lambda x: x[1])\n",
    "    sql_queries[f'is_valid_query_with_{method}'] = result.apply(lambda x: x[2])\n",
    "    sql_queries[f'error_msgs_{method}'] = result.apply(lambda x: x[3])\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"{method} check executed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return sql_queries\n",
    "\n",
    "\n",
    "def check_query_against_schema(row, dialect):\n",
    "\n",
    "    validator_classes = {\n",
    "        'SQLite': SqliteValidator,\n",
    "        'PostgreSQL': PostgresqlValidator,\n",
    "        'MySQL': MysqlValidator,\n",
    "        'SQL Server': SqlserverValidator,\n",
    "        'GoogleSQL': GooglesqlValidator,\n",
    "    }\n",
    "\n",
    "    kwargs_postgres = {\n",
    "        'domain': row['Topic'],\n",
    "        'db_creds': postgres_db_creds,\n",
    "    }\n",
    "    kwargs_mysql = {\n",
    "        'domain': row['Topic'],\n",
    "        'db_creds': mysql_db_creds,\n",
    "        'mysql_container': mysql_container,\n",
    "    }\n",
    "    kwargs_sqlserver = {\n",
    "        'domain': row['Topic'],\n",
    "        'db_creds': sqlserver_db_creds,\n",
    "        'sqlserver_container': sqlserver_container,\n",
    "    }\n",
    "    kwargs_bigquery = {\n",
    "        'domain': row['db_name'],\n",
    "        'db_creds': biquery_db_creds,\n",
    "    }\n",
    "\n",
    "    all_kwargs = {\n",
    "        'SQLite': {},\n",
    "        'PostgreSQL': kwargs_postgres,\n",
    "        'MySQL': kwargs_mysql,\n",
    "        'SQL Server': kwargs_sqlserver,\n",
    "        'GoogleSQL': kwargs_bigquery\n",
    "    }\n",
    "\n",
    "    dialect_name = dialect.lower().replace(' ', '')\n",
    "\n",
    "    if row['Dialect'] == dialect:\n",
    "        result = validator_classes[dialect].is_valid_sql(\n",
    "            row['SQL Query'], row['Context'], **all_kwargs[dialect]\n",
    "            )\n",
    "    else:\n",
    "        result = None, None\n",
    "    \n",
    "    row[f'is_valid_{dialect_name}'] = result[0]\n",
    "    row[f'error_msg_{dialect_name}'] = result[1]\n",
    "    \n",
    "    return row\n",
    "\n",
    "def apply_check_query_against_schema(sql_queries, dialect):\n",
    "    start_time = time.time()\n",
    "    sql_queries = sql_queries.apply(check_query_against_schema, dialect=dialect, axis=1)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"{dialect} check executed in {elapsed_time:.2f} seconds\")\n",
    "    return sql_queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlfluff check executed in 250.23 seconds\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.970489\n",
      "False    0.029511\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.994098\n",
      "False    0.005902\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.956155\n",
      "False    0.043845\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sqlite\n",
      "True     0.980861\n",
      "False    0.019139\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_postgresql\n",
      "True     0.877273\n",
      "False    0.122727\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_mysql\n",
      "True     0.938776\n",
      "False    0.061224\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sqlserver\n",
      "True     0.83913\n",
      "False    0.16087\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_googlesql\n",
      "True     0.679426\n",
      "False    0.320574\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sql_queries = check_query_and_schema_separately(sql_queries, 'sqlfluff')\n",
    "# sql_queries = check_query_and_schema_separately(sql_queries, 'sqlglot')\n",
    "# sql_queries = check_query_and_schema_separately(sql_queries, 'sqlquery')\n",
    "\n",
    "# sql_queries = apply_check_query_against_schema(sql_queries, 'SQLite')\n",
    "# sql_queries = apply_check_query_against_schema(sql_queries, 'PostgreSQL')\n",
    "# sql_queries = apply_check_query_against_schema(sql_queries, 'MySQL')\n",
    "# sql_queries = apply_check_query_against_schema(sql_queries, 'SQL Server')\n",
    "# sql_queries = apply_check_query_against_schema(sql_queries, 'GoogleSQL')\n",
    "\n",
    "print(sql_queries.is_valid_sql_with_sqlglot.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_sql_with_sqlquery.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_sql_with_sqlfluff.value_counts(normalize=True))\n",
    "\n",
    "print(sql_queries.is_valid_sqlite.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_postgresql.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_mysql.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_sqlserver.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_googlesql.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "googlesql_error_category\n",
      "Type not found                    46\n",
      "Foreign keys are not supported     9\n",
      "does not support                   5\n",
      "Syntax error                       2\n",
      "Name: count, dtype: int64\n",
      "SQL Query              5\n",
      "Context                5\n",
      "error_msg_googlesql    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_googlesql_error_categories(error_msg):\n",
    "    if not error_msg:\n",
    "        return None\n",
    "    googlesql_error_categories = ['Type not found', 'Syntax error', 'Foreign keys are not supported', 'does not support']\n",
    "    for category in googlesql_error_categories:\n",
    "        if category.lower() in error_msg.lower():\n",
    "            return category\n",
    "\n",
    "\n",
    "sql_queries['googlesql_error_category'] = sql_queries['error_msg_googlesql'].apply(get_googlesql_error_categories)\n",
    "\n",
    "remaining = sql_queries[(sql_queries.is_valid_googlesql == False) & (sql_queries.googlesql_error_category.isnull())][['SQL Query', 'Context', 'error_msg_googlesql']]\n",
    "print(sql_queries.googlesql_error_category.value_counts())\n",
    "print(remaining.count())\n",
    "# remaining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries.to_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sqlqueries_1200_validated_092524.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***SQLite***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.985646\n",
      "False    0.014354\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.985646\n",
      "False    0.014354\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "***PostgreSQL***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.986364\n",
      "False    0.013636\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.990909\n",
      "False    0.009091\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.918182\n",
      "False    0.081818\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "***MySQL***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.994898\n",
      "False    0.005102\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.989796\n",
      "False    0.010204\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.969388\n",
      "False    0.030612\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "***SQL Server***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.886957\n",
      "False    0.113043\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.991304\n",
      "False    0.008696\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.995652\n",
      "False    0.004348\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "***GoogleSQL***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.889952\n",
      "False    0.110048\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dialects = ['SQLite', 'PostgreSQL', 'MySQL', 'SQL Server', 'GoogleSQL']\n",
    "for dialect in dialects:\n",
    "    print(f\"\\n***{dialect}***\")\n",
    "    print(sql_queries[sql_queries['Dialect'] == dialect].is_valid_sql_with_sqlglot.value_counts(normalize=True))\n",
    "    print(sql_queries[sql_queries['Dialect'] == dialect].is_valid_sql_with_sqlquery.value_counts(normalize=True))\n",
    "    print(sql_queries[sql_queries['Dialect'] == dialect].is_valid_sql_with_sqlfluff.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SQLite***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.990431\n",
      "False    0.009569\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.990431\n",
      "False    0.009569\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "***PostgreSQL***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.986425\n",
      "False    0.013575\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.918552\n",
      "False    0.081448\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.923077\n",
      "False    0.076923\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "***MySQL***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.989848\n",
      "False    0.010152\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True     0.989848\n",
      "False    0.010152\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.969543\n",
      "False    0.030457\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.969543\n",
      "False    0.030457\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.974619\n",
      "False    0.025381\n",
      "Name: proportion, dtype: float64\n",
      "***SQL Server***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.886957\n",
      "False    0.113043\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True     0.9\n",
      "False    0.1\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True     0.982609\n",
      "False    0.017391\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.991304\n",
      "False    0.008696\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True     0.991304\n",
      "False    0.008696\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.995652\n",
      "False    0.004348\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.995652\n",
      "False    0.004348\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.995652\n",
      "False    0.004348\n",
      "Name: proportion, dtype: float64\n",
      "***GoogleSQL***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.97549\n",
      "False    0.02451\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True     0.97549\n",
      "False    0.02451\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True     0.995098\n",
      "False    0.004902\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.995098\n",
      "False    0.004902\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True     0.995098\n",
      "False    0.004902\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.823529\n",
      "False    0.176471\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.828431\n",
      "False    0.171569\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.990196\n",
      "False    0.009804\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "methods = ['sqlglot', 'sqlquery', 'sqlfluff']\n",
    "for dialect in dialects:\n",
    "    print(f\"\\n***{dialect}***\")\n",
    "    for method in methods:\n",
    "        print(f\"***{method}***\")\n",
    "        print(sql_queries[sql_queries['Dialect'] == dialect][f'is_valid_sql_with_{method}'].value_counts(normalize=True))\n",
    "        print(sql_queries[sql_queries['Dialect'] == dialect][f'is_valid_schema_with_{method}'].value_counts(normalize=True))\n",
    "        print(sql_queries[sql_queries['Dialect'] == dialect][f'is_valid_query_with_{method}'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SQLite***\n",
      "is_valid_sql_aggregate\n",
      "True     0.990431\n",
      "False    0.009569\n",
      "Name: proportion, dtype: float64\n",
      "***PostgreSQL***\n",
      "is_valid_sql_aggregate\n",
      "True     0.914027\n",
      "False    0.085973\n",
      "Name: proportion, dtype: float64\n",
      "***MySQL***\n",
      "is_valid_sql_aggregate\n",
      "True     0.969543\n",
      "False    0.030457\n",
      "Name: proportion, dtype: float64\n",
      "***SQL Server***\n",
      "is_valid_sql_aggregate\n",
      "True     0.882609\n",
      "False    0.117391\n",
      "Name: proportion, dtype: float64\n",
      "***GoogleSQL***\n",
      "is_valid_sql_aggregate\n",
      "True     0.823529\n",
      "False    0.176471\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check if the query is valid with both sqlglot and sqlfluff\n",
    "# SQLQuery is proven to be useless so not counting it in the aggregate\n",
    "sql_queries['is_valid_sql_aggregate'] = sql_queries[['is_valid_sql_with_sqlglot', 'is_valid_sql_with_sqlfluff']].all(axis=1)\n",
    "for dialect in dialects:\n",
    "    print(f\"***{dialect}***\")\n",
    "    print(sql_queries[sql_queries['Dialect'] == dialect].is_valid_sql_aggregate.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***SQLite***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_sqlite                         \n",
      "False                           2      2\n",
      "True                            1    204\n",
      "\n",
      "***PostgreSQL***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_postgresql                     \n",
      "False                          18      9\n",
      "True                            0    193\n",
      "\n",
      "***MySQL***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_mysql                          \n",
      "False                           6      6\n",
      "True                            0    184\n",
      "\n",
      "***SQL Server***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_sqlserver                      \n",
      "False                           1     36\n",
      "True                            0    193\n",
      "\n",
      "***GoogleSQL***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_googlesql                      \n",
      "False                          14     53\n",
      "True                            9    133\n"
     ]
    }
   ],
   "source": [
    "# What are the differences between checking against schema and validating the query separately from schema?\n",
    "for dialect in dialects:\n",
    "    print(f\"\\n***{dialect}***\")\n",
    "    dialect_name = dialect.lower().replace(' ', '')\n",
    "    df = sql_queries[sql_queries['Dialect'] == dialect]\n",
    "    print(pd.crosstab(df[f'is_valid_{dialect_name}'], df['is_valid_sql_with_sqlfluff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleSQL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQL Query</th>\n",
       "      <th>Context</th>\n",
       "      <th>error_msg_googlesql</th>\n",
       "      <th>error_msgs_sqlfluff</th>\n",
       "      <th>error_msgs_sqlquery</th>\n",
       "      <th>error_msgs_sqlglot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>SELECT PolicyID, PolicyName, Description FROM PlatformPolicies WHERE LastUpdated &gt; '2022-01-01';</td>\n",
       "      <td>CREATE TABLE PlatformPolicies (   PolicyID STRING NOT NULL,   PolicyName STRING NOT NULL, Description STRING,   LastUpdated DATE,   PRIMARY KEY (PolicyID) );</td>\n",
       "      <td>None</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 31: Found unparsable section: '(   PolicyID STRING NOT NULL,   PolicyNa...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>SELECT * FROM Security_Breaches WHERE EXTRACT(YEAR FROM reported_date) = EXTRACT(YEAR FROM CURRENT_DATE()) - 1;</td>\n",
       "      <td>CREATE TABLE Security_Breaches (     breach_id STRING NOT NULL,     description STRING, reported_date DATE,     affected_customers INT64, PRIMARY KEY(breach_id) );  CREATE TABLE Telecommunications_Companies (     company_id STRING NOT NULL,     company_name STRING, headquarters STRING,     PRIMARY KEY(company_id) );</td>\n",
       "      <td>None</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 32: Found unparsable section: '(     breach_id STRING NOT NULL,     des...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>SELECT plant_name, capacity_mw FROM RenewableEnergyPlants;</td>\n",
       "      <td>CREATE TABLE RenewableEnergyPlants (     plant_id STRING NOT NULL,     plant_name STRING, capacity_mw FLOAT,     PRIMARY KEY(plant_id) );</td>\n",
       "      <td>None</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 36: Found unparsable section: '(     plant_id STRING NOT NULL,     plan...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>SELECT MAX(close) AS highest_closing_price FROM stocks WHERE ticker = 'AAPL' AND EXTRACT(YEAR FROM date) = 2022;</td>\n",
       "      <td>CREATE TABLE stocks (     ticker STRING NOT NULL, date DATE NOT NULL,     open FLOAT64,     high FLOAT64,     low FLOAT64,     close FLOAT64, volume INT64,     PRIMARY KEY (ticker, date) ); CREATE TABLE companies (     ticker STRING NOT NULL,     name STRING NOT NULL,     sector STRING, industry STRING,     PRIMARY KEY (ticker) );</td>\n",
       "      <td>None</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 21: Found unparsable section: '(     ticker STRING NOT NULL, date DATE ...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>SELECT COUNT(*) FROM BMI_View WHERE BMI &gt; 25;</td>\n",
       "      <td>CREATE TABLE Patients (   patient_id STRING, name STRING,   age INT64,   height FLOAT64, weight FLOAT64,   PRIMARY KEY(patient_id) ); CREATE VIEW BMI_View AS SELECT patient_id, weight / (height * height) AS BMI FROM Patients;</td>\n",
       "      <td>None</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 23: Found unparsable section: '(   patient_id STRING, name STRING,   ag...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             SQL Query  \\\n",
       "1033                  SELECT PolicyID, PolicyName, Description FROM PlatformPolicies WHERE LastUpdated > '2022-01-01';   \n",
       "1044   SELECT * FROM Security_Breaches WHERE EXTRACT(YEAR FROM reported_date) = EXTRACT(YEAR FROM CURRENT_DATE()) - 1;   \n",
       "1074                                                        SELECT plant_name, capacity_mw FROM RenewableEnergyPlants;   \n",
       "1094  SELECT MAX(close) AS highest_closing_price FROM stocks WHERE ticker = 'AAPL' AND EXTRACT(YEAR FROM date) = 2022;   \n",
       "1097                                                                     SELECT COUNT(*) FROM BMI_View WHERE BMI > 25;   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                           Context  \\\n",
       "1033                                                                                                                                                                                 CREATE TABLE PlatformPolicies (   PolicyID STRING NOT NULL,   PolicyName STRING NOT NULL, Description STRING,   LastUpdated DATE,   PRIMARY KEY (PolicyID) );   \n",
       "1044                 CREATE TABLE Security_Breaches (     breach_id STRING NOT NULL,     description STRING, reported_date DATE,     affected_customers INT64, PRIMARY KEY(breach_id) );  CREATE TABLE Telecommunications_Companies (     company_id STRING NOT NULL,     company_name STRING, headquarters STRING,     PRIMARY KEY(company_id) );   \n",
       "1074                                                                                                                                                                                                     CREATE TABLE RenewableEnergyPlants (     plant_id STRING NOT NULL,     plant_name STRING, capacity_mw FLOAT,     PRIMARY KEY(plant_id) );   \n",
       "1094  CREATE TABLE stocks (     ticker STRING NOT NULL, date DATE NOT NULL,     open FLOAT64,     high FLOAT64,     low FLOAT64,     close FLOAT64, volume INT64,     PRIMARY KEY (ticker, date) ); CREATE TABLE companies (     ticker STRING NOT NULL,     name STRING NOT NULL,     sector STRING, industry STRING,     PRIMARY KEY (ticker) );   \n",
       "1097                                                                                                             CREATE TABLE Patients (   patient_id STRING, name STRING,   age INT64,   height FLOAT64, weight FLOAT64,   PRIMARY KEY(patient_id) ); CREATE VIEW BMI_View AS SELECT patient_id, weight / (height * height) AS BMI FROM Patients;   \n",
       "\n",
       "     error_msg_googlesql  \\\n",
       "1033                None   \n",
       "1044                None   \n",
       "1074                None   \n",
       "1094                None   \n",
       "1097                None   \n",
       "\n",
       "                                                                                                     error_msgs_sqlfluff  \\\n",
       "1033  ***Schema error: PRS: Line 1, Position 31: Found unparsable section: '(   PolicyID STRING NOT NULL,   PolicyNa...'   \n",
       "1044  ***Schema error: PRS: Line 1, Position 32: Found unparsable section: '(     breach_id STRING NOT NULL,     des...'   \n",
       "1074  ***Schema error: PRS: Line 1, Position 36: Found unparsable section: '(     plant_id STRING NOT NULL,     plan...'   \n",
       "1094  ***Schema error: PRS: Line 1, Position 21: Found unparsable section: '(     ticker STRING NOT NULL, date DATE ...'   \n",
       "1097  ***Schema error: PRS: Line 1, Position 23: Found unparsable section: '(   patient_id STRING, name STRING,   ag...'   \n",
       "\n",
       "     error_msgs_sqlquery error_msgs_sqlglot  \n",
       "1033                                         \n",
       "1044                                         \n",
       "1074                                         \n",
       "1094                                         \n",
       "1097                                         "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect = dialects[4]\n",
    "dialect_name = dialect.lower().replace(' ', '')\n",
    "print(dialect)\n",
    "df = sql_queries[(sql_queries['Dialect'] == dialect) & \n",
    "                 ((sql_queries['is_valid_sql_with_sqlfluff'] == False) & \n",
    "                  (sql_queries[f'is_valid_{dialect_name}'] == True))]\n",
    "df[['SQL Query', 'Context', f'error_msg_{dialect_name}', 'error_msgs_sqlfluff', 'error_msgs_sqlquery', 'error_msgs_sqlglot']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    CREATE TABLE Properties (PropertyID INT PRIMARY KEY, Address NVARCHAR(255), OwnerID INT); CREATE TABLE Rentals (RentalID INT PRIMARY KEY, PropertyID INT FOREIGN KEY REFERENCES Properties(PropertyID), TenantID INT, RentAmount DECIMAL(10,2), RentDate DATE); CREATE TABLE Owners (OwnerID INT PRIMARY KEY, OwnerName NVARCHAR(255));\n",
      "5                                                                                                                                                                                                                       CREATE TABLE Machines (\\n  machine_id SERIAL PRIMARY KEY,\\n  machine_name VARCHAR(255),\\n  last_active_date DATE\\n);\n",
      "Name: Context, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sql_queries['Context'].loc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Code Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['F821'], ['Undefined name `word`'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "bad_code = \"\"\"\n",
    "import re2\n",
    "world = \"hhh\"\n",
    "print(word)\n",
    "\"\"\"\n",
    "\n",
    "# Errors that will lead to runtime errors\n",
    "select_errors = [\n",
    "    \"F821\", \"F822\", \"F823\", \"F841\",   # Pyflakes: Undefined names, imports\n",
    "    \"PLE\",                            # Pylint: Errors\n",
    "]\n",
    "\n",
    "# Issues that are highly likely to cause runtime errors\n",
    "select_issues = [\n",
    "    \"F401\", \"F811\",   # Pyflakes: Unused imports, variables\n",
    "    \"ARG\",                    # Flake8: Unused arguments\n",
    "    \"B\",                      # Bugbear: All bugbear issues which flag potential common bugs\n",
    "    \"A\",                      # Builtins: Avoid shadowing built-in names\n",
    "    \"C901\",                   # Complexity\n",
    "    \"RET505\", \"RET506\", \"RET507\", \"RET508\", # Flake8: Unreachable code\n",
    "    \"FIX\",                    # Flake8: Contains TODO or FIXME which indicates incomplete code\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "proc = subprocess.run(\n",
    "    [\"ruff\", \"check\", f\"--select={','.join(select_errors)}\", \"--output-format=json\", \"-\"],\n",
    "    input=bad_code,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(proc.returncode)  # 1 if bad\n",
    "print(proc.stderr)\n",
    "# print(json.loads(proc.stdout))\n",
    "result = json.loads(proc.stdout)\n",
    "error_codes = [issue['code'] for issue in result]\n",
    "error_messages = [issue['message'] for issue in result]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_code_with_method(df, method='compile', language='python'):\n",
    "    start_time = time.time()\n",
    "    if language == 'python':\n",
    "        methods = python_check_methods\n",
    "    elif language == 'typescript':\n",
    "        methods = typescript_check_methods\n",
    "    elif language == 'sql':\n",
    "        raise ValueError('SQL not supported as it requires a schema as input')\n",
    "    else:\n",
    "        raise ValueError('language not supported')\n",
    "    func = methods[method]\n",
    "    df[f'check_{method}'] = df['code'].apply(func)\n",
    "    df[f'is_valid_{language}_with_{method}'] = df[f'check_{method}'].apply(lambda x: x[0])\n",
    "    df[f'{method}_error'] = df[f'check_{method}'].apply(lambda x: x[1])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"\\n{method} check executed in {elapsed_time:.2f} seconds\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile check executed in 0.33 seconds\n",
      "is_valid_python_with_compile\n",
      "True     976\n",
      "False     24\n",
      "Name: count, dtype: int64\n",
      "ast check executed in 0.34 seconds\n",
      "is_valid_python_with_ast\n",
      "True     976\n",
      "False     24\n",
      "Name: count, dtype: int64\n",
      "pyflakes check executed in 3.62 seconds\n",
      "is_valid_python_with_pyflakes\n",
      "True     667\n",
      "False    333\n",
      "Name: count, dtype: int64\n",
      "parso check executed in 5.24 seconds\n",
      "is_valid_python_with_parso\n",
      "True    1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "python_check_methods = {\n",
    "    'compile': is_valid_python_with_complie,\n",
    "    'ast': is_valid_python_with_ast,\n",
    "    'pyflakes': is_valid_python_with_pyflakes,\n",
    "    'parso': is_valid_python_with_parso,\n",
    "    'mypy': is_valid_python_with_mypy,\n",
    "    'ruff': is_valid_python_with_ruff,\n",
    "}\n",
    "\n",
    "for method in python_check_methods.keys():\n",
    "    python_codes = check_code_with_method(python_codes, method)\n",
    "    print(python_codes[f'is_valid_python_with_{method}'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>compile_error</th>\n",
       "      <th>ast_error</th>\n",
       "      <th>is_valid_python_with_pyflakes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>import threading\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Function to process user sessions in parallel\\ndef process_session(session):\\n    # Analyze user behavior in real-time\\n    user_behavior = analyze_user_behavior(session)\\n\\n    # Detect signs of potential cart abandonment\\n    is_abandonment = detect_abandonment(user_behavior)\\n\\n    if is_abandonment:\\n        # Trigger appropriate interventions (e.g., sending a reminder email or push notification)\\n        trigger_intervention(session)\\n\\n# Function to analyze user behavior in real-time\\ndef analyze_user_behavior(session):\\n    # Implement logic to analyze user behavior\\n    # ...\\n\\n    return user_behavior\\n\\n# Function to detect signs of potential cart abandonment\\ndef detect_abandonment(user_behavior):\\n    # Implement logic to detect signs of potential cart abandonment\\n    # ...\\n\\n    return is_abandonment\\n\\n# Function to trigger appropriate interventions (e.g., sending a remi...</td>\n",
       "      <td>expected an indented block (&lt;string&gt;, line 37)</td>\n",
       "      <td>expected an indented block (&lt;unknown&gt;, line 37)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nfrom multiprocessing import Pool\\n\\n# Preprocess the data\\ndef preprocess_data(data):\\n    # Perform data cleaning, feature engineering, and transformation\\n    # ...\\n\\n    return processed_data\\n\\n# Design a concurrent and parallel processing system\\ndef process_data_parallel(data_chunks):\\n    with Pool() as pool:\\n        processed_data = pool.map(preprocess_data, data_chunks)\\n\\n    return processed_data\\n\\n# Build the CLV prediction model\\ndef build_clv_model(processed_data):\\n    # Split the data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        processed_data.drop('CLV', axis=1),\\n        processed_data['CLV'],\\n        test_size=0.2,\\n        random_state=42\\n    )\\n\\n    # Train a random forest regression model\\n    model = RandomFor...</td>\n",
       "      <td>expected an indented block (&lt;string&gt;, line 48)</td>\n",
       "      <td>expected an indented block (&lt;unknown&gt;, line 48)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>import asyncio\\n\\nasync def ingest_data(spacecraft):\\n    # Connect to spacecraft and start streaming data\\n    while True:\\n        data = await spacecraft.receive_data()\\n        yield data\\n```\\n\\n2. **Data Processing**: Use `pandas` for data processing and analysis. This will allow us to handle large volumes of data efficiently and perform various operations on it.\\n\\n```python\\nimport pandas as pd\\n\\nasync def process_data(data):\\n    # Convert data to pandas DataFrame\\n    df = pd.DataFrame(data)\\n\\n    # Perform various operations on DataFrame (filtering, aggregation, etc.)\\n    processed_df = df.groupby('timestamp').mean()\\n\\n    return processed_df\\n```\\n\\n3. **Data Analysis**: Use `seaborn` or `matplotlib` for data visualization. This will allow us to gain insights from our data.\\n\\n```python\\nimport seaborn as sns\\n\\nasync def analyze_data(processed_df):\\n    # Generate a heatmap of the data\\n    sns.heatmap(processed_df.corr())\\n```\\n\\n4. **Error Handling**: Implement e...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 8)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 8)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>import numpy as np\\nimport matplotlib.pyplot as plt\\n\\ndef q_learning(state_space, action_space, reward_function, learning_rate, discount_factor, num_episodes, epsilon=0.1):\\n    # Initialize Q-table with zeros\\n    q_table = np.zeros((state_space, action_space))\\n\\n    # Initialize list to store learning curve\\n    learning_curve = []\\n\\n    # Loop through episodes\\n    for episode in range(num_episodes):\\n        # Reset state at beginning of episode\\n        state = 0\\n\\n        # Initialize total reward for episode\\n        total_reward = 0\\n\\n        # Loop through steps in episode\\n        for step in range(100):\\n            # Select action based on epsilon-greedy policy\\n            if np.random.uniform() &lt; epsilon:\\n                action = np.random.choice(action_space)\\n            else:\\n                action = np.argmax(q_table[state])\\n\\n            # Receive reward and next state from environment\\n            reward = reward_function(state, action)\\n            next...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 55)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 55)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>import sys\\n\\ndef count_error_code(log_file_path, error_code):\\n    count = 0\\n    with open(log_file_path, 'r') as file:\\n        for line in file:\\n            if error_code in line:\\n                count += 1\\n    return count\\n\\nif __name__ == \"__main__\":\\n    if len(sys.argv) != 3:\\n        print(\"Usage: python script.py &lt;log_file_path&gt; &lt;error_code&gt;\")\\n        sys.exit(1)\\n\\n    log_file_path = sys.argv[1]\\n    error_code = sys.argv[2]\\n\\n    error_code_count = count_error_code(log_file_path, error_code)\\n    print(f\"The count of error code '{error_code}' in the log file is: {error_code_count}\")\\n```\\n\\nTo use this script, save it as `count_error_code.py` and run it using the command:\\n\\n```bash\\npython count_error_code.py &lt;log_file_path&gt; &lt;error_code&gt;</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 21)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 21)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>import numpy as np\\n\\nclass MRI_Scanner:\\n    def __init__(self, patient_id, scan_date, scan_type):\\n        self.patient_id = patient_id\\n        self.scan_date = scan_date\\n        self.scan_type = scan_type\\n\\n    def simulate_scanning(self):\\n        try:\\n            if not isinstance(self.patient_id, int) or self.patient_id &lt;= 0:\\n                raise ValueError(\"Invalid patient ID\")\\n\\n            if not isinstance(self.scan_date, str) or len(self.scan_date.split(\"-\")) != 3:\\n                raise ValueError(\"Incorrect scan date format. Expected format: YYYY-MM-DD\")\\n\\n            if self.scan_type not in [\"T1\", \"T2\", \"FLAIR\"]:\\n                raise ValueError(\"Unsupported scan type. Expected values: T1, T2, FLAIR\")\\n\\n            np.random.seed(hash(self.patient_id) ^ hash(self.scan_date) ^ hash(self.scan_type))\\n            synthetic_image = np.random.randint(0, 256, (128, 128, 128))\\n\\n            return synthetic_image\\n        except ValueError as e:\\n            retu...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 28)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 28)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>class VirtualClassroom:\\n    def __init__(self, teacher=None, students=None, subject=None, room_capacity=0):\\n        self.teacher = teacher\\n        self.students = students if students else []\\n        self.subject = subject\\n        self.room_capacity = room_capacity\\n\\n    def add_student(self, student):\\n        if len(self.students) &gt;= self.room_capacity:\\n            raise Exception(\"Room capacity exceeded\")\\n        self.students.append(student)\\n\\n    def remove_student(self, student):\\n        if student in self.students:\\n            self.students.remove(student)\\n\\n    def assign_teacher(self, teacher):\\n        if self.teacher:\\n            raise Exception(\"Teacher already assigned\")\\n        self.teacher = teacher\\n\\n    def change_subject(self, subject):\\n        self.subject = subject\\n\\n    def display_classroom_details(self):\\n        print(f\"Teacher: {self.teacher}\")\\n        print(f\"Students: {', '.join(self.students)}\")\\n        print(f\"Subject: {self.subject}\"...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 30)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 30)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>import pandas as pd\\nimport random\\n\\ndef quiz_generator(questions_file_path):\\n    try:\\n        # Read the CSV file using pandas\\n        df = pd.read_csv(questions_file_path)\\n\\n        # Check if the file is empty\\n        if df.empty:\\n            return \"Error: The file is empty.\"\\n\\n        # Filter the questions by difficulty level\\n        easy_questions = df[df['difficulty'] == 'easy']\\n        medium_questions = df[df['difficulty'] == 'medium']\\n        hard_questions = df[df['difficulty'] == 'hard']\\n\\n        # Check if there are at least 3 questions of each difficulty level\\n        if len(easy_questions) &lt; 3 or len(medium_questions) &lt; 3 or len(hard_questions) &lt; 3:\\n            return \"Error: There should be at least 3 questions of each difficulty level.\"\\n\\n        # Randomly select 3 questions of each difficulty level\\n        selected_easy = easy_questions.sample(3)\\n        selected_medium = medium_questions.sample(3)\\n        selected_hard = hard_questions.sample...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 36)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 36)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>import numpy as np\\nfrom PIL import Image, ImageFilter\\n\\nclass ImageProcessor:\\n    def __init__(self, image_path):\\n        self.image_path = image_path\\n        try:\\n            self.image = Image.open(image_path)\\n        except Exception as e:\\n            print(f\"Error opening image: {e}\")\\n\\n    def to_grayscale(self):\\n        try:\\n            self.image = self.image.convert('L')\\n        except Exception as e:\\n            print(f\"Error converting to grayscale: {e}\")\\n\\n    def resize(self, size):\\n        try:\\n            self.image = self.image.resize(size)\\n        except Exception as e:\\n            print(f\"Error resizing image: {e}\")\\n\\n    def apply_gaussian_blur(self, radius=5):\\n        try:\\n            self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\\n        except Exception as e:\\n            print(f\"Error applying Gaussian blur: {e}\")\\n\\n    def get_image_data(self):\\n        try:\\n            return np.asarray(self.image)\\n        except Ex...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 35)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 35)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>To design a Python-based concurrent game engine for a multiplayer online battle arena (MOBA) game, we can utilize parallel processing for efficient real-time simulation of multiple player actions and metaprogramming for dynamic game object creation. The engine should include features such as network synchronization, collision detection, and physics simulation.\\n\\nHere is an overview of the design:\\n\\n1. Libraries and Frameworks:\\n   - `asyncio`: To handle concurrent processing for network synchronization.\\n   - `numpy`: For efficient numerical operations and physics simulation.\\n   - `pygame`: For creating the graphical user interface (GUI) and handling user input.\\n   - `tensorflow`: If needed for machine learning algorithms or predictions.\\n\\n2. High-Level Overview of the Design:\\n   - Game Objects: Represent players, characters, buildings, towers, and other game objects.\\n   - Game World: Manages the game state, including the list of game objects, terrain, and physics simulation...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 1)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        code  \\\n",
       "15   import threading\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Function to process user sessions in parallel\\ndef process_session(session):\\n    # Analyze user behavior in real-time\\n    user_behavior = analyze_user_behavior(session)\\n\\n    # Detect signs of potential cart abandonment\\n    is_abandonment = detect_abandonment(user_behavior)\\n\\n    if is_abandonment:\\n        # Trigger appropriate interventions (e.g., sending a reminder email or push notification)\\n        trigger_intervention(session)\\n\\n# Function to analyze user behavior in real-time\\ndef analyze_user_behavior(session):\\n    # Implement logic to analyze user behavior\\n    # ...\\n\\n    return user_behavior\\n\\n# Function to detect signs of potential cart abandonment\\ndef detect_abandonment(user_behavior):\\n    # Implement logic to detect signs of potential cart abandonment\\n    # ...\\n\\n    return is_abandonment\\n\\n# Function to trigger appropriate interventions (e.g., sending a remi...   \n",
       "26   import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nfrom multiprocessing import Pool\\n\\n# Preprocess the data\\ndef preprocess_data(data):\\n    # Perform data cleaning, feature engineering, and transformation\\n    # ...\\n\\n    return processed_data\\n\\n# Design a concurrent and parallel processing system\\ndef process_data_parallel(data_chunks):\\n    with Pool() as pool:\\n        processed_data = pool.map(preprocess_data, data_chunks)\\n\\n    return processed_data\\n\\n# Build the CLV prediction model\\ndef build_clv_model(processed_data):\\n    # Split the data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        processed_data.drop('CLV', axis=1),\\n        processed_data['CLV'],\\n        test_size=0.2,\\n        random_state=42\\n    )\\n\\n    # Train a random forest regression model\\n    model = RandomFor...   \n",
       "115  import asyncio\\n\\nasync def ingest_data(spacecraft):\\n    # Connect to spacecraft and start streaming data\\n    while True:\\n        data = await spacecraft.receive_data()\\n        yield data\\n```\\n\\n2. **Data Processing**: Use `pandas` for data processing and analysis. This will allow us to handle large volumes of data efficiently and perform various operations on it.\\n\\n```python\\nimport pandas as pd\\n\\nasync def process_data(data):\\n    # Convert data to pandas DataFrame\\n    df = pd.DataFrame(data)\\n\\n    # Perform various operations on DataFrame (filtering, aggregation, etc.)\\n    processed_df = df.groupby('timestamp').mean()\\n\\n    return processed_df\\n```\\n\\n3. **Data Analysis**: Use `seaborn` or `matplotlib` for data visualization. This will allow us to gain insights from our data.\\n\\n```python\\nimport seaborn as sns\\n\\nasync def analyze_data(processed_df):\\n    # Generate a heatmap of the data\\n    sns.heatmap(processed_df.corr())\\n```\\n\\n4. **Error Handling**: Implement e...   \n",
       "146  import numpy as np\\nimport matplotlib.pyplot as plt\\n\\ndef q_learning(state_space, action_space, reward_function, learning_rate, discount_factor, num_episodes, epsilon=0.1):\\n    # Initialize Q-table with zeros\\n    q_table = np.zeros((state_space, action_space))\\n\\n    # Initialize list to store learning curve\\n    learning_curve = []\\n\\n    # Loop through episodes\\n    for episode in range(num_episodes):\\n        # Reset state at beginning of episode\\n        state = 0\\n\\n        # Initialize total reward for episode\\n        total_reward = 0\\n\\n        # Loop through steps in episode\\n        for step in range(100):\\n            # Select action based on epsilon-greedy policy\\n            if np.random.uniform() < epsilon:\\n                action = np.random.choice(action_space)\\n            else:\\n                action = np.argmax(q_table[state])\\n\\n            # Receive reward and next state from environment\\n            reward = reward_function(state, action)\\n            next...   \n",
       "151                                                                                                                                                                                                                                          import sys\\n\\ndef count_error_code(log_file_path, error_code):\\n    count = 0\\n    with open(log_file_path, 'r') as file:\\n        for line in file:\\n            if error_code in line:\\n                count += 1\\n    return count\\n\\nif __name__ == \"__main__\":\\n    if len(sys.argv) != 3:\\n        print(\"Usage: python script.py <log_file_path> <error_code>\")\\n        sys.exit(1)\\n\\n    log_file_path = sys.argv[1]\\n    error_code = sys.argv[2]\\n\\n    error_code_count = count_error_code(log_file_path, error_code)\\n    print(f\"The count of error code '{error_code}' in the log file is: {error_code_count}\")\\n```\\n\\nTo use this script, save it as `count_error_code.py` and run it using the command:\\n\\n```bash\\npython count_error_code.py <log_file_path> <error_code>   \n",
       "160  import numpy as np\\n\\nclass MRI_Scanner:\\n    def __init__(self, patient_id, scan_date, scan_type):\\n        self.patient_id = patient_id\\n        self.scan_date = scan_date\\n        self.scan_type = scan_type\\n\\n    def simulate_scanning(self):\\n        try:\\n            if not isinstance(self.patient_id, int) or self.patient_id <= 0:\\n                raise ValueError(\"Invalid patient ID\")\\n\\n            if not isinstance(self.scan_date, str) or len(self.scan_date.split(\"-\")) != 3:\\n                raise ValueError(\"Incorrect scan date format. Expected format: YYYY-MM-DD\")\\n\\n            if self.scan_type not in [\"T1\", \"T2\", \"FLAIR\"]:\\n                raise ValueError(\"Unsupported scan type. Expected values: T1, T2, FLAIR\")\\n\\n            np.random.seed(hash(self.patient_id) ^ hash(self.scan_date) ^ hash(self.scan_type))\\n            synthetic_image = np.random.randint(0, 256, (128, 128, 128))\\n\\n            return synthetic_image\\n        except ValueError as e:\\n            retu...   \n",
       "163  class VirtualClassroom:\\n    def __init__(self, teacher=None, students=None, subject=None, room_capacity=0):\\n        self.teacher = teacher\\n        self.students = students if students else []\\n        self.subject = subject\\n        self.room_capacity = room_capacity\\n\\n    def add_student(self, student):\\n        if len(self.students) >= self.room_capacity:\\n            raise Exception(\"Room capacity exceeded\")\\n        self.students.append(student)\\n\\n    def remove_student(self, student):\\n        if student in self.students:\\n            self.students.remove(student)\\n\\n    def assign_teacher(self, teacher):\\n        if self.teacher:\\n            raise Exception(\"Teacher already assigned\")\\n        self.teacher = teacher\\n\\n    def change_subject(self, subject):\\n        self.subject = subject\\n\\n    def display_classroom_details(self):\\n        print(f\"Teacher: {self.teacher}\")\\n        print(f\"Students: {', '.join(self.students)}\")\\n        print(f\"Subject: {self.subject}\"...   \n",
       "229  import pandas as pd\\nimport random\\n\\ndef quiz_generator(questions_file_path):\\n    try:\\n        # Read the CSV file using pandas\\n        df = pd.read_csv(questions_file_path)\\n\\n        # Check if the file is empty\\n        if df.empty:\\n            return \"Error: The file is empty.\"\\n\\n        # Filter the questions by difficulty level\\n        easy_questions = df[df['difficulty'] == 'easy']\\n        medium_questions = df[df['difficulty'] == 'medium']\\n        hard_questions = df[df['difficulty'] == 'hard']\\n\\n        # Check if there are at least 3 questions of each difficulty level\\n        if len(easy_questions) < 3 or len(medium_questions) < 3 or len(hard_questions) < 3:\\n            return \"Error: There should be at least 3 questions of each difficulty level.\"\\n\\n        # Randomly select 3 questions of each difficulty level\\n        selected_easy = easy_questions.sample(3)\\n        selected_medium = medium_questions.sample(3)\\n        selected_hard = hard_questions.sample...   \n",
       "243  import numpy as np\\nfrom PIL import Image, ImageFilter\\n\\nclass ImageProcessor:\\n    def __init__(self, image_path):\\n        self.image_path = image_path\\n        try:\\n            self.image = Image.open(image_path)\\n        except Exception as e:\\n            print(f\"Error opening image: {e}\")\\n\\n    def to_grayscale(self):\\n        try:\\n            self.image = self.image.convert('L')\\n        except Exception as e:\\n            print(f\"Error converting to grayscale: {e}\")\\n\\n    def resize(self, size):\\n        try:\\n            self.image = self.image.resize(size)\\n        except Exception as e:\\n            print(f\"Error resizing image: {e}\")\\n\\n    def apply_gaussian_blur(self, radius=5):\\n        try:\\n            self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\\n        except Exception as e:\\n            print(f\"Error applying Gaussian blur: {e}\")\\n\\n    def get_image_data(self):\\n        try:\\n            return np.asarray(self.image)\\n        except Ex...   \n",
       "292  To design a Python-based concurrent game engine for a multiplayer online battle arena (MOBA) game, we can utilize parallel processing for efficient real-time simulation of multiple player actions and metaprogramming for dynamic game object creation. The engine should include features such as network synchronization, collision detection, and physics simulation.\\n\\nHere is an overview of the design:\\n\\n1. Libraries and Frameworks:\\n   - `asyncio`: To handle concurrent processing for network synchronization.\\n   - `numpy`: For efficient numerical operations and physics simulation.\\n   - `pygame`: For creating the graphical user interface (GUI) and handling user input.\\n   - `tensorflow`: If needed for machine learning algorithms or predictions.\\n\\n2. High-Level Overview of the Design:\\n   - Game Objects: Represent players, characters, buildings, towers, and other game objects.\\n   - Game World: Manages the game state, including the list of game objects, terrain, and physics simulation...   \n",
       "\n",
       "                                      compile_error  \\\n",
       "15   expected an indented block (<string>, line 37)   \n",
       "26   expected an indented block (<string>, line 48)   \n",
       "115               invalid syntax (<string>, line 8)   \n",
       "146              invalid syntax (<string>, line 55)   \n",
       "151              invalid syntax (<string>, line 21)   \n",
       "160              invalid syntax (<string>, line 28)   \n",
       "163              invalid syntax (<string>, line 30)   \n",
       "229              invalid syntax (<string>, line 36)   \n",
       "243              invalid syntax (<string>, line 35)   \n",
       "292               invalid syntax (<string>, line 1)   \n",
       "\n",
       "                                           ast_error  \\\n",
       "15   expected an indented block (<unknown>, line 37)   \n",
       "26   expected an indented block (<unknown>, line 48)   \n",
       "115               invalid syntax (<unknown>, line 8)   \n",
       "146              invalid syntax (<unknown>, line 55)   \n",
       "151              invalid syntax (<unknown>, line 21)   \n",
       "160              invalid syntax (<unknown>, line 28)   \n",
       "163              invalid syntax (<unknown>, line 30)   \n",
       "229              invalid syntax (<unknown>, line 36)   \n",
       "243              invalid syntax (<unknown>, line 35)   \n",
       "292               invalid syntax (<unknown>, line 1)   \n",
       "\n",
       "     is_valid_python_with_pyflakes  \n",
       "15                           False  \n",
       "26                           False  \n",
       "115                          False  \n",
       "146                          False  \n",
       "151                          False  \n",
       "160                          False  \n",
       "163                          False  \n",
       "229                          False  \n",
       "243                          False  \n",
       "292                          False  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_codes[python_codes.is_valid_python_with_compile == False][['code', 'compile_error', 'ast_error', 'is_valid_python_with_pyflakes']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes[(python_codes.is_valid_python_with_complie == True) & (python_codes.is_valid_python_with_pyflakes == False)][['code', 'pyflakes_error']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_error_category('pandas is imported but unused')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyflakes_error_category\n",
       "imported but unused           226\n",
       "undefined name                 53\n",
       "assigned to but never used     29\n",
       "Invalid Syntax                 24\n",
       "Other                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_error_category(pyflakes_error: str) -> str:\n",
    "    pyflakes_error_categories = ['undefined name', 'assigned to but never used', 'imported but unused']\n",
    "    for category in pyflakes_error_categories:\n",
    "        if pyflakes_error is not None:\n",
    "            if category in str(pyflakes_error):\n",
    "                return category\n",
    "    return None\n",
    "\n",
    "python_codes['pyflakes_error_category'] = python_codes['pyflakes_error'].apply(get_error_category)\n",
    "python_codes['pyflakes_error_category'][python_codes.is_valid_python_with_compile == False] = 'Invalid Syntax'\n",
    "python_codes['pyflakes_error_category'][(python_codes.is_valid_python_with_pyflakes == False) & (python_codes.pyflakes_error_category.isnull())] = 'Other'\n",
    "\n",
    "python_codes['pyflakes_error_category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.to_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/python_codes_with_checks.csv', index=False)\n",
    "# python_codes = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/python_codes_with_checks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python_codes[python_codes.is_valid_python_with_pyflakes == False][['code', 'pyflakes_error', 'is_valid_python_with_compile']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert Python Developer Needed for Autonomous Driving Software: We require an expert Python developer to create a concurrent and parallel processing system that can handle multiple data streams from various sensors (e.g., LIDAR, RADAR, cameras) in real-time. The system should be capable of metaprogramming to adapt to different vehicle models and their unique sensor configurations. The final code will be integrated into our autonomous driving software for the automotive industry. Please provide a detailed solution that demonstrates your expertise in concurrency, parallel processing, and metaprogramming.\n",
      "\n",
      "### Instructions\n",
      "    * The code should have a complexity of \"Expert: Concurrency, parallel processing, and metaprogramming\".\n",
      "    * Write code that might be used in the \"Automotive Software\" industry within a \"Autonomous Driving\" context.\n",
      "    * Try to include at least 1 of the following Python packages:  `numpy`.\n",
      "    * Include only the code, without any comments or additional text.\n",
      "\n",
      "----------\n",
      "\n",
      "import concurrent.futures\n",
      "import numpy as np\n",
      "\n",
      "# Simulated sensor data streams\n",
      "sensor_data = {\n",
      "    'lidar': np.random.rand(100, 3),\n",
      "    'radar': np.random.rand(100, 2),\n",
      "    'camera': np.random.rand(100, 4)\n",
      "}\n",
      "\n",
      "# Function to process sensor data\n",
      "def process_sensor_data(sensor_name, data):\n",
      "    # Perform some processing on the data\n",
      "    processed_data = data * 2\n",
      "    return sensor_name, processed_data\n",
      "\n",
      "# Create a thread pool executor\n",
      "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
      "    # Submit the processing tasks to the executor\n",
      "    futures = {sensor_name: executor.submit(process_sensor_data, sensor_name, data)\n",
      "               for sensor_name, data in sensor_data.items()}\n",
      "\n",
      "    # Get the results from the completed tasks\n",
      "    results = {sensor_name: future.result() for sensor_name, future in concurrent.futures.as_completed(futures)}\n",
      "\n",
      "# Print the results\n",
      "for sensor_name, processed_data in results.items():\n",
      "    print(f\"Processed {sensor_name} data:\")\n",
      "    print(processed_data)\n",
      "    print()\n"
     ]
    }
   ],
   "source": [
    "# compile errors\n",
    "ind = 15\n",
    "ind = 115\n",
    "# pyflakes errors\n",
    "ind = 2 # imported but unused\n",
    "ind = 69 # assigned to but never used\n",
    "ind = 36 # undefined name\n",
    "# mypy errors\n",
    "ind = 576 # missing positional argument\n",
    "ind = 743 # unsupported operand types\n",
    "ind = 545 # has no attribute X\n",
    "# incomplete code\n",
    "ind = 261\n",
    "\n",
    "ind = 509\n",
    "print(python_codes.prompt[ind])\n",
    "print('----------\\n')\n",
    "print(python_codes.code[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.error_category[(python_codes.is_valid_python_with_mypy == False)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mypy_error</th>\n",
       "      <th>pyflakes_error_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;string&gt;:37: \u001b[1m\u001b[31merror:\u001b[m expected an indented block  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;string&gt;:48: \u001b[1m\u001b[31merror:\u001b[m expected an indented block  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>&lt;string&gt;:18: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>assigned to but never used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>&lt;string&gt;:8: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>&lt;string&gt;:55: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>&lt;string&gt;:21: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>&lt;string&gt;:35: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queues\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n&lt;string&gt;:36: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"alert_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 2 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>&lt;string&gt;:28: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>&lt;string&gt;:30: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>&lt;string&gt;:29: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"output_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>&lt;string&gt;:1: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>&lt;string&gt;:37: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:38: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:39: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:40: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 4 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>&lt;string&gt;:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream3\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 3 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>&lt;string&gt;:9: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"frame_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n&lt;string&gt;:51: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"preprocess_frame\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 2 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>&lt;string&gt;:36: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>&lt;string&gt;:12: \u001b[1m\u001b[31merror:\u001b[m Incompatible types in assignment (expression has type \u001b[m\u001b[1m\"float\"\u001b[m, variable has type \u001b[m\u001b[1m\"int\"\u001b[m)  \u001b[m\u001b[33m[assignment]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>&lt;string&gt;:29: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>&lt;string&gt;:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"sphere\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:9: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:9: \u001b...</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>&lt;string&gt;:35: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>&lt;string&gt;:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"submission1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"student_id1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"submission2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"student_id2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 4 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>&lt;string&gt;:3: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:3: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:3: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:3: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data3\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data4\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data5\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 5 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>&lt;string&gt;:1: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>&lt;string&gt;:1: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>&lt;string&gt;:48: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_list\"\u001b[m (hint: \u001b[m\u001b[1m\"data_list: list[&lt;type&gt;] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n&lt;string&gt;:49: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"central_server_data\"\u001b[m (hint: \u001b[m\u001b[1m\"central_server_data: list[&lt;type&gt;] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n&lt;string&gt;:50: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"error_data_list\"\u001b[m (hint: \u001b[m\u001b[1m\"error_data_list: list[&lt;type&gt;] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 3 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  mypy_error  \\\n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <string>:37: \u001b[1m\u001b[31merror:\u001b[m expected an indented block  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <string>:48: \u001b[1m\u001b[31merror:\u001b[m expected an indented block  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "69                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <string>:18: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "72                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "115                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <string>:8: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "146                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:55: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "151                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:21: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "157                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <string>:35: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queues\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n<string>:36: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"alert_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 2 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "160                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:28: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "163                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:30: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "164                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <string>:29: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"output_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "166                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "175                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:1: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "180                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <string>:37: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:38: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:39: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:40: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 4 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "191                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <string>:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream3\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 3 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "219                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:9: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"frame_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n<string>:51: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"preprocess_frame\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 2 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "229                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:36: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "231                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:12: \u001b[1m\u001b[31merror:\u001b[m Incompatible types in assignment (expression has type \u001b[m\u001b[1m\"float\"\u001b[m, variable has type \u001b[m\u001b[1m\"int\"\u001b[m)  \u001b[m\u001b[33m[assignment]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "234                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <string>:29: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "240  <string>:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"sphere\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:9: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:9: \u001b...   \n",
       "243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:35: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "244                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"submission1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"student_id1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"submission2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"student_id2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 4 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "249                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:3: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:3: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:3: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:3: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "259                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data3\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data4\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data5\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 5 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "261                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:1: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "292                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <string>:1: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "316                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "321                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:48: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_list\"\u001b[m (hint: \u001b[m\u001b[1m\"data_list: list[<type>] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n<string>:49: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"central_server_data\"\u001b[m (hint: \u001b[m\u001b[1m\"central_server_data: list[<type>] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n<string>:50: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"error_data_list\"\u001b[m (hint: \u001b[m\u001b[1m\"error_data_list: list[<type>] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 3 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "\n",
       "        pyflakes_error_category  \n",
       "13                         None  \n",
       "15               Invalid Syntax  \n",
       "26               Invalid Syntax  \n",
       "41          imported but unused  \n",
       "69   assigned to but never used  \n",
       "72                         None  \n",
       "115              Invalid Syntax  \n",
       "146              Invalid Syntax  \n",
       "151              Invalid Syntax  \n",
       "157         imported but unused  \n",
       "160              Invalid Syntax  \n",
       "163              Invalid Syntax  \n",
       "164         imported but unused  \n",
       "166                        None  \n",
       "175         imported but unused  \n",
       "180              undefined name  \n",
       "191              undefined name  \n",
       "219              undefined name  \n",
       "229              Invalid Syntax  \n",
       "231         imported but unused  \n",
       "234                        None  \n",
       "240              undefined name  \n",
       "243              Invalid Syntax  \n",
       "244              undefined name  \n",
       "249                        None  \n",
       "259              undefined name  \n",
       "261                        None  \n",
       "292              Invalid Syntax  \n",
       "316                        None  \n",
       "321         imported but unused  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_codes[(python_codes.is_valid_python_with_mypy == False)][['mypy_error', 'pyflakes_error_category']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python_codes[python_codes.pyflakes_error_category == 'undefined name'][['pyflakes_error', 'mypy_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incomplete_code\n",
      "False    968\n",
      "True      32\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>pyflakes_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>import threading\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Function to process user sessions in parallel\\ndef process_session(session):\\n    # Analyze user behavior in real-time\\n    user_behavior = analyze_user_behavior(session)\\n\\n    # Detect signs of potential cart abandonment\\n    is_abandonment = detect_abandonment(user_behavior)\\n\\n    if is_abandonment:\\n        # Trigger appropriate interventions (e.g., sending a reminder email or push notification)\\n        trigger_intervention(session)\\n\\n# Function to analyze user behavior in real-time\\ndef analyze_user_behavior(session):\\n    # Implement logic to analyze user behavior\\n    # ...\\n\\n    return user_behavior\\n\\n# Function to detect signs of potential cart abandonment\\ndef detect_abandonment(user_behavior):\\n    # Implement logic to detect signs of potential cart abandonment\\n    # ...\\n\\n    return is_abandonment\\n\\n# Function to trigger appropriate interventions (e.g., sending a remi...</td>\n",
       "      <td>&lt;string&gt;:37:1: expected an indented block\\nuser_sessions = pd.read_csv('user_sessions.csv')\\n^\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nfrom multiprocessing import Pool\\n\\n# Preprocess the data\\ndef preprocess_data(data):\\n    # Perform data cleaning, feature engineering, and transformation\\n    # ...\\n\\n    return processed_data\\n\\n# Design a concurrent and parallel processing system\\ndef process_data_parallel(data_chunks):\\n    with Pool() as pool:\\n        processed_data = pool.map(preprocess_data, data_chunks)\\n\\n    return processed_data\\n\\n# Build the CLV prediction model\\ndef build_clv_model(processed_data):\\n    # Split the data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        processed_data.drop('CLV', axis=1),\\n        processed_data['CLV'],\\n        test_size=0.2,\\n        random_state=42\\n    )\\n\\n    # Train a random forest regression model\\n    model = RandomFor...</td>\n",
       "      <td>&lt;string&gt;:48:1: expected an indented block\\nsales_data = pd.read_csv('sales_data.csv')\\n^\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>import concurrent.futures\\nimport requests\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import IsolationForest\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Define a list of network protocols\\nprotocols = ['http', 'https', 'ftp', 'ssh', 'smtp']\\n\\n# Define a function to analyze network traffic for a given protocol\\ndef analyze_traffic(protocol):\\n    # Fetch network traffic data for the given protocol\\n    data = requests.get(f'https://api.example.com/traffic/{protocol}').json()\\n\\n    # Preprocess the data\\n    df = pd.DataFrame(data)\\n    scaler = StandardScaler()\\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\\n\\n    # Detect anomalies using Isolation Forest\\n    clf = IsolationForest(contamination=0.01)\\n    preds = clf.fit_predict(df)\\n    anomalies = df[preds == -1]\\n\\n    # Mitigate the detected anomalies\\n    # ...\\n\\n    return anomalies\\n\\n# Create a thread pool executor\\nwith concurrent.futures.ThreadPoolExecutor() as exec...</td>\n",
       "      <td>&lt;string&gt;:4:1: 'numpy as np' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>import threading\\nimport queue\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport scipy.stats as stats\\n\\n# Define a worker function to process data streams\\ndef worker(data_queue):\\n    while True:\\n        data = data_queue.get()\\n        # Perform analytics on the data\\n        # ...\\n        # Update network settings based on analytics results\\n        # ...\\n        data_queue.task_done()\\n\\n# Create a queue to hold data streams\\ndata_queue = queue.Queue()\\n\\n# Create and start multiple worker threads\\nfor i in range(4):\\n    t = threading.Thread(target=worker, args=(data_queue,))\\n    t.start()\\n\\n# Generate and process synthetic data\\nfor _ in range(100):\\n    data = pd.DataFrame({'signal_strength': stats.norm.rvs(size=1000),\\n                         'latency': stats.uniform.rvs(size=1000),\\n                         'packet_loss': stats.binom.rvs(100, 0.05, size=1000)})\\n    data_queue.put(data)\\n\\n# Wait for all tasks in the queue to be processed\\ndata_queue.joi...</td>\n",
       "      <td>&lt;string&gt;:10:9: local variable 'data' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport concurrent.futures\\nfrom scipy.optimize import minimize_scalar\\n\\n# Differential Privacy Mechanism: Laplace Mechanism\\ndef laplace_mechanism(data, epsilon):\\n    noise = np.random.laplace(0, 1 / epsilon, len(data))\\n    return data + noise\\n\\n# Process a subset of data\\ndef process_subset(subset, epsilon):\\n    # Add noise to the data\\n    noisy_data = laplace_mechanism(subset, epsilon)\\n    # Perform analytics or ML tasks on the noisy data\\n    # ...\\n    return result\\n\\n# Combine results while maintaining privacy\\ndef combine_results(results):\\n    # Perform post-processing on the results to ensure privacy\\n    # ...\\n    return combined_result\\n\\n# Main function to manage processes and combine results\\ndef main():\\n    # Read large dataset\\n    data = pd.read_csv('large_dataset.csv')\\n\\n    # Split data into subsets for parallel processing\\n    subsets = np.array_split(data, num_processes)\\n\\n    # Set epsilon value for differenti...</td>\n",
       "      <td>&lt;string&gt;:4:1: 'scipy.optimize.minimize_scalar' imported but unused\\n&lt;string&gt;:14:5: local variable 'noisy_data' is assigned to but never used\\n&lt;string&gt;:17:12: undefined name 'result'\\n&lt;string&gt;:23:12: undefined name 'combined_result'\\n&lt;string&gt;:31:36: undefined name 'num_processes'\\n&lt;string&gt;:38:74: undefined name 'num_processes'\\n&lt;string&gt;:41:5: local variable 'combined_result' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>import asyncio\\nimport pandas as pd\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Simulated supplier data feeds\\nsupplier_data_feeds = {\\n    'Supplier1': 'data1.csv',\\n    'Supplier2': 'data2.csv',\\n    'Supplier3': 'data3.csv'\\n}\\n\\n# Function to process data from a supplier\\ndef process_supplier_data(supplier, file):\\n    data = pd.read_csv(file)\\n    # Process data (e.g., update inventory database)\\n    # ...\\n    return data\\n\\n# Function to handle real-time updates from suppliers\\nasync def handle_supplier_updates():\\n    with ThreadPoolExecutor(max_workers=3) as executor:\\n        tasks = {executor.submit(process_supplier_data, supplier, file): supplier for supplier, file in supplier_data_feeds.items()}\\n        for future in asyncio.as_completed(tasks):\\n            supplier = tasks[future]\\n            try:\\n                data = await future\\n                # Process data (e.g., update inventory database)\\n                # ...\\n            except Exception as...</td>\n",
       "      <td>&lt;string&gt;:26:17: local variable 'data' is assigned to but never used\\n&lt;string&gt;:30:23: f-string is missing placeholders\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>import threading\\nimport queue\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom tensorflow.keras.applications import VGG16\\nfrom tensorflow.keras.models import Model\\n\\n# Thread-safe queue for handling video frames\\nframe_queue = queue.Queue()\\n\\n# Function to process video frames\\ndef process_frames(stream_id):\\n    while True:\\n        frame = frame_queue.get()\\n        # Process frame here\\n        # ...\\n        frame_queue.task_done()\\n\\n# Load pre-trained CNN model\\nbase_model = VGG16(weights='imagenet', include_top=False)\\n\\n# Define metaprogramming function for dynamic model loading and inference\\ndef load_and_infer(model_path):\\n    # Load custom model\\n    custom_model = load_model(model_path)\\n\\n    # Create a new model with the custom layers\\n    input_tensor = base_model.input\\n    output_tensor = custom_model(base_model.output)\\n    new_model = Model(inputs=input_tensor, outputs=output_tensor)\\n\\n    return new_model\\n\\n# Assign each video s...</td>\n",
       "      <td>&lt;string&gt;:3:1: 'numpy as np' imported but unused\\n&lt;string&gt;:4:1: 'sklearn.preprocessing.StandardScaler' imported but unused\\n&lt;string&gt;:14:9: local variable 'frame' is assigned to but never used\\n&lt;string&gt;:25:20: undefined name 'load_model'\\n&lt;string&gt;:51:23: undefined name 'preprocess_frame'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>import requests\\nimport pandas as pd\\nimport concurrent.futures\\n\\n# Function to monitor network traffic\\ndef monitor_traffic(url):\\n    response = requests.get(url)\\n    return response.status_code, url\\n\\n# Function to analyze network traffic data\\ndef analyze_traffic(data):\\n    df = pd.DataFrame(data, columns=['Status Code', 'URL'])\\n\\n    # Perform analysis using pandas\\n    # ...\\n\\n    # Return results\\n    return df\\n\\n# List of URLs to monitor\\nurls = ['https://example.com', 'https://example.org', 'https://example.net']\\n\\n# Use concurrent.futures to monitor network traffic concurrently\\nwith concurrent.futures.ThreadPoolExecutor() as executor:\\n    results = executor.map(monitor_traffic, urls)\\n\\n# Analyze the traffic data\\ndf = analyze_traffic(results)\\n\\n# Generate report\\nreport = df.to_string(index=False)\\nprint(report)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>import pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import classification_report\\n\\n# Load the healthcare data\\ndata = pd.read_csv('healthcare_data.csv')\\n\\n# Preprocessing function\\ndef preprocess_data(patient):\\n    # Data preprocessing steps\\n    # ...\\n    return processed_patient\\n\\n# Feature extraction function\\ndef extract_features(patient):\\n    # Feature extraction steps\\n    # ...\\n    return features\\n\\n# Model training function\\ndef train_model(features):\\n    # Model training steps\\n    # ...\\n    return model\\n\\n# Analyze results function\\ndef analyze_results(models):\\n    # Analyze results steps\\n    # ...\\n    return report\\n\\n# Process the data in parallel\\nprocessed_data = Parallel(n_jobs=-1)(delayed(preprocess_data)(patient) for _, patient in data.iterrows())\\n\\nfeatures = Parallel(n_jobs=-1)(delayed(extract_features)(patient) for pat...</td>\n",
       "      <td>&lt;string&gt;:3:1: 'sklearn.preprocessing.StandardScaler' imported but unused\\n&lt;string&gt;:4:1: 'sklearn.ensemble.RandomForestClassifier' imported but unused\\n&lt;string&gt;:5:1: 'sklearn.metrics.classification_report' imported but unused\\n&lt;string&gt;:14:12: undefined name 'processed_patient'\\n&lt;string&gt;:26:12: undefined name 'model'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>import multiprocessing as mp\\nimport numpy as np\\nimport sklearn.decomposition as skd\\nfrom sklearn.preprocessing import StandardScaler\\n\\ndef process_image(image):\\n    # Some image processing tasks like filtering, segmentation, or feature extraction\\n    # ...\\n    return processed_image\\n\\ndef apply_pca(image):\\n    flattened_image = image.flatten()\\n    pca = skd.PCA(n_components=2)\\n    pca.fit(flattened_image)\\n    return pca.transform(flattened_image)\\n\\nif __name__ == \"__main__\":\\n    # Assume we have a list of medical images\\n    images = [np.random.rand(100, 100) for _ in range(100)]\\n\\n    # Standardize the images\\n    scaler = StandardScaler()\\n    images = scaler.fit_transform(images)\\n\\n    # Create a pool of processes\\n    pool = mp.Pool()\\n\\n    # Apply image processing and PCA in parallel\\n    processed_images = pool.map(process_image, images)\\n    pca_images = pool.map(apply_pca, processed_images)\\n\\n    # Close the pool and wait for all processes to finish\\n    p...</td>\n",
       "      <td>&lt;string&gt;:9:12: undefined name 'processed_image'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>import multiprocessing\\nimport numpy as np\\nimport logging\\n\\nlogging.basicConfig(filename='game_log.txt', level=logging.DEBUG)\\n\\ndef game_instance(params):\\n    try:\\n        # Your game logic here\\n        # Use params to dynamically generate game instance\\n        logging.info(f'Game instance with params {params} started.')\\n\\n        # Simulate game instance\\n        # ...\\n\\n        logging.info(f'Game instance with params {params} completed successfully.')\\n    except Exception as e:\\n        logging.error(f'Game instance with params {params} failed with error: {str(e)}')\\n\\ndef run_game_instances(params_list):\\n    with multiprocessing.Pool() as pool:\\n        pool.map(game_instance, params_list)\\n\\n# Generate parameters for game instances\\nparams_list = [np.random.rand(10) for _ in range(100)]\\n\\nrun_game_instances(params_list)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load tax laws and regulations\\ntax_laws = pd.read_csv('tax_laws.csv')\\n\\n# Define a function to process a single tax scenario\\ndef process_tax_scenario(scenario):\\n    # Calculate tax planning strategy\\n    # ...\\n\\n    return result\\n\\n# Define a function to process multiple tax scenarios concurrently\\ndef process_tax_scenarios(scenarios):\\n    results = []\\n\\n    with ThreadPoolExecutor(max_workers=4) as executor:\\n        future_results = {executor.submit(process_tax_scenario, scenario): scenario for scenario in scenarios}\\n\\n        for future in concurrent.futures.as_completed(future_results):\\n            scenario = future_results[future]\\n\\n            try:\\n                result = future.result()\\n                results.append(result)\\n            except Exception as e:\\n                print(f'Exception occurred while processing tax scenario: {e}')\\n\\n    return results\\n\\n# L...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'numpy as np' imported but unused\\n&lt;string&gt;:13:12: undefined name 'result'\\n&lt;string&gt;:22:23: undefined name 'concurrent'\\n&lt;string&gt;:23:13: local variable 'scenario' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>import threading\\nimport queue\\nimport time\\nimport numpy as np\\nfrom sklearn import linear_model\\n\\n# Define a worker function that processes incoming data from vehicle sensors\\ndef process_data(q):\\n    while True:\\n        data = q.get()\\n        # Perform data processing here\\n        time.sleep(1)\\n        q.task_done()\\n\\n# Define a metaprogramming function that dynamically adapts to different vehicle models\\ndef adapt_to_model(model):\\n    # Use metaprogramming techniques here to dynamically adapt to the vehicle model\\n    regressor = linear_model.LinearRegression()\\n    # Train the regressor with data specific to the vehicle model\\n    # ...\\n    return regressor\\n\\n# Create a queue to hold incoming data from vehicle sensors\\nq = queue.Queue()\\n\\n# Create multiple worker threads to process incoming data in parallel\\nfor i in range(5):\\n    t = threading.Thread(target=process_data, args=(q,))\\n    t.daemon = True\\n    t.start()\\n\\n# Simulate incoming data from vehicle sensor...</td>\n",
       "      <td>&lt;string&gt;:10:9: local variable 'data' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>import concurrent.futures\\nimport pandas as pd\\nimport requests\\n\\n# Define loan application data\\nloan_applications = [\\n    {\"loan_type\": \"home_loan\", \"amount\": 200000, \"term\": 30},\\n    {\"loan_type\": \"auto_loan\", \"amount\": 30000, \"term\": 60},\\n    {\"loan_type\": \"personal_loan\", \"amount\": 5000, \"term\": 12},\\n]\\n\\n# Define function to process loan application\\ndef process_loan(loan):\\n    try:\\n        # Simulate API call to get loan details\\n        response = requests.get(f\"https://api.financial_services.com/loans/{loan['loan_type']}?amount={loan['amount']}&amp;term={loan['term']}\")\\n        loan_details = response.json()\\n\\n        # Simulate processing the loan application\\n        # ...\\n\\n        # Return processed loan data\\n        return {\\n            \"loan_type\": loan[\"loan_type\"],\\n            \"amount\": loan[\"amount\"],\\n            \"term\": loan[\"term\"],\\n            \"status\": \"approved\",\\n            \"details\": loan_details,\\n        }\\n    except Exception as e:\\n        ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>import cv2\\nimport numpy as np\\nfrom multiprocessing import Pool\\nimport concurrent.futures\\nfrom functools import partial\\n\\n# Load the YOLO model\\nnet = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\\n\\n# Define the function to process a single frame\\ndef process_frame(frame):\\n    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0, 0, 0), True, crop=False)\\n    net.setInput(blob)\\n    outs = net.forward(net.getUnconnectedOutLayersNames())\\n    # Post-process the output and draw bounding boxes on the frame\\n    # ...\\n\\n# Capture video from webcam\\ncap = cv2.VideoCapture(0)\\n\\n# Create a pool of processes\\nwith Pool(processes=4) as pool:\\n    while True:\\n        ret, frame = cap.read()\\n        if not ret:\\n            break\\n\\n        # Submit the frame for processing to the pool\\n        pool.apply_async(process_frame, (frame,))\\n\\n# Release resources\\ncap.release()\\ncv2.destroyAllWindows()</td>\n",
       "      <td>&lt;string&gt;:2:1: 'numpy as np' imported but unused\\n&lt;string&gt;:4:1: 'concurrent.futures' imported but unused\\n&lt;string&gt;:5:1: 'functools.partial' imported but unused\\n&lt;string&gt;:14:5: local variable 'outs' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>import random\\nimport threading\\nimport numpy as np\\nimport tensorflow as tf\\n\\nclass Game:\\n    def __init__(self):\\n        self.players = []\\n        self.levels = []\\n\\n    def add_player(self, player):\\n        self.players.append(player)\\n\\n    def generate_level(self):\\n        levels = ['Easy', 'Medium', 'Hard']\\n        level = random.choice(levels)\\n        self.levels.append(level)\\n        return level\\n\\nclass Player(threading.Thread):\\n    def __init__(self, game):\\n        threading.Thread.__init__(self)\\n        self.game = game\\n\\n    def run(self):\\n        level = self.game.generate_level()\\n        print(f\"Player {self.name} is playing on level: {level}\")\\n\\n        # Simulate player's actions within the level\\n        # ...\\n\\n        # Update game state based on player's actions\\n        # ...\\n\\n# Create game object\\ngame = Game()\\n\\n# Add players to the game\\nfor i in range(10):\\n    player = Player(game)\\n    player.start()\\n    game.add_player(player)\\n\\n#...</td>\n",
       "      <td>&lt;string&gt;:3:1: 'numpy as np' imported but unused\\n&lt;string&gt;:4:1: 'tensorflow as tf' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>import pandas as pd\\n\\nclass Patient:\\n    def __init__(self, age, gender, medical_history, current_symptoms, lab_test_results):\\n        self.age = age\\n        self.gender = gender\\n        self.medical_history = medical_history\\n        self.current_symptoms = current_symptoms\\n        self.lab_test_results = lab_test_results\\n\\nclass DecisionSupportEngine:\\n    def __init__(self, patient):\\n        self.patient = patient\\n\\n    def analyze_patient_data(self):\\n        try:\\n            patient_df = pd.DataFrame([self.patient.__dict__])\\n            # Perform analysis on patient_df\\n            # ...\\n            return \"Treatment Recommendation\"\\n        except Exception as e:\\n            return str(e)</td>\n",
       "      <td>&lt;string&gt;:17:13: local variable 'patient_df' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>import pandas as pd\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Data Ingestion\\ndef fetch_data(sources):\\n    data = pd.DataFrame()\\n    for source in sources:\\n        if source.endswith('.csv'):\\n            data = data.append(pd.read_csv(source))\\n        else:\\n            data = data.append(pd.read_sql_query('SELECT * FROM customers', source))\\n    return data\\n\\n# Data Preprocessing\\ndef preprocess_data(data):\\n    # Clean and transform data\\n    # ...\\n\\n    # Normalize data\\n    scaler = StandardScaler()\\n    normalized_data = scaler.fit_transform(data)\\n    return normalized_data\\n\\n# Feature Engineering\\ndef generate_features(data):\\n    # Generate relevant features\\n    # ...\\n    return features\\n\\n# Segmentation\\ndef perform_segmentation(features, num_clusters):\\n    kmeans = KMeans(n_clusters=num_clusters)\\n    kmeans.fit(features)\\n    return kmeans.labels_\\n\\n# Metaprogramming\\ndef configure_pipeline(config):\\n    sourc...</td>\n",
       "      <td>&lt;string&gt;:29:12: undefined name 'features'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>import pandas as pd\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load student performance metrics, learning styles, and curriculum details from CSV files\\nstudent_data = pd.read_csv('student_data.csv')\\nlearning_styles = pd.read_csv('learning_styles.csv')\\ncurriculum = pd.read_csv('curriculum.csv')\\n\\n# Define a function to generate a personalized learning path for a student\\ndef generate_learning_path(student):\\n    # Perform some processing on the student data, learning styles, and curriculum details\\n    # ...\\n\\n    # Generate the learning path based on the processed data\\n    learning_path = []\\n    # ...\\n\\n    return learning_path\\n\\n# Define a function to generate learning paths for all students using concurrency\\ndef generate_all_learning_paths(students):\\n    learning_paths = []\\n\\n    with ThreadPoolExecutor() as executor:\\n        # Use the executor.map function to apply the generate_learning_path function to all students concurrently\\n        learning_paths ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>import concurrent.futures\\nimport requests\\nimport pandas as pd\\nfrom sklearn.ensemble import IsolationForest\\n\\n# Sample user credentials\\ncredentials = {\\n    \"user1\": \"pass1\",\\n    \"user2\": \"pass2\",\\n    # ...\\n}\\n\\n# Security policies\\nsecurity_policies = {\\n    \"failed_attempts_threshold\": 3,\\n    \"lockout_duration\": 10,  # minutes\\n    # ...\\n}\\n\\n# User session management\\nuser_sessions = {}\\n\\n# Brute force detection\\ndef detect_brute_force(user):\\n    # Fetch authentication attempts from a database or log file\\n    attempts = pd.read_csv(\"attempts.csv\")\\n    failed_attempts = attempts[attempts[\"user\"] == user][\"status\"] == \"failed\"\\n\\n    if len(failed_attempts) &gt; security_policies[\"failed_attempts_threshold\"]:\\n        return True\\n    else:\\n        return False\\n\\n# Authenticate user\\ndef authenticate(user, password):\\n    if credentials[user] == password:\\n        # Check for brute force attacks\\n        if detect_brute_force(user):\\n            return False\\n        e...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'requests' imported but unused\\n&lt;string&gt;:4:1: 'sklearn.ensemble.IsolationForest' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nimport concurrent.futures\\nimport requests\\n\\n# Sample data of banking transactions\\ntransactions = [\\n    {\"transaction_id\": 1, \"account_id\": 1001, \"amount\": 5000},\\n    {\"transaction_id\": 2, \"account_id\": 1002, \"amount\": 3000},\\n    {\"transaction_id\": 3, \"account_id\": 1003, \"amount\": 2000},\\n    # ... more transactions\\n]\\n\\ndef process_transaction(transaction):\\n    try:\\n        # Simulate network connectivity delay\\n        response = requests.get(\"https://api.bank.com/process_transaction\", params=transaction)\\n        if response.status_code == 200:\\n            return f\"Transaction {transaction['transaction_id']} processed successfully\"\\n        else:\\n            return f\"Error processing transaction {transaction['transaction_id']}\"\\n    except Exception as e:\\n        return f\"Error processing transaction {transaction['transaction_id']}: {str(e)}\"\\n\\ndef process_transactions_concurrently(transactions):\\n    results = []\\n    with co...</td>\n",
       "      <td>&lt;string&gt;:1:1: 'pandas as pd' imported but unused\\n&lt;string&gt;:2:1: 'numpy as np' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>import pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load dataset\\ndf = pd.read_csv('patient_records.csv')\\n\\n# Define function for parallel processing\\ndef analyze_data(patient_data):\\n    # Analyze data and identify patterns or anomalies\\n    # ...\\n\\n    return results\\n\\n# Create a ThreadPoolExecutor\\nwith ThreadPoolExecutor() as executor:\\n    # Submit tasks to the executor\\n    futures = [executor.submit(analyze_data, data) for _, data in df.iterrows()]\\n\\n    # Get the results\\n    results = [future.result() for future in futures]\\n\\n# Create a heatmap using seaborn\\nsns.heatmap(pd.DataFrame(results).corr(), annot=True)\\n\\n# Save the plot\\nplt.savefig('patterns.png')</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Sure, here's some sample code that demonstrates the use of concurrency, parallel processing, and metaprogramming techniques to optimize the performance of a medication management system. This code uses the `multiprocessing` module to create a parallel processing pipeline that can handle large-scale medication data from different data sources. It also uses the `pandas` library to manipulate and analyze the data, and the `numpy` library to perform numerical operations on the data.\\n```\\nimport multiprocessing as mp\\nimport pandas as pd\\nimport numpy as np\\n\\n# Define a function to process data from a single data source\\ndef process_data(data):\\n    # Perform some data processing operations here\\n    # ...\\n    return processed_data\\n\\n# Define a function to handle data from multiple data sources\\ndef handle_data(sources):\\n    # Create a pool of worker processes\\n    pool = mp.Pool(processes=mp.cpu_count())\\n\\n    # Process data from each source in parallel\\n    processed_data = pool...</td>\n",
       "      <td>&lt;string&gt;:1:484: EOL while scanning string literal\\nSure, here's some sample code that demonstrates the use of concurrency, parallel processing, and metaprogramming techniques to optimize the performance of a medication management system. This code uses the `multiprocessing` module to create a parallel processing pipeline that can handle large-scale medication data from different data sources. It also uses the `pandas` library to manipulate and analyze the data, and the `numpy` library to perform numerical operations on the data.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>import concurrent.futures\\nimport pandas as pd\\nimport numpy as np\\nimport scikit_learn as sklearn\\nimport re\\n\\n# Function to parse log files\\ndef parse_log_file(file_path):\\n    log_data = []\\n    with open(file_path, 'r') as file:\\n        for line in file:\\n            log_entry = re.split(r'\\s+', line)\\n            log_data.append(log_entry)\\n    return log_data\\n\\n# Function to perform pattern matching and anomaly detection\\ndef detect_anomalies(log_data):\\n    # Implement pattern matching and anomaly detection algorithms here\\n    # ...\\n\\n    return anomalies\\n\\n# Function to create alert for potential security incidents\\ndef create_alert(anomaly):\\n    # Implement alerting system here\\n    # ...\\n\\n    return alert\\n\\n# Function to process log files concurrently\\ndef process_log_files(file_paths):\\n    with concurrent.futures.ThreadPoolExecutor() as executor:\\n        futures = [executor.submit(parse_log_file, file_path) for file_path in file_paths]\\n        log_data = [fu...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'pandas as pd' imported but unused\\n&lt;string&gt;:3:1: 'numpy as np' imported but unused\\n&lt;string&gt;:4:1: 'scikit_learn as sklearn' imported but unused\\n&lt;string&gt;:21:12: undefined name 'anomalies'\\n&lt;string&gt;:28:12: undefined name 'alert'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>import pandas as pd\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.metrics.pairwise import linear_kernel\\nfrom multiprocessing import Pool\\n\\n# Load user behavior data\\nuser_data = pd.read_csv('user_behavior.csv')\\n\\n# Function to recommend products based on user behavior\\ndef recommend_products(user):\\n    tfidf = TfidfVectorizer(stop_words='english')\\n    tfidf_matrix = tfidf.fit_transform(user['product_description'])\\n    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\\n    # ... (rest of the recommendation logic)\\n    return recommended_products\\n\\n# Parallel processing to recommend products for all users\\nwith Pool() as p:\\n    recommendations = p.map(recommend_products, user_data['user_id'])\\n\\n# Save recommendations to a file\\npd.DataFrame(recommendations).to_csv('recommendations.csv', index=False)</td>\n",
       "      <td>&lt;string&gt;:13:5: local variable 'cosine_sim' is assigned to but never used\\n&lt;string&gt;:15:12: undefined name 'recommended_products'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>import asyncio\\nimport pandas as pd\\nfrom scipy.stats import norm\\n\\n# Simulated VoIP call data\\ncalls = [\\n    {\"call_id\": 1, \"latency\": 50, \"jitter\": 10, \"packet_loss\": 0.5},\\n    {\"call_id\": 2, \"latency\": 45, \"jitter\": 8, \"packet_loss\": 0.3},\\n    # ... more call data ...\\n]\\n\\n# Define SLAs\\nslas = {\\n    \"latency\": {\"mean\": 50, \"std_dev\": 10},\\n    \"jitter\": {\"mean\": 8, \"std_dev\": 2},\\n    \"packet_loss\": {\"mean\": 0.1, \"std_dev\": 0.05},\\n}\\n\\nasync def process_call(call):\\n    # Calculate metrics\\n    latency_anomaly = abs(call[\"latency\"] - slas[\"latency\"][\"mean\"]) &gt; slas[\"latency\"][\"std_dev\"]\\n    jitter_anomaly = abs(call[\"jitter\"] - slas[\"jitter\"][\"mean\"]) &gt; slas[\"jitter\"][\"std_dev\"]\\n    packet_loss_anomaly = abs(call[\"packet_loss\"] - slas[\"packet_loss\"][\"mean\"]) &gt; slas[\"packet_loss\"][\"std_dev\"]\\n\\n    # Generate alert if any anomaly detected\\n    if latency_anomaly or jitter_anomaly or packet_loss_anomaly:\\n        print(f\"Alert: Anomaly detected in call {call['call_id']}\"...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'pandas as pd' imported but unused\\n&lt;string&gt;:3:1: 'scipy.stats.norm' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>import multiprocessing as mp\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\ndef process_data(data):\\n    # Preprocessing steps\\n    # ...\\n    return processed_data\\n\\ndef train_model(data):\\n    X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\\n    model.fit(X_train, y_train)\\n    return model\\n\\ndef main():\\n    # Load data\\n    data = pd.read_csv('financial_data.csv')\\n\\n    # Create a pool of processes\\n    with mp.Pool(processes=mp.cpu_count()) as pool:\\n        # Process data in parallel\\n        processed_data = pool.map(process_data, np.array_split(data, mp.cpu_count()))\\n\\n        # Train models in parallel\\n        models = pool.map(train_model, processed_data)\\n\\nif __name__ == '__main__':\\n    main()</td>\n",
       "      <td>&lt;string&gt;:10:12: undefined name 'processed_data'\\n&lt;string&gt;:28:9: local variable 'models' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>import re\\nimport requests\\nfrom Crypto.Cipher import AES\\n\\nclass InvalidURLException(Exception):\\n    pass\\n\\nclass SecurityScanner:\\n    def __init__(self, target_url):\\n        self.target_url = target_url\\n\\n    def validate_url(self):\\n        pattern = re.compile(\\n            r'^(?:http|ftp)s?://'  # http:// or https://\\n            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\\n            r'localhost|'  # localhost...\\n            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  # ...or ip\\n            r'(?::\\d+)?'  # optional port\\n            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\\n        if not re.match(pattern, self.target_url):\\n            raise InvalidURLException(\"Invalid URL\")\\n\\n    def find_vulnerabilities(self):\\n        vulnerabilities = []\\n        # Code to scan for vulnerabilities goes here\\n        # For demonstration, let's assume we found some vulnerabilities\\n        vulnerabilities.append(\"SQL Injection\")\\n     ...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'requests' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nfrom multiprocessing import Pool\\n\\n# Simulated signal processing function\\ndef process_signal(signal):\\n    # Perform signal processing operations here\\n    # ...\\n    # Calculate signal strength, frequency, and duration\\n    signal_strength = np.random.uniform(0, 1)\\n    frequency = np.random.uniform(1e9, 2e9)\\n    duration = np.random.uniform(1, 10)\\n    return signal_strength, frequency, duration\\n\\n# Generate a large number of signals\\nsignals = [{'id': i} for i in range(10000)]\\n\\n# Create a pool of processes\\nwith Pool() as pool:\\n    # Process the signals in parallel\\n    results = pool.map(process_signal, signals)\\n\\n# Convert results to a pandas DataFrame\\ndf = pd.DataFrame(results, columns=['signal_strength', 'frequency', 'duration'])\\n\\n# Perform analytics on the processed signals\\n# ...\\n# Output detailed analytics\\nprint(df.describe())</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>import pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Load customer data\\ncustomer_data = pd.read_csv('customer_data.csv')\\n\\n# Preprocess data\\nscaler = StandardScaler()\\ncustomer_data_scaled = scaler.fit_transform(customer_data)\\n\\n# Define CLV calculation function\\ndef calculate_clv(customer):\\n    # Calculate CLV based on historical purchases, average order value, and purchase frequency\\n    # Include predicted future behavior and potential churn rate\\n    # Return CLV value\\n    pass\\n\\n# Parallel processing to calculate CLV for each customer\\nclv_values = Parallel(n_jobs=-1)(delayed(calculate_clv)(customer) for _, customer in customer_data_scaled.iterrows())\\n\\n# Store CLV values in a new column in the dataframe\\ncustomer_data['CLV'] = clv_values\\n\\n# Generate insights and trends report\\n# ...</td>\n",
       "      <td>&lt;string&gt;:3:1: 'sklearn.ensemble.RandomForestRegressor' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>import numpy as np\\nimport multiprocessing as mp\\n\\n# Define the control algorithm\\ndef control_algorithm(sensor_data, control_signals):\\n    # Perform some calculations on the sensor data and control signals\\n    # ...\\n\\n    # Dynamically adjust the control algorithm based on the vehicle's current state\\n    state = np.random.choice(['accelerating', 'cruising', 'braking'])\\n    if state == 'accelerating':\\n        # Adjust the control algorithm for accelerating state\\n        # ...\\n        pass\\n    elif state == 'cruising':\\n        # Adjust the control algorithm for cruising state\\n        # ...\\n        pass\\n    elif state == 'braking':\\n        # Adjust the control algorithm for braking state\\n        # ...\\n        pass\\n\\n    # Return the control signals\\n    return control_signals\\n\\n# Define the parallel processing function\\ndef process_data(sensor_data, control_signals):\\n    # Process the sensor data and control signals concurrently\\n    with mp.Pool() as pool:\\n     ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom concurrent.futures import ThreadPoolExecutor\\nimport matplotlib.pyplot as plt\\n\\n# Function to process student data and generate personalized learning paths\\ndef process_student_data(student_data):\\n    # Preprocess data, analyze strengths and weaknesses, and generate personalized learning paths\\n    # This is a placeholder function, replace with actual implementation\\n    personalized_paths = {}\\n    # ...\\n    return personalized_paths\\n\\n# Function to train and test a machine learning model for predicting student performance\\ndef train_and_test_model(student_data):\\n    # Split data into features and target\\n    X = student_data.drop('target', axis=1)\\n    y = student_data['target']\\n\\n    # Split data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_sp...</td>\n",
       "      <td>&lt;string&gt;:1:1: 'pandas as pd' imported but unused\\n&lt;string&gt;:2:1: 'numpy as np' imported but unused\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        code  \\\n",
       "15   import threading\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Function to process user sessions in parallel\\ndef process_session(session):\\n    # Analyze user behavior in real-time\\n    user_behavior = analyze_user_behavior(session)\\n\\n    # Detect signs of potential cart abandonment\\n    is_abandonment = detect_abandonment(user_behavior)\\n\\n    if is_abandonment:\\n        # Trigger appropriate interventions (e.g., sending a reminder email or push notification)\\n        trigger_intervention(session)\\n\\n# Function to analyze user behavior in real-time\\ndef analyze_user_behavior(session):\\n    # Implement logic to analyze user behavior\\n    # ...\\n\\n    return user_behavior\\n\\n# Function to detect signs of potential cart abandonment\\ndef detect_abandonment(user_behavior):\\n    # Implement logic to detect signs of potential cart abandonment\\n    # ...\\n\\n    return is_abandonment\\n\\n# Function to trigger appropriate interventions (e.g., sending a remi...   \n",
       "26   import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nfrom multiprocessing import Pool\\n\\n# Preprocess the data\\ndef preprocess_data(data):\\n    # Perform data cleaning, feature engineering, and transformation\\n    # ...\\n\\n    return processed_data\\n\\n# Design a concurrent and parallel processing system\\ndef process_data_parallel(data_chunks):\\n    with Pool() as pool:\\n        processed_data = pool.map(preprocess_data, data_chunks)\\n\\n    return processed_data\\n\\n# Build the CLV prediction model\\ndef build_clv_model(processed_data):\\n    # Split the data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        processed_data.drop('CLV', axis=1),\\n        processed_data['CLV'],\\n        test_size=0.2,\\n        random_state=42\\n    )\\n\\n    # Train a random forest regression model\\n    model = RandomFor...   \n",
       "41   import concurrent.futures\\nimport requests\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import IsolationForest\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Define a list of network protocols\\nprotocols = ['http', 'https', 'ftp', 'ssh', 'smtp']\\n\\n# Define a function to analyze network traffic for a given protocol\\ndef analyze_traffic(protocol):\\n    # Fetch network traffic data for the given protocol\\n    data = requests.get(f'https://api.example.com/traffic/{protocol}').json()\\n\\n    # Preprocess the data\\n    df = pd.DataFrame(data)\\n    scaler = StandardScaler()\\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\\n\\n    # Detect anomalies using Isolation Forest\\n    clf = IsolationForest(contamination=0.01)\\n    preds = clf.fit_predict(df)\\n    anomalies = df[preds == -1]\\n\\n    # Mitigate the detected anomalies\\n    # ...\\n\\n    return anomalies\\n\\n# Create a thread pool executor\\nwith concurrent.futures.ThreadPoolExecutor() as exec...   \n",
       "69   import threading\\nimport queue\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport scipy.stats as stats\\n\\n# Define a worker function to process data streams\\ndef worker(data_queue):\\n    while True:\\n        data = data_queue.get()\\n        # Perform analytics on the data\\n        # ...\\n        # Update network settings based on analytics results\\n        # ...\\n        data_queue.task_done()\\n\\n# Create a queue to hold data streams\\ndata_queue = queue.Queue()\\n\\n# Create and start multiple worker threads\\nfor i in range(4):\\n    t = threading.Thread(target=worker, args=(data_queue,))\\n    t.start()\\n\\n# Generate and process synthetic data\\nfor _ in range(100):\\n    data = pd.DataFrame({'signal_strength': stats.norm.rvs(size=1000),\\n                         'latency': stats.uniform.rvs(size=1000),\\n                         'packet_loss': stats.binom.rvs(100, 0.05, size=1000)})\\n    data_queue.put(data)\\n\\n# Wait for all tasks in the queue to be processed\\ndata_queue.joi...   \n",
       "103  import numpy as np\\nimport pandas as pd\\nimport concurrent.futures\\nfrom scipy.optimize import minimize_scalar\\n\\n# Differential Privacy Mechanism: Laplace Mechanism\\ndef laplace_mechanism(data, epsilon):\\n    noise = np.random.laplace(0, 1 / epsilon, len(data))\\n    return data + noise\\n\\n# Process a subset of data\\ndef process_subset(subset, epsilon):\\n    # Add noise to the data\\n    noisy_data = laplace_mechanism(subset, epsilon)\\n    # Perform analytics or ML tasks on the noisy data\\n    # ...\\n    return result\\n\\n# Combine results while maintaining privacy\\ndef combine_results(results):\\n    # Perform post-processing on the results to ensure privacy\\n    # ...\\n    return combined_result\\n\\n# Main function to manage processes and combine results\\ndef main():\\n    # Read large dataset\\n    data = pd.read_csv('large_dataset.csv')\\n\\n    # Split data into subsets for parallel processing\\n    subsets = np.array_split(data, num_processes)\\n\\n    # Set epsilon value for differenti...   \n",
       "203  import asyncio\\nimport pandas as pd\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Simulated supplier data feeds\\nsupplier_data_feeds = {\\n    'Supplier1': 'data1.csv',\\n    'Supplier2': 'data2.csv',\\n    'Supplier3': 'data3.csv'\\n}\\n\\n# Function to process data from a supplier\\ndef process_supplier_data(supplier, file):\\n    data = pd.read_csv(file)\\n    # Process data (e.g., update inventory database)\\n    # ...\\n    return data\\n\\n# Function to handle real-time updates from suppliers\\nasync def handle_supplier_updates():\\n    with ThreadPoolExecutor(max_workers=3) as executor:\\n        tasks = {executor.submit(process_supplier_data, supplier, file): supplier for supplier, file in supplier_data_feeds.items()}\\n        for future in asyncio.as_completed(tasks):\\n            supplier = tasks[future]\\n            try:\\n                data = await future\\n                # Process data (e.g., update inventory database)\\n                # ...\\n            except Exception as...   \n",
       "219  import threading\\nimport queue\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom tensorflow.keras.applications import VGG16\\nfrom tensorflow.keras.models import Model\\n\\n# Thread-safe queue for handling video frames\\nframe_queue = queue.Queue()\\n\\n# Function to process video frames\\ndef process_frames(stream_id):\\n    while True:\\n        frame = frame_queue.get()\\n        # Process frame here\\n        # ...\\n        frame_queue.task_done()\\n\\n# Load pre-trained CNN model\\nbase_model = VGG16(weights='imagenet', include_top=False)\\n\\n# Define metaprogramming function for dynamic model loading and inference\\ndef load_and_infer(model_path):\\n    # Load custom model\\n    custom_model = load_model(model_path)\\n\\n    # Create a new model with the custom layers\\n    input_tensor = base_model.input\\n    output_tensor = custom_model(base_model.output)\\n    new_model = Model(inputs=input_tensor, outputs=output_tensor)\\n\\n    return new_model\\n\\n# Assign each video s...   \n",
       "261                                                                                                                                                            import requests\\nimport pandas as pd\\nimport concurrent.futures\\n\\n# Function to monitor network traffic\\ndef monitor_traffic(url):\\n    response = requests.get(url)\\n    return response.status_code, url\\n\\n# Function to analyze network traffic data\\ndef analyze_traffic(data):\\n    df = pd.DataFrame(data, columns=['Status Code', 'URL'])\\n\\n    # Perform analysis using pandas\\n    # ...\\n\\n    # Return results\\n    return df\\n\\n# List of URLs to monitor\\nurls = ['https://example.com', 'https://example.org', 'https://example.net']\\n\\n# Use concurrent.futures to monitor network traffic concurrently\\nwith concurrent.futures.ThreadPoolExecutor() as executor:\\n    results = executor.map(monitor_traffic, urls)\\n\\n# Analyze the traffic data\\ndf = analyze_traffic(results)\\n\\n# Generate report\\nreport = df.to_string(index=False)\\nprint(report)   \n",
       "270  import pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import classification_report\\n\\n# Load the healthcare data\\ndata = pd.read_csv('healthcare_data.csv')\\n\\n# Preprocessing function\\ndef preprocess_data(patient):\\n    # Data preprocessing steps\\n    # ...\\n    return processed_patient\\n\\n# Feature extraction function\\ndef extract_features(patient):\\n    # Feature extraction steps\\n    # ...\\n    return features\\n\\n# Model training function\\ndef train_model(features):\\n    # Model training steps\\n    # ...\\n    return model\\n\\n# Analyze results function\\ndef analyze_results(models):\\n    # Analyze results steps\\n    # ...\\n    return report\\n\\n# Process the data in parallel\\nprocessed_data = Parallel(n_jobs=-1)(delayed(preprocess_data)(patient) for _, patient in data.iterrows())\\n\\nfeatures = Parallel(n_jobs=-1)(delayed(extract_features)(patient) for pat...   \n",
       "333  import multiprocessing as mp\\nimport numpy as np\\nimport sklearn.decomposition as skd\\nfrom sklearn.preprocessing import StandardScaler\\n\\ndef process_image(image):\\n    # Some image processing tasks like filtering, segmentation, or feature extraction\\n    # ...\\n    return processed_image\\n\\ndef apply_pca(image):\\n    flattened_image = image.flatten()\\n    pca = skd.PCA(n_components=2)\\n    pca.fit(flattened_image)\\n    return pca.transform(flattened_image)\\n\\nif __name__ == \"__main__\":\\n    # Assume we have a list of medical images\\n    images = [np.random.rand(100, 100) for _ in range(100)]\\n\\n    # Standardize the images\\n    scaler = StandardScaler()\\n    images = scaler.fit_transform(images)\\n\\n    # Create a pool of processes\\n    pool = mp.Pool()\\n\\n    # Apply image processing and PCA in parallel\\n    processed_images = pool.map(process_image, images)\\n    pca_images = pool.map(apply_pca, processed_images)\\n\\n    # Close the pool and wait for all processes to finish\\n    p...   \n",
       "349                                                                                                                                                         import multiprocessing\\nimport numpy as np\\nimport logging\\n\\nlogging.basicConfig(filename='game_log.txt', level=logging.DEBUG)\\n\\ndef game_instance(params):\\n    try:\\n        # Your game logic here\\n        # Use params to dynamically generate game instance\\n        logging.info(f'Game instance with params {params} started.')\\n\\n        # Simulate game instance\\n        # ...\\n\\n        logging.info(f'Game instance with params {params} completed successfully.')\\n    except Exception as e:\\n        logging.error(f'Game instance with params {params} failed with error: {str(e)}')\\n\\ndef run_game_instances(params_list):\\n    with multiprocessing.Pool() as pool:\\n        pool.map(game_instance, params_list)\\n\\n# Generate parameters for game instances\\nparams_list = [np.random.rand(10) for _ in range(100)]\\n\\nrun_game_instances(params_list)   \n",
       "373  import pandas as pd\\nimport numpy as np\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load tax laws and regulations\\ntax_laws = pd.read_csv('tax_laws.csv')\\n\\n# Define a function to process a single tax scenario\\ndef process_tax_scenario(scenario):\\n    # Calculate tax planning strategy\\n    # ...\\n\\n    return result\\n\\n# Define a function to process multiple tax scenarios concurrently\\ndef process_tax_scenarios(scenarios):\\n    results = []\\n\\n    with ThreadPoolExecutor(max_workers=4) as executor:\\n        future_results = {executor.submit(process_tax_scenario, scenario): scenario for scenario in scenarios}\\n\\n        for future in concurrent.futures.as_completed(future_results):\\n            scenario = future_results[future]\\n\\n            try:\\n                result = future.result()\\n                results.append(result)\\n            except Exception as e:\\n                print(f'Exception occurred while processing tax scenario: {e}')\\n\\n    return results\\n\\n# L...   \n",
       "377  import threading\\nimport queue\\nimport time\\nimport numpy as np\\nfrom sklearn import linear_model\\n\\n# Define a worker function that processes incoming data from vehicle sensors\\ndef process_data(q):\\n    while True:\\n        data = q.get()\\n        # Perform data processing here\\n        time.sleep(1)\\n        q.task_done()\\n\\n# Define a metaprogramming function that dynamically adapts to different vehicle models\\ndef adapt_to_model(model):\\n    # Use metaprogramming techniques here to dynamically adapt to the vehicle model\\n    regressor = linear_model.LinearRegression()\\n    # Train the regressor with data specific to the vehicle model\\n    # ...\\n    return regressor\\n\\n# Create a queue to hold incoming data from vehicle sensors\\nq = queue.Queue()\\n\\n# Create multiple worker threads to process incoming data in parallel\\nfor i in range(5):\\n    t = threading.Thread(target=process_data, args=(q,))\\n    t.daemon = True\\n    t.start()\\n\\n# Simulate incoming data from vehicle sensor...   \n",
       "378  import concurrent.futures\\nimport pandas as pd\\nimport requests\\n\\n# Define loan application data\\nloan_applications = [\\n    {\"loan_type\": \"home_loan\", \"amount\": 200000, \"term\": 30},\\n    {\"loan_type\": \"auto_loan\", \"amount\": 30000, \"term\": 60},\\n    {\"loan_type\": \"personal_loan\", \"amount\": 5000, \"term\": 12},\\n]\\n\\n# Define function to process loan application\\ndef process_loan(loan):\\n    try:\\n        # Simulate API call to get loan details\\n        response = requests.get(f\"https://api.financial_services.com/loans/{loan['loan_type']}?amount={loan['amount']}&term={loan['term']}\")\\n        loan_details = response.json()\\n\\n        # Simulate processing the loan application\\n        # ...\\n\\n        # Return processed loan data\\n        return {\\n            \"loan_type\": loan[\"loan_type\"],\\n            \"amount\": loan[\"amount\"],\\n            \"term\": loan[\"term\"],\\n            \"status\": \"approved\",\\n            \"details\": loan_details,\\n        }\\n    except Exception as e:\\n        ...   \n",
       "394                                                                                     import cv2\\nimport numpy as np\\nfrom multiprocessing import Pool\\nimport concurrent.futures\\nfrom functools import partial\\n\\n# Load the YOLO model\\nnet = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\\n\\n# Define the function to process a single frame\\ndef process_frame(frame):\\n    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0, 0, 0), True, crop=False)\\n    net.setInput(blob)\\n    outs = net.forward(net.getUnconnectedOutLayersNames())\\n    # Post-process the output and draw bounding boxes on the frame\\n    # ...\\n\\n# Capture video from webcam\\ncap = cv2.VideoCapture(0)\\n\\n# Create a pool of processes\\nwith Pool(processes=4) as pool:\\n    while True:\\n        ret, frame = cap.read()\\n        if not ret:\\n            break\\n\\n        # Submit the frame for processing to the pool\\n        pool.apply_async(process_frame, (frame,))\\n\\n# Release resources\\ncap.release()\\ncv2.destroyAllWindows()   \n",
       "402  import random\\nimport threading\\nimport numpy as np\\nimport tensorflow as tf\\n\\nclass Game:\\n    def __init__(self):\\n        self.players = []\\n        self.levels = []\\n\\n    def add_player(self, player):\\n        self.players.append(player)\\n\\n    def generate_level(self):\\n        levels = ['Easy', 'Medium', 'Hard']\\n        level = random.choice(levels)\\n        self.levels.append(level)\\n        return level\\n\\nclass Player(threading.Thread):\\n    def __init__(self, game):\\n        threading.Thread.__init__(self)\\n        self.game = game\\n\\n    def run(self):\\n        level = self.game.generate_level()\\n        print(f\"Player {self.name} is playing on level: {level}\")\\n\\n        # Simulate player's actions within the level\\n        # ...\\n\\n        # Update game state based on player's actions\\n        # ...\\n\\n# Create game object\\ngame = Game()\\n\\n# Add players to the game\\nfor i in range(10):\\n    player = Player(game)\\n    player.start()\\n    game.add_player(player)\\n\\n#...   \n",
       "431                                                                                                                                                                                                                                                                                             import pandas as pd\\n\\nclass Patient:\\n    def __init__(self, age, gender, medical_history, current_symptoms, lab_test_results):\\n        self.age = age\\n        self.gender = gender\\n        self.medical_history = medical_history\\n        self.current_symptoms = current_symptoms\\n        self.lab_test_results = lab_test_results\\n\\nclass DecisionSupportEngine:\\n    def __init__(self, patient):\\n        self.patient = patient\\n\\n    def analyze_patient_data(self):\\n        try:\\n            patient_df = pd.DataFrame([self.patient.__dict__])\\n            # Perform analysis on patient_df\\n            # ...\\n            return \"Treatment Recommendation\"\\n        except Exception as e:\\n            return str(e)   \n",
       "453  import pandas as pd\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Data Ingestion\\ndef fetch_data(sources):\\n    data = pd.DataFrame()\\n    for source in sources:\\n        if source.endswith('.csv'):\\n            data = data.append(pd.read_csv(source))\\n        else:\\n            data = data.append(pd.read_sql_query('SELECT * FROM customers', source))\\n    return data\\n\\n# Data Preprocessing\\ndef preprocess_data(data):\\n    # Clean and transform data\\n    # ...\\n\\n    # Normalize data\\n    scaler = StandardScaler()\\n    normalized_data = scaler.fit_transform(data)\\n    return normalized_data\\n\\n# Feature Engineering\\ndef generate_features(data):\\n    # Generate relevant features\\n    # ...\\n    return features\\n\\n# Segmentation\\ndef perform_segmentation(features, num_clusters):\\n    kmeans = KMeans(n_clusters=num_clusters)\\n    kmeans.fit(features)\\n    return kmeans.labels_\\n\\n# Metaprogramming\\ndef configure_pipeline(config):\\n    sourc...   \n",
       "461  import pandas as pd\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load student performance metrics, learning styles, and curriculum details from CSV files\\nstudent_data = pd.read_csv('student_data.csv')\\nlearning_styles = pd.read_csv('learning_styles.csv')\\ncurriculum = pd.read_csv('curriculum.csv')\\n\\n# Define a function to generate a personalized learning path for a student\\ndef generate_learning_path(student):\\n    # Perform some processing on the student data, learning styles, and curriculum details\\n    # ...\\n\\n    # Generate the learning path based on the processed data\\n    learning_path = []\\n    # ...\\n\\n    return learning_path\\n\\n# Define a function to generate learning paths for all students using concurrency\\ndef generate_all_learning_paths(students):\\n    learning_paths = []\\n\\n    with ThreadPoolExecutor() as executor:\\n        # Use the executor.map function to apply the generate_learning_path function to all students concurrently\\n        learning_paths ...   \n",
       "543  import concurrent.futures\\nimport requests\\nimport pandas as pd\\nfrom sklearn.ensemble import IsolationForest\\n\\n# Sample user credentials\\ncredentials = {\\n    \"user1\": \"pass1\",\\n    \"user2\": \"pass2\",\\n    # ...\\n}\\n\\n# Security policies\\nsecurity_policies = {\\n    \"failed_attempts_threshold\": 3,\\n    \"lockout_duration\": 10,  # minutes\\n    # ...\\n}\\n\\n# User session management\\nuser_sessions = {}\\n\\n# Brute force detection\\ndef detect_brute_force(user):\\n    # Fetch authentication attempts from a database or log file\\n    attempts = pd.read_csv(\"attempts.csv\")\\n    failed_attempts = attempts[attempts[\"user\"] == user][\"status\"] == \"failed\"\\n\\n    if len(failed_attempts) > security_policies[\"failed_attempts_threshold\"]:\\n        return True\\n    else:\\n        return False\\n\\n# Authenticate user\\ndef authenticate(user, password):\\n    if credentials[user] == password:\\n        # Check for brute force attacks\\n        if detect_brute_force(user):\\n            return False\\n        e...   \n",
       "564  import pandas as pd\\nimport numpy as np\\nimport concurrent.futures\\nimport requests\\n\\n# Sample data of banking transactions\\ntransactions = [\\n    {\"transaction_id\": 1, \"account_id\": 1001, \"amount\": 5000},\\n    {\"transaction_id\": 2, \"account_id\": 1002, \"amount\": 3000},\\n    {\"transaction_id\": 3, \"account_id\": 1003, \"amount\": 2000},\\n    # ... more transactions\\n]\\n\\ndef process_transaction(transaction):\\n    try:\\n        # Simulate network connectivity delay\\n        response = requests.get(\"https://api.bank.com/process_transaction\", params=transaction)\\n        if response.status_code == 200:\\n            return f\"Transaction {transaction['transaction_id']} processed successfully\"\\n        else:\\n            return f\"Error processing transaction {transaction['transaction_id']}\"\\n    except Exception as e:\\n        return f\"Error processing transaction {transaction['transaction_id']}: {str(e)}\"\\n\\ndef process_transactions_concurrently(transactions):\\n    results = []\\n    with co...   \n",
       "592                                                                                                                                                                                                                                                import pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load dataset\\ndf = pd.read_csv('patient_records.csv')\\n\\n# Define function for parallel processing\\ndef analyze_data(patient_data):\\n    # Analyze data and identify patterns or anomalies\\n    # ...\\n\\n    return results\\n\\n# Create a ThreadPoolExecutor\\nwith ThreadPoolExecutor() as executor:\\n    # Submit tasks to the executor\\n    futures = [executor.submit(analyze_data, data) for _, data in df.iterrows()]\\n\\n    # Get the results\\n    results = [future.result() for future in futures]\\n\\n# Create a heatmap using seaborn\\nsns.heatmap(pd.DataFrame(results).corr(), annot=True)\\n\\n# Save the plot\\nplt.savefig('patterns.png')   \n",
       "618  Sure, here's some sample code that demonstrates the use of concurrency, parallel processing, and metaprogramming techniques to optimize the performance of a medication management system. This code uses the `multiprocessing` module to create a parallel processing pipeline that can handle large-scale medication data from different data sources. It also uses the `pandas` library to manipulate and analyze the data, and the `numpy` library to perform numerical operations on the data.\\n```\\nimport multiprocessing as mp\\nimport pandas as pd\\nimport numpy as np\\n\\n# Define a function to process data from a single data source\\ndef process_data(data):\\n    # Perform some data processing operations here\\n    # ...\\n    return processed_data\\n\\n# Define a function to handle data from multiple data sources\\ndef handle_data(sources):\\n    # Create a pool of worker processes\\n    pool = mp.Pool(processes=mp.cpu_count())\\n\\n    # Process data from each source in parallel\\n    processed_data = pool...   \n",
       "720  import concurrent.futures\\nimport pandas as pd\\nimport numpy as np\\nimport scikit_learn as sklearn\\nimport re\\n\\n# Function to parse log files\\ndef parse_log_file(file_path):\\n    log_data = []\\n    with open(file_path, 'r') as file:\\n        for line in file:\\n            log_entry = re.split(r'\\s+', line)\\n            log_data.append(log_entry)\\n    return log_data\\n\\n# Function to perform pattern matching and anomaly detection\\ndef detect_anomalies(log_data):\\n    # Implement pattern matching and anomaly detection algorithms here\\n    # ...\\n\\n    return anomalies\\n\\n# Function to create alert for potential security incidents\\ndef create_alert(anomaly):\\n    # Implement alerting system here\\n    # ...\\n\\n    return alert\\n\\n# Function to process log files concurrently\\ndef process_log_files(file_paths):\\n    with concurrent.futures.ThreadPoolExecutor() as executor:\\n        futures = [executor.submit(parse_log_file, file_path) for file_path in file_paths]\\n        log_data = [fu...   \n",
       "732                                                                                                                                                      import pandas as pd\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.metrics.pairwise import linear_kernel\\nfrom multiprocessing import Pool\\n\\n# Load user behavior data\\nuser_data = pd.read_csv('user_behavior.csv')\\n\\n# Function to recommend products based on user behavior\\ndef recommend_products(user):\\n    tfidf = TfidfVectorizer(stop_words='english')\\n    tfidf_matrix = tfidf.fit_transform(user['product_description'])\\n    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\\n    # ... (rest of the recommendation logic)\\n    return recommended_products\\n\\n# Parallel processing to recommend products for all users\\nwith Pool() as p:\\n    recommendations = p.map(recommend_products, user_data['user_id'])\\n\\n# Save recommendations to a file\\npd.DataFrame(recommendations).to_csv('recommendations.csv', index=False)   \n",
       "763  import asyncio\\nimport pandas as pd\\nfrom scipy.stats import norm\\n\\n# Simulated VoIP call data\\ncalls = [\\n    {\"call_id\": 1, \"latency\": 50, \"jitter\": 10, \"packet_loss\": 0.5},\\n    {\"call_id\": 2, \"latency\": 45, \"jitter\": 8, \"packet_loss\": 0.3},\\n    # ... more call data ...\\n]\\n\\n# Define SLAs\\nslas = {\\n    \"latency\": {\"mean\": 50, \"std_dev\": 10},\\n    \"jitter\": {\"mean\": 8, \"std_dev\": 2},\\n    \"packet_loss\": {\"mean\": 0.1, \"std_dev\": 0.05},\\n}\\n\\nasync def process_call(call):\\n    # Calculate metrics\\n    latency_anomaly = abs(call[\"latency\"] - slas[\"latency\"][\"mean\"]) > slas[\"latency\"][\"std_dev\"]\\n    jitter_anomaly = abs(call[\"jitter\"] - slas[\"jitter\"][\"mean\"]) > slas[\"jitter\"][\"std_dev\"]\\n    packet_loss_anomaly = abs(call[\"packet_loss\"] - slas[\"packet_loss\"][\"mean\"]) > slas[\"packet_loss\"][\"std_dev\"]\\n\\n    # Generate alert if any anomaly detected\\n    if latency_anomaly or jitter_anomaly or packet_loss_anomaly:\\n        print(f\"Alert: Anomaly detected in call {call['call_id']}\"...   \n",
       "850                         import multiprocessing as mp\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\ndef process_data(data):\\n    # Preprocessing steps\\n    # ...\\n    return processed_data\\n\\ndef train_model(data):\\n    X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\\n    model.fit(X_train, y_train)\\n    return model\\n\\ndef main():\\n    # Load data\\n    data = pd.read_csv('financial_data.csv')\\n\\n    # Create a pool of processes\\n    with mp.Pool(processes=mp.cpu_count()) as pool:\\n        # Process data in parallel\\n        processed_data = pool.map(process_data, np.array_split(data, mp.cpu_count()))\\n\\n        # Train models in parallel\\n        models = pool.map(train_model, processed_data)\\n\\nif __name__ == '__main__':\\n    main()   \n",
       "876  import re\\nimport requests\\nfrom Crypto.Cipher import AES\\n\\nclass InvalidURLException(Exception):\\n    pass\\n\\nclass SecurityScanner:\\n    def __init__(self, target_url):\\n        self.target_url = target_url\\n\\n    def validate_url(self):\\n        pattern = re.compile(\\n            r'^(?:http|ftp)s?://'  # http:// or https://\\n            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\\n            r'localhost|'  # localhost...\\n            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  # ...or ip\\n            r'(?::\\d+)?'  # optional port\\n            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\\n        if not re.match(pattern, self.target_url):\\n            raise InvalidURLException(\"Invalid URL\")\\n\\n    def find_vulnerabilities(self):\\n        vulnerabilities = []\\n        # Code to scan for vulnerabilities goes here\\n        # For demonstration, let's assume we found some vulnerabilities\\n        vulnerabilities.append(\"SQL Injection\")\\n     ...   \n",
       "901                                                                                                   import numpy as np\\nimport pandas as pd\\nfrom multiprocessing import Pool\\n\\n# Simulated signal processing function\\ndef process_signal(signal):\\n    # Perform signal processing operations here\\n    # ...\\n    # Calculate signal strength, frequency, and duration\\n    signal_strength = np.random.uniform(0, 1)\\n    frequency = np.random.uniform(1e9, 2e9)\\n    duration = np.random.uniform(1, 10)\\n    return signal_strength, frequency, duration\\n\\n# Generate a large number of signals\\nsignals = [{'id': i} for i in range(10000)]\\n\\n# Create a pool of processes\\nwith Pool() as pool:\\n    # Process the signals in parallel\\n    results = pool.map(process_signal, signals)\\n\\n# Convert results to a pandas DataFrame\\ndf = pd.DataFrame(results, columns=['signal_strength', 'frequency', 'duration'])\\n\\n# Perform analytics on the processed signals\\n# ...\\n# Output detailed analytics\\nprint(df.describe())   \n",
       "928                                                                                import pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Load customer data\\ncustomer_data = pd.read_csv('customer_data.csv')\\n\\n# Preprocess data\\nscaler = StandardScaler()\\ncustomer_data_scaled = scaler.fit_transform(customer_data)\\n\\n# Define CLV calculation function\\ndef calculate_clv(customer):\\n    # Calculate CLV based on historical purchases, average order value, and purchase frequency\\n    # Include predicted future behavior and potential churn rate\\n    # Return CLV value\\n    pass\\n\\n# Parallel processing to calculate CLV for each customer\\nclv_values = Parallel(n_jobs=-1)(delayed(calculate_clv)(customer) for _, customer in customer_data_scaled.iterrows())\\n\\n# Store CLV values in a new column in the dataframe\\ncustomer_data['CLV'] = clv_values\\n\\n# Generate insights and trends report\\n# ...   \n",
       "931  import numpy as np\\nimport multiprocessing as mp\\n\\n# Define the control algorithm\\ndef control_algorithm(sensor_data, control_signals):\\n    # Perform some calculations on the sensor data and control signals\\n    # ...\\n\\n    # Dynamically adjust the control algorithm based on the vehicle's current state\\n    state = np.random.choice(['accelerating', 'cruising', 'braking'])\\n    if state == 'accelerating':\\n        # Adjust the control algorithm for accelerating state\\n        # ...\\n        pass\\n    elif state == 'cruising':\\n        # Adjust the control algorithm for cruising state\\n        # ...\\n        pass\\n    elif state == 'braking':\\n        # Adjust the control algorithm for braking state\\n        # ...\\n        pass\\n\\n    # Return the control signals\\n    return control_signals\\n\\n# Define the parallel processing function\\ndef process_data(sensor_data, control_signals):\\n    # Process the sensor data and control signals concurrently\\n    with mp.Pool() as pool:\\n     ...   \n",
       "949  import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom concurrent.futures import ThreadPoolExecutor\\nimport matplotlib.pyplot as plt\\n\\n# Function to process student data and generate personalized learning paths\\ndef process_student_data(student_data):\\n    # Preprocess data, analyze strengths and weaknesses, and generate personalized learning paths\\n    # This is a placeholder function, replace with actual implementation\\n    personalized_paths = {}\\n    # ...\\n    return personalized_paths\\n\\n# Function to train and test a machine learning model for predicting student performance\\ndef train_and_test_model(student_data):\\n    # Split data into features and target\\n    X = student_data.drop('target', axis=1)\\n    y = student_data['target']\\n\\n    # Split data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_sp...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              pyflakes_error  \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          <string>:37:1: expected an indented block\\nuser_sessions = pd.read_csv('user_sessions.csv')\\n^\\n  \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <string>:48:1: expected an indented block\\nsales_data = pd.read_csv('sales_data.csv')\\n^\\n  \n",
       "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <string>:4:1: 'numpy as np' imported but unused\\n  \n",
       "69                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:10:9: local variable 'data' is assigned to but never used\\n  \n",
       "103                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:4:1: 'scipy.optimize.minimize_scalar' imported but unused\\n<string>:14:5: local variable 'noisy_data' is assigned to but never used\\n<string>:17:12: undefined name 'result'\\n<string>:23:12: undefined name 'combined_result'\\n<string>:31:36: undefined name 'num_processes'\\n<string>:38:74: undefined name 'num_processes'\\n<string>:41:5: local variable 'combined_result' is assigned to but never used\\n  \n",
       "203                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <string>:26:17: local variable 'data' is assigned to but never used\\n<string>:30:23: f-string is missing placeholders\\n  \n",
       "219                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <string>:3:1: 'numpy as np' imported but unused\\n<string>:4:1: 'sklearn.preprocessing.StandardScaler' imported but unused\\n<string>:14:9: local variable 'frame' is assigned to but never used\\n<string>:25:20: undefined name 'load_model'\\n<string>:51:23: undefined name 'preprocess_frame'\\n  \n",
       "261                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "270                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:3:1: 'sklearn.preprocessing.StandardScaler' imported but unused\\n<string>:4:1: 'sklearn.ensemble.RandomForestClassifier' imported but unused\\n<string>:5:1: 'sklearn.metrics.classification_report' imported but unused\\n<string>:14:12: undefined name 'processed_patient'\\n<string>:26:12: undefined name 'model'\\n  \n",
       "333                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <string>:9:12: undefined name 'processed_image'\\n  \n",
       "349                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "373                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <string>:2:1: 'numpy as np' imported but unused\\n<string>:13:12: undefined name 'result'\\n<string>:22:23: undefined name 'concurrent'\\n<string>:23:13: local variable 'scenario' is assigned to but never used\\n  \n",
       "377                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <string>:10:9: local variable 'data' is assigned to but never used\\n  \n",
       "378                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "394                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <string>:2:1: 'numpy as np' imported but unused\\n<string>:4:1: 'concurrent.futures' imported but unused\\n<string>:5:1: 'functools.partial' imported but unused\\n<string>:14:5: local variable 'outs' is assigned to but never used\\n  \n",
       "402                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <string>:3:1: 'numpy as np' imported but unused\\n<string>:4:1: 'tensorflow as tf' imported but unused\\n  \n",
       "431                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              <string>:17:13: local variable 'patient_df' is assigned to but never used\\n  \n",
       "453                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              <string>:29:12: undefined name 'features'\\n  \n",
       "461                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "543                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <string>:2:1: 'requests' imported but unused\\n<string>:4:1: 'sklearn.ensemble.IsolationForest' imported but unused\\n  \n",
       "564                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:1:1: 'pandas as pd' imported but unused\\n<string>:2:1: 'numpy as np' imported but unused\\n  \n",
       "592                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "618  <string>:1:484: EOL while scanning string literal\\nSure, here's some sample code that demonstrates the use of concurrency, parallel processing, and metaprogramming techniques to optimize the performance of a medication management system. This code uses the `multiprocessing` module to create a parallel processing pipeline that can handle large-scale medication data from different data sources. It also uses the `pandas` library to manipulate and analyze the data, and the `numpy` library to perform numerical operations on the data.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...  \n",
       "720                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <string>:2:1: 'pandas as pd' imported but unused\\n<string>:3:1: 'numpy as np' imported but unused\\n<string>:4:1: 'scikit_learn as sklearn' imported but unused\\n<string>:21:12: undefined name 'anomalies'\\n<string>:28:12: undefined name 'alert'\\n  \n",
       "732                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <string>:13:5: local variable 'cosine_sim' is assigned to but never used\\n<string>:15:12: undefined name 'recommended_products'\\n  \n",
       "763                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:2:1: 'pandas as pd' imported but unused\\n<string>:3:1: 'scipy.stats.norm' imported but unused\\n  \n",
       "850                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <string>:10:12: undefined name 'processed_data'\\n<string>:28:9: local variable 'models' is assigned to but never used\\n  \n",
       "876                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:2:1: 'requests' imported but unused\\n  \n",
       "901                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "928                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <string>:3:1: 'sklearn.ensemble.RandomForestRegressor' imported but unused\\n  \n",
       "931                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "949                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:1:1: 'pandas as pd' imported but unused\\n<string>:2:1: 'numpy as np' imported but unused\\n  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_codes['incomplete_code']= python_codes.code.apply(lambda x: '# ...' in x)\n",
    "print(python_codes.incomplete_code.value_counts())\n",
    "python_codes[python_codes.incomplete_code == True][['code', 'pyflakes_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_quality_score(row):\n",
    "    if row['is_valid_python_with_compile'] == False:\n",
    "        return 0\n",
    "    if row['pyflakes_error_category'] == 'undefined name':\n",
    "        return 1\n",
    "    if row['incomplete_code']:\n",
    "        return 1\n",
    "    if row['pyflakes_error_category'] == 'assigned to but never used':\n",
    "        return 2\n",
    "    if row['pyflakes_error_category'] == 'imported but unused':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "python_codes['code_quality_score'] = python_codes.apply(get_code_quality_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.groupby('complexity').code_quality_score.mean()  \n",
    "# No correlation between complexity and code quality score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.code_quality_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navhelpers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
