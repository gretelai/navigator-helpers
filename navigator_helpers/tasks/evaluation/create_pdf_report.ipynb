{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a PDF of the Data Quality Report for Data Desginer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéõÔ∏è Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from navigator_helpers.llms.llm_suite import GretelLLMSuite\n",
    "from navigator_helpers.tasks.evaluation.evaluation import (\n",
    "    BaseEvaluationTaskSuite,\n",
    "    VisualizationTaskSuite\n",
    ")\n",
    "\n",
    "# set environment variable 'GRETEL_PROD_API_KEY' from https://console.gretel.ai/users/me/key\n",
    "gretel_prod_api_key = input(\"Enter your Gretel API key from https://console.gretel.ai/users/me/key: \")\n",
    "os.environ['GRETEL_PROD_API_KEY'] = gretel_prod_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¢ Choose Dataset for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of samples to load from the dataset for testing\n",
    "# Set to None to use the full dataset\n",
    "NUM_SAMPLES = 1000\n",
    "\n",
    "datasets_dict = {\n",
    "    \"synthetic_text_to_sql\": {\n",
    "        \"dataset_kwargs\": {\n",
    "            \"path\": \"gretelai/synthetic_text_to_sql\",\n",
    "            \"split\": \"train\"\n",
    "        },\n",
    "        \"code_lang\": \"sql\",\n",
    "        \"eval_kwargs\":{\n",
    "            \"instruction_col_name\": \"sql_prompt\",\n",
    "            \"code_col_name\": \"sql\",\n",
    "            \"context_col_name\": \"sql_context\"\n",
    "        }\n",
    "    },\n",
    "    \"gsm8k\": {\n",
    "        \"dataset_kwargs\": {\n",
    "            \"path\": \"openai/gsm8k\",\n",
    "            \"name\": \"main\",\n",
    "            \"split\": \"train\"\n",
    "        },\n",
    "        \"eval_kwargs\": {\n",
    "            \"instruction_col_name\": \"question\",\n",
    "            \"code_col_name\": \"answer\",\n",
    "        }\n",
    "    },\n",
    "    \"synthetic_gsm8k\": {\n",
    "        \"dataset_kwargs\": {\n",
    "            \"path\": \"gretelai/synthetic-gsm8k-reflection-405b\",\n",
    "            \"split\": \"train\"\n",
    "        },\n",
    "        \"eval_kwargs\": {\n",
    "            \"instruction_col_name\": \"question\",\n",
    "            \"code_col_name\": \"answer\",\n",
    "        }\n",
    "    },\n",
    "    \"xlcost_text_to_code\": {\n",
    "        \"dataset_kwargs\": {\n",
    "            \"path\": \"codeparrot/xlcost-text-to-code\",\n",
    "            \"split\": \"train\"\n",
    "        },\n",
    "        \"code_lang\": \"python\",\n",
    "        \"eval_kwargs\": {\n",
    "            \"instruction_col_name\": \"text\",\n",
    "            \"code_col_name\": \"code\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# Prompt user to select a dataset\n",
    "print(\"Available datasets:\")\n",
    "for key in datasets_dict.keys():\n",
    "    print(f\" - {key}\")\n",
    "\n",
    "selected_dataset = input(\"\\nEnter the name of the dataset to load: \").strip()\n",
    "\n",
    "# Load the selected dataset\n",
    "if selected_dataset in datasets_dict:\n",
    "    dataset_dict = datasets_dict[selected_dataset]\n",
    "    eval_kwargs = dataset_dict[\"eval_kwargs\"]\n",
    "    code_lang = dataset_dict[\"code_lang\"] if \"code_lang\" in dataset_dict.keys() else None\n",
    "    dataset = load_dataset(**dataset_dict[\"dataset_kwargs\"])\n",
    "\n",
    "    # Optionally, select a subset if NUM_SAMPLES is specified\n",
    "    if NUM_SAMPLES is not None and NUM_SAMPLES < len(dataset):\n",
    "        dataset = dataset.select(range(NUM_SAMPLES))\n",
    "    \n",
    "    dataset_df = dataset.to_pandas()\n",
    "    \n",
    "    print(f\"Loaded dataset '{selected_dataset}' successfully!\")\n",
    "else:\n",
    "    print(\"Error: Dataset not found. Please enter a valid dataset name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp\n",
    "import pandas as pd\n",
    "dataset_df = pd.read_json('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/text_to_python_v1.json')\n",
    "dataset_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp\n",
    "results = {'results': {'row_uniqueness': {'percent_unique': 100.0,\n",
    "   'percent_semantically_unique': 100.0,\n",
    "   'non_unique_ids': [],\n",
    "   'non_semantically_unique_ids': []},\n",
    "  'feature_cardinality': {'id': 100,\n",
    "   'domain': 10,\n",
    "   'topic': 69,\n",
    "   'complexity': 4,\n",
    "   'prompt': 100,\n",
    "   'dependency_list': 12,\n",
    "   'code': 100},\n",
    "  'feature_distribution': {'distribution': {'id': None,\n",
    "    'domain': {'Educational Technology': 13,\n",
    "     'Healthcare Technology': 12,\n",
    "     'E-commerce': 12,\n",
    "     'Financial Services': 11,\n",
    "     'Cybersecurity': 10,\n",
    "     'Aerospace Software': 10,\n",
    "     'Telecommunications': 10,\n",
    "     'Video Game Development': 8,\n",
    "     'Artificial Intelligence': 8,\n",
    "     'Automotive Software': 6},\n",
    "    'topic': {'avg_length': 19.69,\n",
    "     'std_length': 4.500718236733404,\n",
    "     'avg_word_count': 2.26,\n",
    "     'word_count_histogram': ([0, 0, 1, 0, 0, 74, 0, 23, 0, 2],\n",
    "      [0.0,\n",
    "       0.4,\n",
    "       0.8,\n",
    "       1.2000000000000002,\n",
    "       1.6,\n",
    "       2.0,\n",
    "       2.4000000000000004,\n",
    "       2.8000000000000003,\n",
    "       3.2,\n",
    "       3.6,\n",
    "       4.0])},\n",
    "    'complexity': {'Expert: Concurrency, parallel processing, and metaprogramming': 29,\n",
    "     'Beginner: Basic syntax, data types, and control structures': 27,\n",
    "     'Advanced: Object-oriented programming and exception handling': 26,\n",
    "     'Intermediate: Functions, modules, and file handling': 18},\n",
    "    'prompt': {'avg_length': 1103.08,\n",
    "     'std_length': 259.7072042111884,\n",
    "     'avg_word_count': 159.96,\n",
    "     'word_count_histogram': ([0, 0, 0, 35, 49, 7, 5, 3, 0, 1],\n",
    "      [0.0,\n",
    "       35.9,\n",
    "       71.8,\n",
    "       107.69999999999999,\n",
    "       143.6,\n",
    "       179.5,\n",
    "       215.39999999999998,\n",
    "       251.29999999999998,\n",
    "       287.2,\n",
    "       323.09999999999997,\n",
    "       359.0])},\n",
    "    'dependency_list': {'avg_length': 60.38,\n",
    "     'std_length': 1.9683351935946871,\n",
    "     'avg_word_count': 5.0,\n",
    "     'word_count_histogram': ([0, 0, 0, 0, 0, 0, 0, 0, 0, 100],\n",
    "      [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0])},\n",
    "    'code': {'avg_length': 1059.34,\n",
    "     'std_length': 595.0563375416523,\n",
    "     'avg_word_count': 102.05,\n",
    "     'word_count_histogram': ([7, 16, 16, 18, 16, 15, 4, 3, 4, 1],\n",
    "      [0.0,\n",
    "       27.2,\n",
    "       54.4,\n",
    "       81.6,\n",
    "       108.8,\n",
    "       136.0,\n",
    "       163.2,\n",
    "       190.4,\n",
    "       217.6,\n",
    "       244.79999999999998,\n",
    "       272.0])}},\n",
    "   'score': {'id': None,\n",
    "    'domain': {'gini-simpson_index': 0.8958},\n",
    "    'topic': {'text_diversity_index': 0.8279853407018426},\n",
    "    'complexity': {'gini-simpson_index': 0.743},\n",
    "    'prompt': {'text_diversity_index': 0.5630924313331656},\n",
    "    'dependency_list': {'text_diversity_index': 0.18927071370650894},\n",
    "    'code': {'text_diversity_index': 0.7658162507189068}}},\n",
    "  'num_words_per_record': {'average_words_per_record': 46.26166666666666,\n",
    "   'word_counts_per_column': {'domain': 1.76,\n",
    "    'topic': 2.26,\n",
    "    'complexity': 6.54,\n",
    "    'prompt': 159.96,\n",
    "    'dependency_list': 5.0,\n",
    "    'code': 102.05},\n",
    "   'average_tokens_per_record': 496.66,\n",
    "   'tokens_per_column': {'id': 1.0,\n",
    "    'domain': 2.77,\n",
    "    'topic': 2.78,\n",
    "    'complexity': 10.71,\n",
    "    'prompt': 222.83,\n",
    "    'dependency_list': 20.3,\n",
    "    'code': 236.27},\n",
    "   'total_tokens': 49666},\n",
    "  'column_notes': {'id': 'Unique ID',\n",
    "   'domain': 'Seed Column',\n",
    "   'topic': 'Seed Column',\n",
    "   'complexity': 'Seed Column',\n",
    "   'prompt': '',\n",
    "   'dependency_list': 'Seed Column',\n",
    "   'code': ''},\n",
    "  'column_data_types': {'id': 'Other',\n",
    "   'domain': 'Categorical',\n",
    "   'topic': 'Text',\n",
    "   'complexity': 'Categorical',\n",
    "   'prompt': 'Text',\n",
    "   'dependency_list': 'Text',\n",
    "   'code': 'Text'}},\n",
    " 'dataset_overview_statistics': {'number_of_rows': 100,\n",
    "  'number_of_columns': 7,\n",
    "  'number_of_categorical_columns': 2,\n",
    "  'number_of_text_columns': 4,\n",
    "  'number_of_numerical_columns': 0,\n",
    "  'number_of_other_columns': 1,\n",
    "  'number_of_seed_columns': 4,\n",
    "  'data_completeness': 100.0,\n",
    "  'single_row': {'id': 0,\n",
    "   'domain': 'Cybersecurity',\n",
    "   'topic': 'Application Security',\n",
    "   'complexity': 'Beginner: Basic syntax, data types, and control structures',\n",
    "   'prompt': 'Write a Python function that checks if a given password meets the following security criteria:\\n\\n1. It should be at least 8 characters long.\\n2. It must contain at least one uppercase letter.\\n3. It must contain at least one lowercase letter.\\n4. It must contain at least one digit.\\n5. It must contain at least one special character from the following set: !@#$%^&*().\\n\\nThe function should return True if the password meets all the criteria, and False otherwise. Name the function \"is_secure_password\".\\n\\n### Instructions\\n    * The code should have a complexity of \"Beginner: Basic syntax, data types, and control structures\".\\n    * Write code that might be used in the \"Cybersecurity\" industry within a \"Application Security\" context.\\n    * Try to include at least 1 of the following Python packages:  `scikit-learn`, `requests`, `numpy`, `matplotlib`, `pandas`.\\n    * Include only the code, without any comments or additional text.\\n',\n",
    "   'dependency_list': ['scikit-learn',\n",
    "    'requests',\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'pandas'],\n",
    "   'code': \"import re\\n\\ndef is_secure_password(password):\\n    if len(password) < 8:\\n        return False\\n    if not re.search(r'[A-Z]', password):\\n        return False\\n    if not re.search(r'[a-z]', password):\\n        return False\\n    if not re.search(r'\\\\d', password):\\n        return False\\n    if not re.search(r'[!@#$%^&*()]', password):\\n        return False\\n    return True\"}}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_suite = GretelLLMSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a dictionary to store evaluation results\n",
    "# results = {}\n",
    "\n",
    "# # Uncomment the following lines to run individual evaluation tasks\n",
    "# results.update({\"row_uniqueness\": BaseEvaluationTaskSuite(llm_suite, dataset_df).row_uniqueness()})\n",
    "# results.update({\"feature_cardinality\": BaseEvaluationTaskSuite(llm_suite, dataset_df).feature_cardinality()})\n",
    "# results.update({\"feature_distribution\": BaseEvaluationTaskSuite(llm_suite, dataset_df).feature_distribution()})\n",
    "# results.update({\"num_words_per_record\": BaseEvaluationTaskSuite(llm_suite, dataset_df).num_words_per_record()})\n",
    "\n",
    "# # Uncomment this line to run everything, including LLM-as-a-judge\n",
    "# # results = BaseEvaluationTaskSuite(llm_suite, dataset_df, code_lang, eval_kwargs).evaluate_all()\n",
    "\n",
    "# pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from typing import List, Optional, Tuple, Union, Dict, Any\n",
    "import math\n",
    "import io\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.io import to_image\n",
    "from PIL import Image as PILImage\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, PageBreak, Paragraph, Spacer, Image, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib.enums import TA_CENTER\n",
    "\n",
    "# Constants\n",
    "FIG_WIDTH = 7  # inches\n",
    "FIG_HEIGHT = 3.6  # inches\n",
    "SCORE_VALUES = [\n",
    "    {\"label\": \"Very poor\", \"color\": \"rgb(229, 60, 26)\"},\n",
    "    {\"label\": \"Poor\", \"color\": \"rgb(229, 128, 26)\"},\n",
    "    {\"label\": \"Average\", \"color\": \"rgb(229, 161, 26)\"},\n",
    "    {\"label\": \"Good\", \"color\": \"rgb(183, 210, 45)\"},\n",
    "    {\"label\": \"Excellent\", \"color\": \"rgb(72, 210, 45)\"},\n",
    "]\n",
    "PRIMARY_PALETTE = ['#2E1065', '#D3A66E', '#110420', '#4F00A9', '#F9EFDE', '#1D0B32', '#8D32FA', '#C399FF', '#EFE5FF', '#EFD7AD', '#F4E3C6', '#FBF7ED', '#A59DAD', '#D2CED6', '#E8E7EB']\n",
    "SECONDARY_PALETTE = ['#052095', '#FF6BA9', '#3056F2', '#FFA8CC', '#8BB9FF', '#FFEDF5', '#E5F0FF', '#1E9C98', '#92F6F4', '#C5FEFF', '#E8FEFF', '#FF9248', '#FFB38A', '#FFD7B5', '#FFECDC', '#FF6700', '#FFCA1A', '#FFE16D', '#FFF099', '#FFFDE3', '#ECA10A']\n",
    "\n",
    "# Set up custom color palette for seaborn\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_palette(sns.color_palette(SECONDARY_PALETTE))\n",
    "\n",
    "def create_chart(data: pd.Series, title: str, xlabel: str, ylabel: str) -> Image:\n",
    "    fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT))\n",
    "    bars = ax.bar(range(len(data)), data.values, color='#4F00A9')\n",
    "    ax.set_facecolor('white')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    ax.set_title(title, fontsize=10, color='#1D0B32')\n",
    "    ax.set_xlabel(xlabel, fontsize=10, color='#1D0B32')\n",
    "    ax.set_ylabel(ylabel, fontsize=10, color='#1D0B32')\n",
    "    ax.set_xticks(range(len(data)))\n",
    "    \n",
    "    truncated_labels = [str(label)[:17] + '...' if len(str(label)) > 20 else str(label) for label in data.index]\n",
    "    ax.set_xticklabels(truncated_labels, rotation=45, ha='right', fontsize=8, color='#1D0B32')\n",
    "    \n",
    "    ax.tick_params(axis='both', colors='#1D0B32')\n",
    "    ax.tick_params(axis='y', labelsize=6)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}' if isinstance(height, float) else f'{height}',\n",
    "                ha='center', va='bottom', fontsize=8, color='#1D0B32')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    img_buffer = io.BytesIO()\n",
    "    plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "    img_buffer.seek(0)\n",
    "    return Image(img_buffer, width=7*inch, height=4*inch)\n",
    "\n",
    "def create_pareto_chart(data: pd.DataFrame, title: str) -> Image:\n",
    "    fig, ax1 = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    bars = ax1.bar(range(len(data)), data['count'], color='#4F00A9')\n",
    "    ax1.set_facecolor('white')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    ax1.set_xlabel('Categories', fontsize=10, color='#1D0B32')\n",
    "    ax1.set_ylabel('Count', fontsize=10, color='#1D0B32')\n",
    "    ax1.set_title(title, fontsize=10, color='#1D0B32')\n",
    "    \n",
    "    cumulative_percentage = 100 * data['count'].cumsum() / data['count'].sum()\n",
    "    ax2.plot(range(len(data)), cumulative_percentage, color='#FF6700', marker='D', ms=4)\n",
    "    ax2.set_ylabel('Cumulative Percentage', fontsize=10, color='#1D0B32')\n",
    "    ax2.set_ylim([0, 110])\n",
    "    \n",
    "    ax1.tick_params(axis='both', colors='#1D0B32')\n",
    "    ax2.tick_params(axis='both', colors='#1D0B32')\n",
    "    ax1.tick_params(axis='y', labelsize=6)\n",
    "    ax2.tick_params(axis='y', labelsize=6)\n",
    "    \n",
    "    ax1.set_xticks(range(len(data)))\n",
    "    truncated_labels = [str(label)[:17] + '...' if len(str(label)) > 20 else str(label) for label in data.index]\n",
    "    ax1.set_xticklabels(truncated_labels, rotation=45, ha='right', fontsize=6, color='#1D0B32')\n",
    "    \n",
    "    for i, v in enumerate(data['count']):\n",
    "        ax1.text(i, v, f'{v:.2f}' if isinstance(v, float) else f'{v}', ha='center', va='bottom', fontsize=8, color='#1D0B32')\n",
    "    \n",
    "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0f}%'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    img_buffer = io.BytesIO()\n",
    "    plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "    img_buffer.seek(0)\n",
    "    return Image(img_buffer, width=FIG_WIDTH*inch, height=FIG_HEIGHT*inch)\n",
    "\n",
    "def create_text_diversity_chart(text_diversity_df: pd.DataFrame) -> Image:\n",
    "    plt.figure(figsize=(FIG_WIDTH, FIG_HEIGHT))\n",
    "    ax = sns.barplot(x=text_diversity_df.index, y='diversity_index', data=text_diversity_df, color='#4F00A9')\n",
    "    ax.set_facecolor('white')\n",
    "    plt.gcf().patch.set_facecolor('white')\n",
    "    \n",
    "    plt.title(\"Text Diversity Indices\", fontsize=10, color='#1D0B32')\n",
    "    plt.ylabel(\"Diversity Index\", fontsize=10, color='#1D0B32')\n",
    "    plt.xlabel(\"\", fontsize=10, color='#1D0B32')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=8, color='#1D0B32')\n",
    "    \n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    ax.tick_params(axis='both', colors='#1D0B32')\n",
    "    ax.tick_params(axis='y', labelsize=6)\n",
    "    \n",
    "    for i, v in enumerate(text_diversity_df['diversity_index']):\n",
    "        ax.text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=8, color='#1D0B32')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    img_buffer = io.BytesIO()\n",
    "    plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "    img_buffer.seek(0)\n",
    "    return Image(img_buffer, width=FIG_WIDTH*inch, height=FIG_HEIGHT*inch)\n",
    "\n",
    "def create_histogram(counts: List[int], bins: List[float], col_name: str, data_type: str = \"Text\") -> Image:\n",
    "    assert data_type in [\"Text\", \"Numeric\"], f\"Invalid data type: {data_type}\"\n",
    "    if data_type == \"Text\":\n",
    "        x_label = \"Word Count\"\n",
    "    else:\n",
    "        x_label = \"Value\"\n",
    "    \n",
    "    plt.figure(figsize=(FIG_WIDTH, FIG_HEIGHT))\n",
    "    plt.hist(bins[:-1], bins, weights=counts, color='#4F00A9')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(x_label, fontsize=10, color='#1D0B32')\n",
    "    plt.ylabel(\"Count\", fontsize=10, color='#1D0B32')\n",
    "    plt.title(f\"{col_name.replace('_', ' ').title()}: {x_label} Distribution (Histogram)\", fontsize=10, color='#1D0B32')\n",
    "    plt.xticks(fontsize=6, color='#1D0B32')\n",
    "    plt.yticks(fontsize=6, color='#1D0B32')\n",
    "\n",
    "    # Add counts above bars\n",
    "    for i in range(len(counts)):\n",
    "        plt.text((bins[i]+bins[i+1])/2, counts[i], str(counts[i]), ha='center', va='bottom', fontsize=8, color='#1D0B32')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    img_buffer = io.BytesIO()\n",
    "    plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "    img_buffer.seek(0)\n",
    "    return Image(img_buffer, width=FIG_WIDTH*inch, height=FIG_HEIGHT*inch)\n",
    "\n",
    "def create_schema_table(dataset_df: pd.DataFrame, data_results: Dict[str, Any]) -> Tuple[Table, Dict[str, float]]:\n",
    "    schema_data = [['Column Name', 'Type', 'Total Count', '% Null', 'Average Length', 'Avg Tokens']]\n",
    "    for col in dataset_df.columns:\n",
    "        dtype = str(dataset_df[col].dtype)\n",
    "        total_count = len(dataset_df)\n",
    "        null_count = dataset_df[col].isnull().sum()\n",
    "        pcnt_null = (null_count / total_count) * 100\n",
    "        avg_length = 'N/A'\n",
    "        avg_tokens = 'N/A'\n",
    "        if 'num_words_per_record' in data_results:\n",
    "            num_words = data_results['num_words_per_record']\n",
    "            if col in num_words['word_counts_per_column']:\n",
    "                avg_length = num_words['word_counts_per_column'][col]\n",
    "            if col in num_words['tokens_per_column']:\n",
    "                avg_tokens = num_words['tokens_per_column'][col]\n",
    "        schema_data.append([col, dtype, total_count, f\"{pcnt_null:.2f}%\", avg_length, avg_tokens])\n",
    "    \n",
    "    table = Table(schema_data)\n",
    "    style = TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#4F00A9')),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 8),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.HexColor('#EFE5FF')),\n",
    "        ('TEXTCOLOR', (0, 1), (-1, -1), colors.HexColor('#110420')),\n",
    "        ('ALIGN', (0, 1), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "        ('FONTSIZE', (0, 1), (-1, -1), 7),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 3),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 3),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#4F00A9'))\n",
    "    ])\n",
    "    table.setStyle(style)\n",
    "    return table\n",
    "\n",
    "def create_overview_table(overview_data: List[List[str]]) -> Table:\n",
    "    table = Table(overview_data, colWidths=[1.5*inch, 1.5*inch])\n",
    "    style = TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#4F00A9')),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 8),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 3),  # Reduced padding\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.HexColor('#EFE5FF')),\n",
    "        ('TEXTCOLOR', (0, 1), (-1, -1), colors.HexColor('#110420')),\n",
    "        ('ALIGN', (0, 1), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "        ('FONTSIZE', (0, 1), (-1, -1), 7),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 3),  # Minimal top padding\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 3),  # Minimal bottom padding\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#4F00A9'))  # Thinner grid lines\n",
    "    ])\n",
    "    table.setStyle(style)\n",
    "    return table\n",
    "\n",
    "def create_single_record_preview(row: Dict[str, Any]) -> str:\n",
    "    preview_text = \"\"\n",
    "    for column, value in row.items():\n",
    "        truncated_value = str(value)[:100] + ('...' if len(str(value)) > 100 else '')\n",
    "        preview_text += f\"<b>{column}:</b>\\t{truncated_value}\"\n",
    "        preview_text += \"<br/>\"\n",
    "    return preview_text\n",
    "\n",
    "def _generate_pointer_path(score: int) -> str:\n",
    "    theta = score * (282 - 34) / 100 - 34\n",
    "    rads = math.radians(theta)\n",
    "    radius = 0.45\n",
    "    size = 0.025\n",
    "    x1 = -1 * radius * math.cos(rads) + 0.5\n",
    "    y1 = radius * math.sin(rads) + 0.5\n",
    "    return f\"\"\"\n",
    "    M {x1} {y1}\n",
    "    L {-1 * size * math.cos(math.radians(theta - 90)) + 0.5}\n",
    "        {size * math.sin(math.radians(theta - 90)) + 0.5}\n",
    "    L {-1 * size * math.cos(math.radians(theta + 90)) + 0.5}\n",
    "        {size * math.sin(math.radians(theta + 90)) + 0.5}\n",
    "    Z\"\"\"\n",
    "\n",
    "def gauge_and_needle_chart(score: Optional[int], display_score: bool = True, marker_colors: Optional[List[str]] = None) -> go.Figure:\n",
    "    if score is None:\n",
    "        fig = go.Figure(\n",
    "            layout=go.Layout(\n",
    "                annotations=[\n",
    "                    go.layout.Annotation(\n",
    "                        text=\"N/A\",\n",
    "                        font=dict(color=\"rgba(174, 95, 5, 1)\", size=18),\n",
    "                        showarrow=False,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\",\n",
    "                        x=0.5,\n",
    "                        y=0.5,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        marker_colors = [\"rgb(220, 220, 220)\", \"rgba(255, 255, 255, 0)\"]\n",
    "        pie_values = [70, 30]\n",
    "    else:\n",
    "        if not marker_colors:\n",
    "            marker_colors = [s[\"color\"] for s in SCORE_VALUES]\n",
    "        if marker_colors[-1] != \"rgba(255, 255, 255, 0)\":\n",
    "            marker_colors.append(\"rgba(255, 255, 255, 0)\")\n",
    "        pie_values = [70 // (len(marker_colors) - 1)] * (len(marker_colors) - 1)\n",
    "        pie_values.append(30)\n",
    "        fig = go.Figure()\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        showlegend=False,\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        height=180,\n",
    "        width=180,\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        hovermode=False,\n",
    "        modebar=None,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            name=\"gauge\",\n",
    "            values=pie_values,\n",
    "            marker=dict(\n",
    "                colors=marker_colors,\n",
    "                line=dict(width=4, color=\"#fafafa\"),\n",
    "            ),\n",
    "            hole=0.75,\n",
    "            direction=\"clockwise\",\n",
    "            sort=False,\n",
    "            rotation=234,\n",
    "            showlegend=False,\n",
    "            hoverinfo=\"none\",\n",
    "            textinfo=\"none\",\n",
    "            textposition=\"outside\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if score is not None:\n",
    "        if display_score:\n",
    "            fig.add_trace(\n",
    "                go.Indicator(\n",
    "                    mode=\"number\", value=score, domain=dict(x=[0, 1], y=[0.28, 0.45])\n",
    "                )\n",
    "            )\n",
    "        fig.add_shape(\n",
    "            type=\"circle\", fillcolor=\"black\", x0=0.475, x1=0.525, y0=0.475, y1=0.525\n",
    "        )\n",
    "        fig.add_shape(\n",
    "            type=\"path\",\n",
    "            fillcolor=\"black\",\n",
    "            line=dict(width=0),\n",
    "            path=_generate_pointer_path(score),\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "def create_gauge_chart(score: int) -> Image:\n",
    "    fig = gauge_and_needle_chart(score)\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        margin=dict(t=20, b=20, l=20, r=20)\n",
    "    )\n",
    "    img_bytes = to_image(fig, format=\"png\", scale=2)\n",
    "    img = PILImage.open(io.BytesIO(img_bytes))\n",
    "    img_buffer = io.BytesIO()\n",
    "    img.save(img_buffer, format=\"PNG\")\n",
    "    img_buffer.seek(0)\n",
    "    return Image(img_buffer, width=1.75*inch, height=1.75*inch)\n",
    "\n",
    "def calculate_average_diversity_indexes(data: Dict[str, Any]) -> Tuple[float, float, List[str]]:\n",
    "    # Average diversity indexes, only for generated columns\n",
    "    text_diversity_scores = []\n",
    "    gini_scores = []\n",
    "    included_columns = []\n",
    "    column_notes = data['results']['column_notes']\n",
    "    try:\n",
    "        for key, value in data['results']['feature_distribution']['score'].items():\n",
    "            if isinstance(value, dict) and column_notes[key] == '':\n",
    "                included_columns.append(key)\n",
    "                if 'text_diversity_index' in value:\n",
    "                    text_diversity_scores.append(value['text_diversity_index'])\n",
    "                if 'gini_simpson_index' in value:\n",
    "                    gini_scores.append(value['gini_simpson_index'])\n",
    "    except Exception as e:\n",
    "        print('Error calculating average diversity indexes:', e)\n",
    "\n",
    "    avg_text_diversity = sum(text_diversity_scores) / len(text_diversity_scores) if text_diversity_scores else None\n",
    "    avg_gini_index = sum(gini_scores) / len(gini_scores) if gini_scores else None\n",
    "\n",
    "    return avg_text_diversity, avg_gini_index, included_columns\n",
    "\n",
    "def plot_distributions(data_results: Dict[str, Any], column_subset: str, story: List[Any], styles):\n",
    "    \"\"\"\n",
    "    Plot the distribution of each generated column or seed column.\n",
    "    data_results: expects data['results]\n",
    "    \"\"\"\n",
    "    assert column_subset in ['generated', 'seed'], f\"column_subset must be 'generated' or 'seed', not '{column_subset}'\"\n",
    "    column_note = \"\" if column_subset == 'generated' else \"Seed Column\"\n",
    "    plot_count = 0\n",
    "\n",
    "    try:\n",
    "        for key, distribution in data_results['feature_distribution']['distribution'].items():\n",
    "\n",
    "            # Only plot distributions for the subset of columns\n",
    "            if data_results['column_notes'][key] != column_note:\n",
    "                continue\n",
    "            \n",
    "            data_type = data_results['column_data_types'][key] if 'column_data_types' in data_results else None\n",
    "        \n",
    "            if distribution and isinstance(distribution, dict):\n",
    "                try:\n",
    "                    if 'score' in data_results['feature_distribution'] and key in data_results['feature_distribution']['score']:\n",
    "                        for score_key, score_value in data_results['feature_distribution']['score'][key].items():\n",
    "                            section_title = key.replace('_', ' ') + ' Distribution (' +score_key.replace('_', ' ')+ ': ' + str(round(score_value, 2)) + ')'\n",
    "                            section_title = section_title.replace('_', ' ').title()\n",
    "                            story.append(Paragraph(section_title, styles['Heading2']))\n",
    "                    \n",
    "                    if data_type == 'Categorical':\n",
    "                        dist_df = pd.DataFrame.from_dict(distribution, orient='index', columns=['count'])\n",
    "                        dist_df['count'] = pd.to_numeric(dist_df['count'], errors='coerce')\n",
    "                        dist_df = dist_df.dropna().sort_values('count', ascending=False)\n",
    "                        \n",
    "                        if not dist_df.empty:\n",
    "                            # Handle large distributions\n",
    "                            if len(dist_df) > 75:\n",
    "                                other_count = dist_df.iloc[75:]['count'].sum()\n",
    "                                dist_df = dist_df.iloc[:75]\n",
    "                                dist_df.loc['Other'] = other_count\n",
    "                            img = create_pareto_chart(dist_df, f\"{key.replace('_', ' ').title()} Distribution (Pareto Chart)\")\n",
    "                        else:\n",
    "                            continue\n",
    "                    \n",
    "                    elif data_type == 'Text':\n",
    "                        counts, bins = distribution['word_count_histogram']\n",
    "                        img = create_histogram(counts, bins, key, \"Text\")\n",
    "                        \n",
    "                    elif data_type == 'Numeric':\n",
    "                        counts = distribution['histogram']\n",
    "                        bins = distribution['bin_edges']\n",
    "                        img = create_histogram(counts, bins, key, \"Numeric\")\n",
    "                    else:\n",
    "                        # Skip unsupported column types, e.g., 'Other', None\n",
    "                        continue\n",
    "\n",
    "                    story.append(img)\n",
    "                    plot_count += 1\n",
    "\n",
    "                    # Fit 2 plots per page\n",
    "                    if plot_count % 2 == 0:\n",
    "                        story.append(PageBreak())\n",
    "                    else:\n",
    "                        story.append(Spacer(1, 0.2*inch))\n",
    "                except Exception as e:\n",
    "                    story.append(Paragraph(f\"Error processing {key} distribution: {str(e)}\", styles['BodyText']))\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def create_report_pdf(data: Dict[str, Any], dataset_df: pd.DataFrame, output_filename: str = 'enhanced_data_quality_report.pdf'):\n",
    "    doc = SimpleDocTemplate(output_filename, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    \n",
    "    chart_title_style = ParagraphStyle(\n",
    "        name='ChartTitle', \n",
    "        parent=styles['BodyText'], \n",
    "        alignment=TA_CENTER,\n",
    "        fontSize=8,\n",
    "        leading=10\n",
    "    )\n",
    "    styles.add(chart_title_style)\n",
    "\n",
    "    styles['Title'].fontSize = 24\n",
    "    styles['Title'].alignment = 1\n",
    "    styles['Title'].spaceAfter = 12\n",
    "    styles['Title'].textColor = colors.HexColor('#110420')\n",
    "\n",
    "    styles['Heading1'].fontSize = 18\n",
    "    styles['Heading1'].spaceAfter = 6\n",
    "    styles['Heading1'].textColor = colors.HexColor('#110420')\n",
    "\n",
    "    styles['Heading2'].fontSize = 14\n",
    "    styles['Heading2'].spaceBefore = 12\n",
    "    styles['Heading2'].spaceAfter = 6\n",
    "    styles['Heading2'].textColor = colors.HexColor('#110420')\n",
    "\n",
    "    styles['BodyText'].fontSize = 10\n",
    "    styles['BodyText'].spaceBefore = 6\n",
    "    styles['BodyText'].spaceAfter = 6\n",
    "    styles['BodyText'].textColor = colors.HexColor('#110420')\n",
    "\n",
    "    styles.add(ParagraphStyle(name='RowPreview',\n",
    "                              parent=styles['BodyText'],\n",
    "                              fontName='Courier',\n",
    "                              fontSize=8,\n",
    "                              leading=10,\n",
    "                              spaceAfter=12,\n",
    "                              firstLineIndent=0,\n",
    "                              leftIndent=20))\n",
    "    \n",
    "    story = []\n",
    "    \n",
    "    # Average diversity indexes, only for generated columns\n",
    "    avg_text_diversity, avg_gini_index, included_columns = calculate_average_diversity_indexes(data)\n",
    "\n",
    "    story.append(Paragraph(\"Data Quality Report\", styles['Title']))\n",
    "    story.append(Spacer(1, 0.2*inch))\n",
    "\n",
    "    story.append(Paragraph(\"Key Metrics\", styles['Heading1']))\n",
    "    \n",
    "    unique_rows_chart = create_gauge_chart(int(data['results']['row_uniqueness']['percent_unique']))\n",
    "    semantically_unique_rows_chart = create_gauge_chart(int(data['results']['row_uniqueness']['percent_semantically_unique']))\n",
    "    text_diversity_chart = create_gauge_chart(int(avg_text_diversity * 100) if avg_text_diversity else None)\n",
    "    gini_simpson_chart = create_gauge_chart(int(avg_gini_index * 100) if avg_gini_index else None)\n",
    "\n",
    "    unique_rows_title = Paragraph(\"Unique Rows\", styles['ChartTitle'])\n",
    "    semantically_unique_rows_title = Paragraph(\"Semantically Unique Rows\", styles['ChartTitle'])\n",
    "    text_diversity_title = Paragraph(\"Text Diversity\", styles['ChartTitle'])\n",
    "    gini_simpson_title = Paragraph(\"Gini-Simpson Diversity\", styles['ChartTitle'])\n",
    "\n",
    "    chart_table = Table([\n",
    "        [unique_rows_title, semantically_unique_rows_title, text_diversity_title, gini_simpson_title],\n",
    "        [unique_rows_chart, semantically_unique_rows_chart, text_diversity_chart, gini_simpson_chart]\n",
    "    ])\n",
    "    chart_table_style = TableStyle([\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 2), \n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 3),\n",
    "    ])\n",
    "    chart_table.setStyle(chart_table_style)\n",
    "\n",
    "    story.append(chart_table)\n",
    "\n",
    "    # Dataset Overview\n",
    "    story.append(Paragraph(\"Dataset Overview\", styles['Heading1']))\n",
    "    story.append(Paragraph(\"This section provides key metrics on the structure, uniqueness, complexity, and quality of the data.\", styles['BodyText']))\n",
    "\n",
    "    overview = data['dataset_overview_statistics']\n",
    "    data_results = data['results']\n",
    "    # Split the overview data into two tables to save space\n",
    "    overview_data_1 = [\n",
    "        [\"Metric\", \"Value\"],\n",
    "        [\"Data Completeness\", f\"{overview['data_completeness']}%\"],\n",
    "        [\"Number of Rows\", f\"{overview['number_of_rows']}\"],\n",
    "        [\"Number of Columns\", f\"{overview['number_of_columns']}\"],\n",
    "        [\"Categorical Columns\", f\"{overview['number_of_categorical_columns']}\"],\n",
    "        [\"Text Columns\", f\"{overview['number_of_text_columns']}\"],\n",
    "        [\"Numerical Columns\", f\"{overview['number_of_numerical_columns']}\"],\n",
    "        [\"Seed Columns\", f\"{overview['number_of_seed_columns']}\"], \n",
    "    ]\n",
    "\n",
    "    overview_data_2 = [\n",
    "        [\"Metric\", \"Value\"],\n",
    "        [\"Unique Rows\", f\"{data['results']['row_uniqueness']['percent_unique']}%\"],\n",
    "        [\"Semantically Unique Rows\", f\"{data_results['row_uniqueness']['percent_semantically_unique']}%\"],\n",
    "        [\"Avg Words per Row\", f\"{data_results['num_words_per_record']['average_words_per_record']:.2f}\"],\n",
    "        [\"Avg Tokens per Row\", f\"{data_results['num_words_per_record']['average_tokens_per_record']:.2f}\"],\n",
    "        [\"Total Tokens\", f\"{data_results['num_words_per_record']['total_tokens']}\"],\n",
    "        [\"Avg Text Diversity\", f\"{avg_text_diversity:.4f}\" if avg_text_diversity else \"N/A\"],\n",
    "        [\"Avg Gini-Simpson Index\", f\"{avg_gini_index:.4f}\" if avg_gini_index else \"N/A\"],\n",
    "    ]\n",
    "\n",
    "    overview_table_1 = create_overview_table(overview_data_1)\n",
    "    overview_table_2 = create_overview_table(overview_data_2)\n",
    "    overview_table_table = Table([[overview_table_1, overview_table_2]])\n",
    "    story.append(overview_table_table)\n",
    "    story.append(Spacer(1, 0.2*inch))\n",
    "\n",
    "    # Single Row Preview\n",
    "    # TODO: cut off the preview if it would spill into the next page?\n",
    "    story.append(Paragraph(\"Single Row Preview\", styles['Heading1']))\n",
    "    preview_text = create_single_record_preview(data['dataset_overview_statistics']['single_row'])\n",
    "    story.append(Paragraph(preview_text, styles['RowPreview']))\n",
    "    story.append(PageBreak())\n",
    "\n",
    "    # Dataset Schema\n",
    "    story.append(Paragraph(\"Dataset Schema & Preview\", styles['Heading1']))\n",
    "    story.append(Paragraph(\"The schema table provides an overview of each column in the dataset.\", styles['BodyText']))\n",
    "    schema_table = create_schema_table(dataset_df, data_results)\n",
    "    story.append(schema_table)\n",
    "    story.append(Spacer(1, 0.2*inch))\n",
    "\n",
    "    # column Cardinality\n",
    "    if 'feature_cardinality' in data_results:\n",
    "        story.append(Paragraph(\"Column Cardinality\", styles['Heading1']))\n",
    "        feature_cardinality = pd.DataFrame.from_dict(data_results['feature_cardinality'], orient='index', columns=['cardinality'])\n",
    "        \n",
    "        img = create_chart(feature_cardinality['cardinality'], \"Column Cardinality\", \"Columns\", \"Cardinality\")\n",
    "        story.append(img)\n",
    "        story.append(PageBreak())\n",
    "\n",
    "    # Distribution Visualizations\n",
    "    story.append(Paragraph(\"Seed Column Distributions\", styles['Heading1']))\n",
    "    plot_distributions(data_results, 'seed', story, styles)\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph(\"Generated Column Distributions\", styles['Heading1']))\n",
    "    plot_distributions(data_results, 'generated', story, styles)\n",
    "    story.append(PageBreak())\n",
    "    \n",
    "    \n",
    "    # Word Count per Column\n",
    "    if 'word_counts_per_column' in data_results['num_words_per_record']:\n",
    "        story.append(Paragraph(\"Average Word Count per Column\", styles['Heading1']))\n",
    "        word_count = pd.DataFrame.from_dict(data_results['num_words_per_record']['word_counts_per_column'], orient='index', columns=['avg_words'])\n",
    "        word_count = word_count.sort_values('avg_words', ascending=False)\n",
    "        \n",
    "        img = create_chart(word_count['avg_words'], \"Average Word Count per Column\", \"Columns\", \"Average Word Count\")\n",
    "        story.append(img)\n",
    "        story.append(Spacer(1, 0.2*inch))\n",
    "\n",
    "    # Text Diversity Indices\n",
    "    if 'feature_distribution' in data_results and 'score' in data_results['feature_distribution']:\n",
    "        text_diversity = {}\n",
    "        for key, value in data_results['feature_distribution']['score'].items():\n",
    "            if isinstance(value, dict) and 'text_diversity_index' in value:\n",
    "                text_diversity[key] = value['text_diversity_index']\n",
    "        if text_diversity:\n",
    "            story.append(Paragraph(\"Text Diversity Indices\", styles['Heading1']))\n",
    "            text_diversity_df = pd.DataFrame.from_dict(text_diversity, orient='index', columns=['diversity_index'])\n",
    "            img = create_text_diversity_chart(text_diversity_df)\n",
    "            story.append(img)\n",
    "            story.append(Spacer(1, 0.2*inch))\n",
    "            \n",
    "\n",
    "    # Conclusion\n",
    "    story.append(Paragraph(\"Conclusion\", styles['Heading1']))\n",
    "\n",
    "    conclusion_text = \"This report provides a comprehensive view of the dataset's structure, content diversity, and the nature of the data it contains. Key takeaways include:<br/>\"\n",
    "\n",
    "    # Data Uniqueness\n",
    "    if 'row_uniqueness' in data_results:\n",
    "        unique = data_results['row_uniqueness'].get('percent_unique', 'N/A')\n",
    "        sem_unique = data_results['row_uniqueness'].get('percent_semantically_unique', 'N/A')\n",
    "        conclusion_text += f\"1. Data Uniqueness: With {unique}% unique rows and {sem_unique}% semantically unique rows, \"\n",
    "        if unique != 'N/A' and float(unique) > 90:\n",
    "            conclusion_text += \"the dataset shows a high degree of individuality in its rows. This suggests a rich and varied dataset.<br/><br/>\"\n",
    "        else:\n",
    "            conclusion_text += \"the dataset shows some level of repetition in its rows. This may indicate patterns or recurring themes in the data.<br/><br/>\"\n",
    "\n",
    "    # column Cardinality\n",
    "    if 'feature_cardinality' in data_results:\n",
    "        conclusion_text += \"2. Column Cardinality: The dataset contains columns with varying cardinalities. \"\n",
    "        conclusion_text += \"This diversity in column types allows for both granular analysis and higher-level pattern recognition.<br/><br/>\"\n",
    "\n",
    "    # Distribution Patterns\n",
    "    if 'feature_distribution' in data_results and 'distribution' in data_results['feature_distribution']:\n",
    "        conclusion_text += \"3. Distribution Patterns: The charts reveal the distribution patterns within each column, \"\n",
    "        conclusion_text += \"highlighting potential focus areas or biases in the data. Understanding these distributions \"\n",
    "        conclusion_text += \"is crucial for balanced analysis and identifying underrepresented categories.<br/><br/>\"\n",
    "\n",
    "    # Text Complexity\n",
    "    if 'num_words_per_record' in data_results:\n",
    "        avg_words = data_results['num_words_per_record'].get('average_words_per_record', 'N/A')\n",
    "        if avg_words != 'N/A':\n",
    "            conclusion_text += f\"4. Text Complexity: With an average of {avg_words:.2f} words per row, \"\n",
    "            if float(avg_words) > 50:\n",
    "                conclusion_text += \"the dataset shows a high level of complexity. \"\n",
    "            elif float(avg_words) > 20:\n",
    "                conclusion_text += \"the dataset shows a moderate level of complexity. \"\n",
    "            else:\n",
    "                conclusion_text += \"the dataset shows a low level of complexity. \"\n",
    "            conclusion_text += \"This gives an indication of the depth of information contained in each row.<br/><br/>\"\n",
    "\n",
    "    # Text Diversity\n",
    "    if 'feature_distribution' in data_results and 'score' in data_results['feature_distribution']:\n",
    "        conclusion_text += \"5. Text Diversity: The text diversity indices provide insight into the variety of content within text columns. \"\n",
    "        conclusion_text += \"Higher diversity can be beneficial for tasks requiring a broad range of examples, while lower diversity \"\n",
    "        conclusion_text += \"might indicate more standardized content.<br/><br/>\"\n",
    "\n",
    "    conclusion_text += \"\"\"\n",
    "    <b>Implications for Machine Learning:</b><br/><br/> \n",
    " \n",
    "    <b>Pre-training</b><br/> \n",
    "    - The dataset's uniqueness and diversity can provide a rich foundation for pre-training language models or other AI systems.<br/>\n",
    "    - High cardinality columns may help in learning broad representations, while low cardinality columns could aid in learning important categorical distinctions.<br/>\n",
    "    - If text diversity is high, it could be particularly valuable for building robust language models that can handle a wide range of contexts and styles.<br/><br/>\n",
    "\n",
    "    <b>Fine-tuning:</b><br/> \n",
    "    - The distribution patterns revealed in the charts should guide the fine-tuning process. Imbalanced categories may require techniques like weighted sampling or loss adjustment to ensure equal representation during fine-tuning.<br/>\n",
    "    - Columns with high semantic uniqueness could be especially useful for fine-tuning models on specific domains or tasks, as they likely contain a wide range of relevant examples.<br/>\n",
    "    - Consider the average word count per row when deciding on sequence length for transformer-based models during fine-tuning.<br/><br/>\n",
    "\n",
    "    <b>Designing/Iterating on Data to Fill Data Gaps:</b><br/> \n",
    "    - Analyze the distribution charts to identify underrepresented categories. These areas may require additional data collection or augmentation to ensure comprehensive model performance.<br/>\n",
    "    - If certain text diversity scores are low, consider ways to introduce more variety in those columns, either through data augmentation techniques or targeted data collection.<br/>\n",
    "    - For columns with very high cardinality, consider if grouping or categorization might be beneficial to prevent overfitting on rare categories.<br/>\n",
    "    - If semantic uniqueness is low in certain areas, it might indicate a need for more diverse examples in those categories to improve model generalization.<br/><br/>\n",
    "\n",
    "    <b>General Considerations:</b><br/> \n",
    "    - The overall uniqueness of the dataset impacts models that require diverse examples. However, care should be taken to address any imbalances revealed in the distribution charts.<br/>\n",
    "    - Monitor for potential biases in the data that could be propagated or amplified by machine learning models.<br/>\n",
    "    - Consider privacy implications, especially for high-cardinality columns that might contain identifiable information.<br/>\n",
    "    - The text complexity (average words per row) should inform decisions about model architecture and preprocessing steps.<br/><br/>\n",
    "    \"\"\"\n",
    "\n",
    "    story.append(Paragraph(conclusion_text, styles['BodyText']))\n",
    "\n",
    "    metric_definition_text = f\"\"\"\n",
    "    This section provides definitions for the metrics used in the report.<br/><br/>\n",
    "    <b>Key Metrics</b><br/>\n",
    "    Only generated columns requested by the user are included in the calculation of Key Metrics: {included_columns}. Helper columns like ID columns, seed columns or informational columns like code validation columns, data quality evaluation columns are excluded from Key Metrics calculation. <br/>\n",
    "    ‚Ä¢ <b>Unique Rows:</b> Percentage of rows that are unique in the dataset.<br/>\n",
    "    ‚Ä¢ <b>Semantically Unique Rows:</b> Percentage of rows that are semantically unique, based on TF-IDF.<br/>\n",
    "    ‚Ä¢ <b>Text Diversity:</b> Average Text Diversity Index (defined below) across all text columns, with higher values indicating more diverse content.<br/>\n",
    "    ‚Ä¢ <b>Gini-Simpson Diversity:</b> Average Gini-Simpson Index (defined below) across all categorical columns. Higher values indicating greater diversity.<br/><br/>\n",
    "\n",
    "    <b>Dataset Overview</b><br/>\n",
    "    The enhanced dataset overview provides key metrics about the structure, uniqueness, complexity, and quality of the data:<br/>\n",
    "    ‚Ä¢ <b>Number of Rows and Columns:</b> Indicates the size and dimensionality of the dataset.<br/>\n",
    "    ‚Ä¢ <b>Categorical and Numerical Columns:</b> Gives insight into the types of data present, helping to guide appropriate analysis techniques.<br/>\n",
    "    ‚Ä¢ <b>Data Completeness:</b> Shows the overall percentage of non-null values across all columns, indicating the dataset's overall quality and potential need for imputation.<br/>\n",
    "    ‚Ä¢ <b>Unique and Semantically Unique Rows:</b> Demonstrates the level of data diversity and potential redundancy in the dataset.<br/>\n",
    "    ‚Ä¢ <b>Average Words per Row:</b> Provides an indication of the typical complexity or detail level of each entry.<br/>\n",
    "    ‚Ä¢ <b>Average Tokens per Row and Total Tokens:</b> These metrics correspond to tokens used in Large Language Models (LLMs), giving an estimate of the dataset's complexity from an LLM processing perspective.<br/>\n",
    "    ‚Ä¢ <b>Average Text Diversity:</b> Average Text Diversity Index (defined below) across all text columns, with higher values indicating more diverse content.<br/>\n",
    "    ‚Ä¢ <b>Average Gini-Simpson Index:</b> Average Gini-Simpson Index (defined below) across all categorical columns. Higher values indicating greater diversity.<br/><br/>\n",
    "\n",
    "    <b>Dataset Schema & Preview</b><br/>\n",
    "    The schema table provides an overview of each column in the dataset, including the data type, the count of non-null and null values, and the average length (where applicable). This information is crucial for understanding the structure of the data and identifying potential data quality issues such as missing values or unexpected data types.<br/>\n",
    "    ‚Ä¢ <b>Data Type:</b> Categorical, Numeric, Text or Other. Categorical columns are those whose percentage of unique values are low; Text columns are non-Categorical columns with at least 2 spaces per Row, on average.<br/>\n",
    "    ‚Ä¢ <b>Total Count:</b> Total number of values in the Column.<br/>\n",
    "    ‚Ä¢ <b>% Null:</b> Percentage of null values in the Column.<br/>\n",
    "    ‚Ä¢ <b>Average Length:</b> Average character count of the values (for each text column).<br/>\n",
    "    ‚Ä¢ <b>Avg Tokens:</b> Average number of tokens in the values (for each text column).<br/><br/>\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if 'feature_cardinality' in data_results:\n",
    "        metric_definition_text += \"\"\"\n",
    "        <b>Column Cardinality</b><br/>\n",
    "        ‚Ä¢ <b>Column cardinality:</b> Represents the number of unique values for each column in the dataset. Higher cardinality indicates more diverse values within a Column.<br/><br/>\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    metric_definition_text += \"\"\"\n",
    "    <b>Column Distributions</b><br/>\n",
    "    Column distributions show the frequency of different values within each column. These visualizations help identify common patterns, imbalances, or biases in the data.<br/>\n",
    "    ‚Ä¢ <b>Pareto Chart:</b> A Pareto chart illustrates the distribution of domain in the dataset. The bars represent the count for each category, while the line shows the cumulative percentage. Only the top 75 categories are shown individually. The remaining categories are grouped as 'Other'. This visualization helps identify the most significant categories and their relative importance.<br/>\n",
    "    ‚Ä¢ <b>Gini-Simpson Index:</b> A diversity index for categorical columns. It quantifies the probability that two values taken at random from the column (with replacement) are different. Higher values indicate greater diversity.<br/>\n",
    "    ‚Ä¢ <b>Text Diversity Index:</b> A diversity index for text columns. It is defined as the average correlation between each row's TF-IDF vector and the dataset's TF-IDF matrix. Higher values indicate greater diversity.<br/><br/>\n",
    "    \"\"\"\n",
    "\n",
    "    story.append(Paragraph(\"Metric Definitions\", styles['Heading1']))\n",
    "    story.append(Paragraph(metric_definition_text, styles['BodyText']))\n",
    "\n",
    "    # Build the PDF\n",
    "    doc.build(story)\n",
    "    print(f\"PDF created: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report_pdf(results, dataset_df,  'data_quality_report.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# field = 'Example'\n",
    "# counts = [7, 7, 7, 10, 6, 6, 3, 1, 1, 2]\n",
    "# bins = [0.0, 27.7, 55.4, 83.1, 110.8, 138.5, 166.2, 193.9, 221.6, 249.29999999999998, 277.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"here's the {prompt} and here's the {response}\"\n",
    "test_str.format(prompt='prompt', response='response', context='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['results']['num_words_per_record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_notes = results['results']['column_notes']\n",
    "column_notes['id'] == ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navhelpers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
