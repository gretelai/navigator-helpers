{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test evaluation task suite for AI data designer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup API key to run tests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Define the root directory and add it to the path\n",
    "root_dir = os.path.abspath(os.path.join(notebook_dir, '..', '..', '..'))\n",
    "sys.path.insert(0, root_dir)\n",
    "\n",
    "# set environment variable 'GRETEL_PROD_API_KEY' from https://console.gretel.ai/users/me/key\n",
    "os.environ['GRETEL_PROD_API_KEY'] = 'grtude0e9cb184406dcdcd14a9cd05667ee0a2890fd889a1631bdf6c1db1cca1c41c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/foundation-shared/dhruv_gretel_ai/navigator-helpers/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Reload packages if you've made changes to the evaluation.py file.\n",
    "# Alternatively you can restart the kernel to pick up changes\n",
    "\n",
    "from importlib import reload\n",
    "import evaluation\n",
    "reload(evaluation)\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from navigator_helpers.llms.llm_suite import GretelLLMSuite\n",
    "from evaluation import BaseEvaluationTaskSuite, NL2SQLEvaluationTaskSuite\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      " - synthetic_text_to_sql\n",
      " - gsm8k\n",
      " - synthetic_gsm8k\n",
      " - xlcost_text_to_code\n",
      " - python_github_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 7.94k/7.94k [00:00<00:00, 21.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "datasets_dict = {\n",
    "    \"synthetic_text_to_sql\": \"gretelai/synthetic_text_to_sql\",\n",
    "    \"gsm8k\": \"openai/gsm8k\",\n",
    "    \"synthetic_gsm8k\": \"gretelai/synthetic-gsm8k-reflection-405b\",\n",
    "    \"xlcost_text_to_code\": \"codeparrot/xlcost-text-to-code\",\n",
    "    \"python_github_code\": \"angie-chen55/python-github-code\"\n",
    "}\n",
    "\n",
    "# Prompt user to select a dataset\n",
    "print(\"Available datasets:\")\n",
    "for key in datasets_dict.keys():\n",
    "    print(f\" - {key}\")\n",
    "\n",
    "selected_dataset = input(\"\\nEnter the name of the dataset to load: \").strip()\n",
    "\n",
    "# Load the selected dataset\n",
    "if selected_dataset in datasets_dict:\n",
    "    dataset_path = datasets_dict[selected_dataset]\n",
    "    dataset = load_dataset(dataset_path, split=\"train\")\n",
    "    \n",
    "    # Optionally, select a subset and convert to pandas DataFrame\n",
    "    dataset_1000 = dataset.select(range(1000))\n",
    "    dataset_1000_pd = dataset_1000.to_pandas()\n",
    "    \n",
    "    print(f\"Loaded dataset '{selected_dataset}' successfully!\")\n",
    "else:\n",
    "    print(\"Error: Dataset not found. Please enter a valid dataset name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_suite = GretelLLMSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = BaseEvaluationTaskSuite(llm_suite, dataset_1000_pd).row_uniqueness()\n",
    "pprint(results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_2 = BaseEvaluationTaskSuite(llm_suite, dataset_1000_pd).feature_cardinality()\n",
    "pprint(results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_3 = BaseEvaluationTaskSuite(llm_suite, dataset_1000_pd).feature_distribution()\n",
    "pprint(results_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_4 = BaseEvaluationTaskSuite(llm_suite, dataset_1000_pd).num_words_per_record()\n",
    "pprint(results_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SQL Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_linter_results = pd.read_csv(\"/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sqlqueries_1200_validated_092524.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coalesce the results of the five dialects into a single column\n",
    "sql_linter_results['is_valid_sql'] = sql_linter_results['is_valid_sqlite'].fillna(\n",
    "    sql_linter_results['is_valid_mysql'].fillna(\n",
    "        sql_linter_results['is_valid_postgresql'].fillna(\n",
    "            sql_linter_results['is_valid_sqlserver'].fillna(\n",
    "                sql_linter_results['is_valid_googlesql']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "sql_linter_results['error_msg'] = sql_linter_results['error_msg_sqlite'].fillna(\n",
    "    sql_linter_results['error_msg_mysql'].fillna(\n",
    "        sql_linter_results['error_msg_postgresql'].fillna(\n",
    "            sql_linter_results['error_msg_sqlserver'].fillna(\n",
    "                sql_linter_results['error_msg_googlesql']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(sql_linter_results.is_valid_sql.value_counts())\n",
    "def is_type_error(error_msg):\n",
    "    # These errors are because of misuse of data types, and they are dialect-specific\n",
    "    # Because the prompt as of now is not aware of the dialect, it makes sense if the LLM cannot identify these errors\n",
    "    import re\n",
    "    error_msg = str(error_msg).lower()\n",
    "\n",
    "    pattern = r'type \"\\w+\" does not exis'\n",
    "    # Check if the pattern exists in the string\n",
    "    if re.search(pattern, error_msg):\n",
    "        return True\n",
    "    \n",
    "    patterns = [\"type not found\", \"cannot find data type\", \"error creating tables\", \"'CREATE VIEW' must be the first statement in a query batch\",\n",
    "                \"login failed\"]\n",
    "    for pattern in patterns:\n",
    "        if pattern.lower() in error_msg:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "sql_linter_results['is_type_error'] = sql_linter_results.error_msg.apply(is_type_error)\n",
    "p = sql_linter_results[sql_linter_results.is_valid_sql == True].sample(10)\n",
    "n = sql_linter_results[(sql_linter_results.is_valid_sql == False) & (sql_linter_results.is_type_error == False)]#.sample(10)\n",
    "\n",
    "sql_linter_results_10 = pd.concat([p, n])\n",
    "sql_linter_results_10.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_5 = NL2SQLEvaluationTaskSuite(\n",
    "    llm_suite=llm_suite, dataset=sql_linter_results_10, code_lang=\"sql\"\n",
    "    )\n",
    "results_5 = task_5.llm_as_a_critic_evaluation(\n",
    "    instruction_col_name=\"Natural Language Prompt\", code_col_name=\"SQL Query\", context_col_name=\"Context\"\n",
    ")\n",
    "table5 = task_5.output_dataset\n",
    "\n",
    "# task_6 = BaseEvaluationTaskSuite(llm_suite, dataset_10_pd)\n",
    "# results_6 = task_6.llm_as_a_critic_evaluation(\n",
    "#     instruction_col_name=\"sql_prompt\", code_col_name=\"sql\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(results_5)\n",
    "# print(results_6)\n",
    "\n",
    "# review specific records\n",
    "# print(dataset_10_pd.loc[results_1['non_semantically_unique_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table5['correctness_score'] = table5['scores'].apply(lambda x: x['correctness_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table5[['Natural Language Prompt', 'SQL Query', 'Context', 'Dialect', 'is_valid_sql', 'scores', 'overall_score', 'correctness_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average correctness scores grouped by is_valid_sql\n",
    "table5.groupby('is_valid_sql')['correctness_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "table5.to_csv(\"/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sql_linter_results_35.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = table5[table5.is_valid_sql == False].index\n",
    "ind = indices[count]\n",
    "print(f'ind = {ind}')\n",
    "print('\\n', table5['error_msg'].loc[ind])\n",
    "print('\\n', table5['Natural Language Prompt'].loc[ind])\n",
    "print('\\n', table5['Context'].loc[ind])\n",
    "print('\\n', table5['SQL Query'].loc[ind])\n",
    "print('\\n', table5['scores'].loc[ind])\n",
    "\n",
    "count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 851\n",
    "# ind = 893\n",
    "# ind = 169\n",
    "# print(table5['error_msg_mysql'].loc[ind])\n",
    "\n",
    "# ind = 247\n",
    "# ind = 212\n",
    "# print(table5['error_msg_sqlite'].loc[ind])\n",
    "\n",
    "# ind = 499\n",
    "# ind = 1085\n",
    "# ind = 1011\n",
    "# print(table5['error_msg_googlesql'].loc[ind]) # Type not found\n",
    "\n",
    "# ind = 876\n",
    "# ind = 928\n",
    "# ind = 985\n",
    "# ind = 813\n",
    "# ind = 885\n",
    "# ind = 308\n",
    "ind = 51\n",
    "print(table5['error_msg_sqlserver'].loc[ind]) # Cannot find data type NUMBER\n",
    "\n",
    "# ind = 298\n",
    "# ind = 846\n",
    "# print(table5['error_msg_postgresql'].loc[ind]) # type \"number\" does not exist\n",
    "\n",
    "\n",
    "print('\\n', table5['Natural Language Prompt'].loc[ind])\n",
    "print('\\n', table5['Context'].loc[ind])\n",
    "print('\\n', table5['SQL Query'].loc[ind])\n",
    "print('\\n', table5['scores'].loc[ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table5['scores'].loc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table6 = task_6.output_dataset\n",
    "print(table6['scores'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navhelpers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
