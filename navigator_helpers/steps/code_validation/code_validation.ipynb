{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: need to install psycopg2 from source if using in production environment\n",
    "# https://www.psycopg.org/docs/install.html\n",
    "# %pip install sqlglot sqlvalidator sqlalchemy psycopg2-binary sqlfluff mysql-connector-python pyodbc\n",
    "# %pip install pyflakes pylint parso flake8 mypy\n",
    "# %pip install docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'python_parsers' from '/mnt/foundation-shared/nina_xu_gretel_ai/navigator-helpers/navigator_helpers/steps/code_validation/python_parsers.py'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import sql_parsers\n",
    "reload(sql_parsers)\n",
    "\n",
    "import python_parsers\n",
    "reload(python_parsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from python_parsers import is_valid_python_with_complie, is_valid_python_with_ast, is_valid_python_with_pyflakes, is_valid_python_with_parso, is_valid_python_with_mypy\n",
    "from sql_parsers import SimpleSqlValidator, SqliteValidator, PostgresqlValidator, MysqlValidator, SqlserverValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_queries = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sql_queries.csv')\n",
    "sql_queries = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sql_queries_w_dialect_1000.csv')\n",
    "sql_queries_googlesql = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sql_queries_googlesql_200.csv')\n",
    "sql_queries = pd.concat([sql_queries, sql_queries_googlesql])\n",
    "python_typscript_codes = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/python_typescript_codes.csv')\n",
    "python_codes = pd.read_json('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/text_to_python_v1.json')\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Code Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialect\n",
      "SQL Server            230\n",
      "PostgreSQL            221\n",
      "SQLite                209\n",
      "GoogleSQL             204\n",
      "MySQL                 197\n",
      "Oracle SQL             43\n",
      "OracleSQL              43\n",
      "Oracle                 37\n",
      "Oracle SQL Dialect      1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Natural Language Prompt</th>\n",
       "      <th>Context</th>\n",
       "      <th>SQL Query</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Dialect</th>\n",
       "      <th>Complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a2b3c4d</td>\n",
       "      <td>List all students with their respective engagement scores who participated in the online activities in the last month.</td>\n",
       "      <td>CREATE TABLE Students (StudentID INT PRIMARY KEY, Name NVARCHAR(100));\\nCREATE TABLE Engagement (EngagementID INT PRIMARY KEY, StudentID INT, Activity NVARCHAR(100), Score INT, Date DATE, FOREIGN KEY (StudentID) REFERENCES Students(StudentID));</td>\n",
       "      <td>SELECT s.Name, e.Score \\nFROM Students s \\nJOIN Engagement e ON s.StudentID = e.StudentID \\nWHERE e.Date &gt;= DATEADD(month, -1, GETDATE());</td>\n",
       "      <td>Education</td>\n",
       "      <td>Student Engagement</td>\n",
       "      <td>SQL Server</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  \\\n",
       "0  1a2b3c4d   \n",
       "\n",
       "                                                                                                  Natural Language Prompt  \\\n",
       "0  List all students with their respective engagement scores who participated in the online activities in the last month.   \n",
       "\n",
       "                                                                                                                                                                                                                                                Context  \\\n",
       "0  CREATE TABLE Students (StudentID INT PRIMARY KEY, Name NVARCHAR(100));\\nCREATE TABLE Engagement (EngagementID INT PRIMARY KEY, StudentID INT, Activity NVARCHAR(100), Score INT, Date DATE, FOREIGN KEY (StudentID) REFERENCES Students(StudentID));   \n",
       "\n",
       "                                                                                                                                    SQL Query  \\\n",
       "0  SELECT s.Name, e.Score \\nFROM Students s \\nJOIN Engagement e ON s.StudentID = e.StudentID \\nWHERE e.Date >= DATEADD(month, -1, GETDATE());   \n",
       "\n",
       "      Domain               Topic     Dialect  Complexity  \n",
       "0  Education  Student Engagement  SQL Server           3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_queries.head(1)\n",
    "print(sql_queries.Dialect.value_counts())\n",
    "\n",
    "sql_queries[sql_queries['Dialect'] == 'SQL Server'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.17.0.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Have a PostgreSQL database running in a Docker container. In command line, run the following commands:\n",
    "# Grant access to non-root users so that the python client will work\n",
    "> sudo groupadd docker\n",
    "> sudo usermod -aG docker $USER\n",
    "> newgrp docker\n",
    "\n",
    "> docker pull postgres\n",
    "> docker run --name my-postgres \\\n",
    "  -e POSTGRES_USER=myuser \\\n",
    "  -e POSTGRES_PASSWORD=mypassword \\\n",
    "  -e POSTGRES_DB=mydatabase \\\n",
    "  -p 5433:5432 \\\n",
    "  -d postgres\n",
    "\n",
    "\"\"\"\n",
    "client = docker.from_env()\n",
    "\n",
    "# List all running containers\n",
    "containers = client.containers.list(all=False)\n",
    "# Get the postgres container\n",
    "postgres_container = client.containers.get('my-postgres')\n",
    "# Get container's gateway, not that it's not the \"IPAddress\" field\n",
    "postgres_container_gateway = postgres_container.attrs['NetworkSettings']['Gateway']\n",
    "print(postgres_container_gateway)\n",
    "\n",
    "postgres_db_creds = {\n",
    "        \"host\": postgres_container_gateway,\n",
    "        \"port\": 5433, # the default port is 5432, but that was already in use for me\n",
    "        \"user\": \"myuser\",\n",
    "        \"password\": \"mypassword\",\n",
    "        \"dbname\": \"my-postgres\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.17.0.3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Have a MySQL database running in a Docker container. In command line, run the following commands:\n",
    "> docker pull mysql\n",
    "> docker run --name my-mysql \\\n",
    "  -e MYSQL_ROOT_PASSWORD=myrootpassword \\\n",
    "  -d mysql\n",
    "\"\"\"\n",
    "\n",
    "mysql_container = client.containers.get('my-mysql')\n",
    "mysql_container_ip = mysql_container.attrs['NetworkSettings']['IPAddress']\n",
    "print(mysql_container_ip)\n",
    "\n",
    "mysql_db_creds = {\n",
    "    \"host\": mysql_container_ip,\n",
    "    \"port\": 3306, # default port for mysql\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"myrootpassword\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.17.0.4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Have a Microsoft SQL Server database running in a Docker container. In command line, run the following commands:\n",
    "$ docker pull mcr.microsoft.com/mssql/server\n",
    "$ docker run --name my-sqlserver \\\n",
    "  -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=myRoot(!)Password' \\\n",
    "  -p 1433:1433 \\\n",
    "  -d mcr.microsoft.com/mssql/server\n",
    "\n",
    "$ sudo apt install unixodbc-dev\n",
    "\n",
    "Install the SQL Server command-line tool (sqlcmd) inside the container:\n",
    "$ docker exec -it --user root my-sqlserver bash\n",
    "# apt-get update\n",
    "# apt-get install -y mssql-tools unixodbc-dev\n",
    "\"\"\"\n",
    "          \n",
    "sqlserver_container = client.containers.get('my-sqlserver')\n",
    "sqlserver_container_ip = sqlserver_container.attrs['NetworkSettings']['IPAddress']\n",
    "print(sqlserver_container_ip)\n",
    "\n",
    "sqlserver_db_creds = {\n",
    "    \"host\": sqlserver_container_ip,\n",
    "    \"port\": 1433, # default port for sql server,\n",
    "    \"user\": \"sa\",\n",
    "    \"password\": \"myRoot(!)Password\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Apply different SQL validators to the SQL queries\n",
    "def is_valid_query_and_schema(row, func):\n",
    "    query_check = func(row['SQL Query'])\n",
    "    schema_check = func(row['Context'])\n",
    "    is_valid_schema = schema_check[0]\n",
    "    is_valid_query = query_check[0]\n",
    "    is_valid_sql = is_valid_schema and is_valid_query\n",
    "    error_messages = f\"***Schema error: {schema_check[1]}\" if not is_valid_schema else ''\n",
    "    error_messages += f\"***Query error: {query_check[1]}\" if not is_valid_query else ''\n",
    "    return is_valid_sql, is_valid_schema, is_valid_query, error_messages\n",
    "\n",
    "def is_valid_query_and_schema_with_sqlfluff(row):\n",
    "    dialect_map = {\n",
    "        'SQLite': 'sqlite',\n",
    "        'PostgreSQL': 'postgres',\n",
    "        'MySQL': 'mysql',\n",
    "        'SQL Server': 'tsql',\n",
    "        'GoogleSQL': 'bigquery',\n",
    "        'Oracle': 'oracle',\n",
    "    }\n",
    "    if 'Oracle' in row['Dialect']:\n",
    "        dialect = 'oracle'\n",
    "    else:\n",
    "        dialect = dialect_map.get(row['Dialect'], 'ansi')\n",
    "    query_check = SimpleSqlValidator.is_valid_sql_with_sqlfluff(row['SQL Query'], dialect)\n",
    "    schema_check = SimpleSqlValidator.is_valid_sql_with_sqlfluff(row['Context'], dialect)\n",
    "    is_valid_schema = schema_check[0]\n",
    "    is_valid_query = query_check[0]\n",
    "    is_valid_sql = is_valid_schema and is_valid_query\n",
    "    error_messages = f\"***Schema error: {schema_check[1]}\" if not is_valid_schema else ''\n",
    "    error_messages += f\"***Query error: {query_check[1]}\" if not is_valid_query else ''\n",
    "    return is_valid_sql, is_valid_schema, is_valid_query, error_messages\n",
    "\n",
    "def check_query_and_schema_separately(sql_queries, method):\n",
    "    functions_to_apply = {\n",
    "        'sqlglot': partial(is_valid_query_and_schema, func=SimpleSqlValidator.is_valid_sql_with_sqlglot),\n",
    "        'sqlquery': partial(is_valid_query_and_schema, func=SimpleSqlValidator.is_valid_sql_with_sqlquery),\n",
    "        'sqlfluff': is_valid_query_and_schema_with_sqlfluff,\n",
    "    }\n",
    "\n",
    "    result = sql_queries.apply(functions_to_apply[method], axis=1).apply(list)\n",
    "    sql_queries[f'is_valid_sql_with_{method}'] = result.apply(lambda x: x[0])\n",
    "    sql_queries[f'is_valid_schema_with_{method}'] = result.apply(lambda x: x[1])\n",
    "    sql_queries[f'is_valid_query_with_{method}'] = result.apply(lambda x: x[2])\n",
    "    sql_queries[f'error_msgs_{method}'] = result.apply(lambda x: x[3])\n",
    "\n",
    "    return sql_queries\n",
    "\n",
    "\n",
    "def check_query_against_schema(row, dialect):\n",
    "\n",
    "    validator_classes = {\n",
    "        'SQLite': SqliteValidator,\n",
    "        'PostgreSQL': PostgresqlValidator,\n",
    "        'MySQL': MysqlValidator,\n",
    "        'SQL Server': SqlserverValidator,\n",
    "    }\n",
    "\n",
    "    kwargs_postgres = {\n",
    "        'domain': row['Domain'],\n",
    "        'db_creds': postgres_db_creds,\n",
    "    }\n",
    "    kwargs_mysql = {\n",
    "        'domain': row['Domain'],\n",
    "        'db_creds': mysql_db_creds,\n",
    "        'mysql_container': mysql_container,\n",
    "    }\n",
    "    kwargs_sqlserver = {\n",
    "        'domain': row['Domain'],\n",
    "        'db_creds': sqlserver_db_creds,\n",
    "        'sqlserver_container': sqlserver_container,\n",
    "    }\n",
    "    all_kwargs = {\n",
    "        'SQLite': {},\n",
    "        'PostgreSQL': kwargs_postgres,\n",
    "        'MySQL': kwargs_mysql,\n",
    "        'SQL Server': kwargs_sqlserver,\n",
    "    }\n",
    "\n",
    "    dialect_name = dialect.lower().replace(' ', '')\n",
    "\n",
    "    if row['Dialect'] == dialect:\n",
    "        result = validator_classes[dialect].is_valid_sql(\n",
    "            row['SQL Query'], row['Context'], **all_kwargs[dialect]\n",
    "            )\n",
    "    else:\n",
    "        result = None, None\n",
    "    \n",
    "    row[f'is_valid_{dialect_name}'] = result[0]\n",
    "    row[f'error_msg_{dialect_name}'] = result[1]\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "sql_queries = check_query_and_schema_separately(sql_queries, 'sqlfluff')\n",
    "sql_queries = check_query_and_schema_separately(sql_queries, 'sqlglot')\n",
    "sql_queries = check_query_and_schema_separately(sql_queries, 'sqlquery')\n",
    "\n",
    "sql_queries = sql_queries.apply(check_query_against_schema, dialect='SQLite', axis=1)\n",
    "sql_queries = sql_queries.apply(check_query_against_schema, dialect='PostgreSQL', axis=1)\n",
    "sql_queries = sql_queries.apply(check_query_against_schema, dialect='MySQL', axis=1)\n",
    "sql_queries = sql_queries.apply(check_query_against_schema, dialect='SQL Server', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries.to_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/sql_queries_1200_validated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_valid_sql_with_sqlglot\n",
      "True     0.968776\n",
      "False    0.031224\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.993249\n",
      "False    0.006751\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.945992\n",
      "False    0.054008\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sqlite\n",
      "True     0.985646\n",
      "False    0.014354\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_postgresql\n",
      "True     0.895928\n",
      "False    0.104072\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_mysql\n",
      "True     0.939086\n",
      "False    0.060914\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sqlserver\n",
      "True     0.86087\n",
      "False    0.13913\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sql_queries.is_valid_sql_with_sqlglot.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_sql_with_sqlquery.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_sql_with_sqlfluff.value_counts(normalize=True))\n",
    "\n",
    "print(sql_queries.is_valid_sqlite.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_postgresql.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_mysql.value_counts(normalize=True))\n",
    "print(sql_queries.is_valid_sqlserver.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SQLite***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.990431\n",
      "False    0.009569\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.990431\n",
      "False    0.009569\n",
      "Name: proportion, dtype: float64\n",
      "***PostgreSQL***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.986425\n",
      "False    0.013575\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.918552\n",
      "False    0.081448\n",
      "Name: proportion, dtype: float64\n",
      "***MySQL***\n",
      "is_valid_sql_with_sqlglot\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.989848\n",
      "False    0.010152\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.969543\n",
      "False    0.030457\n",
      "Name: proportion, dtype: float64\n",
      "***SQL Server***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.886957\n",
      "False    0.113043\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.991304\n",
      "False    0.008696\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.995652\n",
      "False    0.004348\n",
      "Name: proportion, dtype: float64\n",
      "***GoogleSQL***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.97549\n",
      "False    0.02451\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.995098\n",
      "False    0.004902\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.823529\n",
      "False    0.176471\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dialects = ['SQLite', 'PostgreSQL', 'MySQL', 'SQL Server', 'GoogleSQL']\n",
    "for dialect in dialects:\n",
    "    print(f\"***{dialect}***\")\n",
    "    print(sql_queries[sql_queries['Dialect'] == dialect].is_valid_sql_with_sqlglot.value_counts(normalize=True))\n",
    "    print(sql_queries[sql_queries['Dialect'] == dialect].is_valid_sql_with_sqlquery.value_counts(normalize=True))\n",
    "    print(sql_queries[sql_queries['Dialect'] == dialect].is_valid_sql_with_sqlfluff.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SQLite***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.990431\n",
      "False    0.009569\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.990431\n",
      "False    0.009569\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.995215\n",
      "False    0.004785\n",
      "Name: proportion, dtype: float64\n",
      "***PostgreSQL***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.986425\n",
      "False    0.013575\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.918552\n",
      "False    0.081448\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.923077\n",
      "False    0.076923\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.99095\n",
      "False    0.00905\n",
      "Name: proportion, dtype: float64\n",
      "***MySQL***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.989848\n",
      "False    0.010152\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True     0.989848\n",
      "False    0.010152\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.969543\n",
      "False    0.030457\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.969543\n",
      "False    0.030457\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.974619\n",
      "False    0.025381\n",
      "Name: proportion, dtype: float64\n",
      "***SQL Server***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.886957\n",
      "False    0.113043\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True     0.9\n",
      "False    0.1\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True     0.982609\n",
      "False    0.017391\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.991304\n",
      "False    0.008696\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True     0.991304\n",
      "False    0.008696\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.995652\n",
      "False    0.004348\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.995652\n",
      "False    0.004348\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.995652\n",
      "False    0.004348\n",
      "Name: proportion, dtype: float64\n",
      "***GoogleSQL***\n",
      "***sqlglot***\n",
      "is_valid_sql_with_sqlglot\n",
      "True     0.97549\n",
      "False    0.02451\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlglot\n",
      "True     0.97549\n",
      "False    0.02451\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlglot\n",
      "True     0.995098\n",
      "False    0.004902\n",
      "Name: proportion, dtype: float64\n",
      "***sqlquery***\n",
      "is_valid_sql_with_sqlquery\n",
      "True     0.995098\n",
      "False    0.004902\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlquery\n",
      "True    1.0\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlquery\n",
      "True     0.995098\n",
      "False    0.004902\n",
      "Name: proportion, dtype: float64\n",
      "***sqlfluff***\n",
      "is_valid_sql_with_sqlfluff\n",
      "True     0.823529\n",
      "False    0.176471\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_schema_with_sqlfluff\n",
      "True     0.828431\n",
      "False    0.171569\n",
      "Name: proportion, dtype: float64\n",
      "is_valid_query_with_sqlfluff\n",
      "True     0.990196\n",
      "False    0.009804\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "methods = ['sqlglot', 'sqlquery', 'sqlfluff']\n",
    "for dialect in dialects:\n",
    "    print(f\"***{dialect}***\")\n",
    "    for method in methods:\n",
    "        print(f\"***{method}***\")\n",
    "        print(sql_queries[sql_queries['Dialect'] == dialect][f'is_valid_sql_with_{method}'].value_counts(normalize=True))\n",
    "        print(sql_queries[sql_queries['Dialect'] == dialect][f'is_valid_schema_with_{method}'].value_counts(normalize=True))\n",
    "        print(sql_queries[sql_queries['Dialect'] == dialect][f'is_valid_query_with_{method}'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SQLite***\n",
      "is_valid_sql_aggregate\n",
      "True     0.990431\n",
      "False    0.009569\n",
      "Name: proportion, dtype: float64\n",
      "***PostgreSQL***\n",
      "is_valid_sql_aggregate\n",
      "True     0.914027\n",
      "False    0.085973\n",
      "Name: proportion, dtype: float64\n",
      "***MySQL***\n",
      "is_valid_sql_aggregate\n",
      "True     0.969543\n",
      "False    0.030457\n",
      "Name: proportion, dtype: float64\n",
      "***SQL Server***\n",
      "is_valid_sql_aggregate\n",
      "True     0.882609\n",
      "False    0.117391\n",
      "Name: proportion, dtype: float64\n",
      "***GoogleSQL***\n",
      "is_valid_sql_aggregate\n",
      "True     0.823529\n",
      "False    0.176471\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check if the query is valid with both sqlglot and sqlfluff\n",
    "# SQLQuery is proven to be useless so not counting it in the aggregate\n",
    "sql_queries['is_valid_sql_aggregate'] = sql_queries[['is_valid_sql_with_sqlglot', 'is_valid_sql_with_sqlfluff']].all(axis=1)\n",
    "for dialect in dialects:\n",
    "    print(f\"***{dialect}***\")\n",
    "    print(sql_queries[sql_queries['Dialect'] == dialect].is_valid_sql_aggregate.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SQLite***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_sqlite                         \n",
      "False                           1      2\n",
      "True                            1    205\n",
      "***PostgreSQL***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_postgresql                     \n",
      "False                          18      5\n",
      "True                            0    198\n",
      "***MySQL***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_mysql                          \n",
      "False                           6      6\n",
      "True                            0    185\n",
      "***SQL Server***\n",
      "is_valid_sql_with_sqlfluff  False  True \n",
      "is_valid_sqlserver                      \n",
      "False                           1     31\n",
      "True                            0    198\n"
     ]
    }
   ],
   "source": [
    "# What are the differences between checking against schema and validating the query separately from schema?\n",
    "for dialect in dialects[:-1]:\n",
    "    print(f\"***{dialect}***\")\n",
    "    dialect_name = dialect.lower().replace(' ', '')\n",
    "    df = sql_queries[sql_queries['Dialect'] == dialect]\n",
    "    print(pd.crosstab(df[f'is_valid_{dialect_name}'], df['is_valid_sql_with_sqlfluff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQL Query</th>\n",
       "      <th>Context</th>\n",
       "      <th>error_msg_postgresql</th>\n",
       "      <th>error_msgs_sqlfluff</th>\n",
       "      <th>error_msgs_sqlquery</th>\n",
       "      <th>error_msgs_sqlglot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SELECT AVG(HeartRate) AS AverageHeartRate FROM Patients WHERE Age &gt; 60 AND VisitDate BETWEEN ADD_MONTHS(TRUNC(SYSDATE, 'MM'), -1) AND LAST_DAY(ADD_MONTHS(TRUNC(SYSDATE, 'MM'), -1));</td>\n",
       "      <td>CREATE TABLE Patients (\\n    PatientID INT PRIMARY KEY,\\n    Name VARCHAR2(255),\\n    Age INT,\\n    VisitDate DATE,\\n    HeartRate INT\\n);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 3:     Name VARCHAR2(255),\\n                 ^\\n\\n[SQL: CREATE TABLE Patients (\\n    PatientID INT PRIMARY KEY,\\n    Name VARCHAR2(255),\\n    Age INT,\\n    VisitDate DATE,\\n    HeartRate INT\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Patients (\\n    PatientID IN...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>SELECT p.name, AVG(r.rating) AS average_rating FROM products p JOIN reviews r ON p.id = r.product_id WHERE p.category = 'electronics' GROUP BY p.name;</td>\n",
       "      <td>CREATE TABLE customers (id NUMBER PRIMARY KEY, name VARCHAR2(50), email VARCHAR2(100)); CREATE TABLE products (id NUMBER PRIMARY KEY, name VARCHAR2(100), category VARCHAR2(50)); CREATE TABLE reviews (id NUMBER PRIMARY KEY, customer_id NUMBER, product_id NUMBER, rating NUMBER, review TEXT, CONSTRAINT fk_customer FOREIGN KEY (customer_id) REFERENCES customers(id), CONSTRAINT fk_product FOREIGN KEY (product_id) REFERENCES products(id));</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 1: CREATE TABLE customers (id NUMBER PRIMARY KEY, name VARCHAR2...\\n                                   ^\\n\\n[SQL: CREATE TABLE customers (id NUMBER PRIMARY KEY, name VARCHAR2(50), email VARCHAR2(100)); CREATE TABLE products (id NUMBER PRIMARY KEY, name VARCHAR2(100), category VARCHAR2(50)); CREATE TABLE reviews (id NUMBER PRIMARY KEY, customer_id NUMBER, product_id NUMBER, rating NUMBER, review TEXT, CONSTRAINT fk_customer FOREIGN KEY (customer_id) REFERENCES customers(id), CONSTRAINT fk_product FOREIGN KEY (product_id) REFERENCES products(id));]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE customers (id NUMBER PRIMAR...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>SELECT p.product_name, p.price FROM products p JOIN inventory i ON p.product_id = i.product_id WHERE p.available = 'true' AND i.quantity &gt; 0;</td>\n",
       "      <td>CREATE TABLE products (\\n    product_id VARCHAR2(50) PRIMARY KEY,\\n    product_name VARCHAR2(255),\\n    price NUMBER(10, 2),\\n    available BOOLEAN\\n);\\n\\nCREATE TABLE inventory (\\n    inventory_id VARCHAR2(50) PRIMARY KEY,\\n    product_id VARCHAR2(50) REFERENCES products(product_id),\\n    quantity NUMBER\\n);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     product_id VARCHAR2(50) PRIMARY KEY,\\n                       ^\\n\\n[SQL: CREATE TABLE products (\\n    product_id VARCHAR2(50) PRIMARY KEY,\\n    product_name VARCHAR2(255),\\n    price NUMBER(10, 2),\\n    available BOOLEAN\\n);\\n\\nCREATE TABLE inventory (\\n    inventory_id VARCHAR2(50) PRIMARY KEY,\\n    product_id VARCHAR2(50) REFERENCES products(product_id),\\n    quantity NUMBER\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE products (\\n    product_id V...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>SELECT d.name, SUM(s.quantity_sold) as total_sales FROM sales s JOIN drugs d ON s.drug_id = d.id WHERE DATE_PART('month', s.sale_date) = DATE_PART('month', CURRENT_DATE) AND DATE_PART('year', s.sale_date) = DATE_PART('year', CURRENT_DATE) GROUP BY d.name;</td>\n",
       "      <td>CREATE TABLE sales (id SERIAL PRIMARY KEY, drug_id INTEGER REFERENCES drugs(id), quantity_sold INTEGER, sale_date DATE);\\nCREATE TABLE drugs (id SERIAL PRIMARY KEY, name VARCHAR(255) NOT NULL);</td>\n",
       "      <td>(psycopg2.errors.UndefinedTable) relation \"drugs\" does not exist\\n\\n[SQL: CREATE TABLE sales (id SERIAL PRIMARY KEY, drug_id INTEGER REFERENCES drugs(id), quantity_sold INTEGER, sale_date DATE);\\nCREATE TABLE drugs (id SERIAL PRIMARY KEY, name VARCHAR(255) NOT NULL);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>SELECT City, AVG(BroadbandSpeed) AS AverageSpeed FROM BroadbandData GROUP BY City;</td>\n",
       "      <td>CREATE TABLE BroadbandData (\\n    City VARCHAR2(100),\\n    BroadbandSpeed NUMBER\\n);\\n</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     City VARCHAR2(100),\\n                 ^\\n\\n[SQL: CREATE TABLE BroadbandData (\\n    City VARCHAR2(100),\\n    BroadbandSpeed NUMBER\\n);\\n]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE BroadbandData (\\n    City VA...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>SELECT p.PropertyType, SUM(i.Amount) AS TotalInvestment FROM Investments i JOIN Properties p ON i.PropertyID = p.PropertyID GROUP BY p.PropertyType;</td>\n",
       "      <td>CREATE TABLE Investments (InvestmentID VARCHAR2(20), InvestorID VARCHAR2(20), PropertyID VARCHAR2(20), Amount NUMBER(10, 2), InvestmentDate DATE); CREATE TABLE Properties (PropertyID VARCHAR2(20), PropertyType VARCHAR2(50), Address VARCHAR2(255));</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 1: CREATE TABLE Investments (InvestmentID VARCHAR2(20), Investo...\\n                                               ^\\n\\n[SQL: CREATE TABLE Investments (InvestmentID VARCHAR2(20), InvestorID VARCHAR2(20), PropertyID VARCHAR2(20), Amount NUMBER(10, 2), InvestmentDate DATE); CREATE TABLE Properties (PropertyID VARCHAR2(20), PropertyType VARCHAR2(50), Address VARCHAR2(255));]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Investments (InvestmentID V...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>SELECT P.name FROM Patients P JOIN Appointments A ON P.patient_id = A.patient_id JOIN Doctors D ON A.doctor_id = D.doctor_id WHERE D.name = 'Dr. Smith' AND appointment_date BETWEEN CURRENT_DATE AND (CURRENT_DATE + INTERVAL '7 days');</td>\n",
       "      <td>CREATE TABLE Patients (patient_id SERIAL PRIMARY KEY, name VARCHAR(100), age INT, gender CHAR(1)); CREATE TABLE Appointments (appointment_id SERIAL PRIMARY KEY, patient_id INT, doctor_id INT, appointment_date DATE, FOREIGN KEY (patient_id) REFERENCES Patients(patient_id), FOREIGN KEY (doctor_id) REFERENCES Doctors(doctor_id)); CREATE TABLE Doctors (doctor_id SERIAL PRIMARY KEY, name VARCHAR(100), specialty VARCHAR(100));</td>\n",
       "      <td>(psycopg2.errors.UndefinedTable) relation \"doctors\" does not exist\\n\\n[SQL: CREATE TABLE Patients (patient_id SERIAL PRIMARY KEY, name VARCHAR(100), age INT, gender CHAR(1)); CREATE TABLE Appointments (appointment_id SERIAL PRIMARY KEY, patient_id INT, doctor_id INT, appointment_date DATE, FOREIGN KEY (patient_id) REFERENCES Patients(patient_id), FOREIGN KEY (doctor_id) REFERENCES Doctors(doctor_id)); CREATE TABLE Doctors (doctor_id SERIAL PRIMARY KEY, name VARCHAR(100), specialty VARCHAR(100));]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>SELECT product_name FROM products WHERE in_stock = TRUE AND price &gt; 50;</td>\n",
       "      <td>CREATE TABLE products (product_id NUMBER PRIMARY KEY, product_name VARCHAR2(255), price NUMBER, in_stock BOOLEAN);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 1: CREATE TABLE products (product_id NUMBER PRIMARY KEY, produc...\\n                                          ^\\n\\n[SQL: CREATE TABLE products (product_id NUMBER PRIMARY KEY, product_name VARCHAR2(255), price NUMBER, in_stock BOOLEAN);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE products (product_id NUMBER...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>SELECT AVG(grade) AS average_grade FROM Students WHERE course_name = 'Data Science 101';</td>\n",
       "      <td>CREATE TABLE Students (\\n    student_id VARCHAR2(50),\\n    student_name VARCHAR2(100),\\n    grade NUMBER(3, 2),\\n    course_name VARCHAR2(100)\\n);\\n\\nCREATE TABLE Courses (\\n    course_id VARCHAR2(50),\\n    course_name VARCHAR2(100),\\n    instructor VARCHAR2(100)\\n);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     student_id VARCHAR2(50),\\n                       ^\\n\\n[SQL: CREATE TABLE Students (\\n    student_id VARCHAR2(50),\\n    student_name VARCHAR2(100),\\n    grade NUMBER(3, 2),\\n    course_name VARCHAR2(100)\\n);\\n\\nCREATE TABLE Courses (\\n    course_id VARCHAR2(50),\\n    course_name VARCHAR2(100),\\n    instructor VARCHAR2(100)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Students (\\n    student_id V...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>SELECT COUNT(*)\\nFROM CustomerComplaints\\nWHERE DateReceived &gt;= ADD_MONTHS(SYSDATE, -1);</td>\n",
       "      <td>CREATE TABLE CustomerComplaints (\\n    ComplaintID INT PRIMARY KEY,\\n    CustomerID INT,\\n    DateReceived DATE,\\n    ComplaintText VARCHAR2(4000),\\n    Status VARCHAR2(50)\\n);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 5:     ComplaintText VARCHAR2(4000),\\n                          ^\\n\\n[SQL: CREATE TABLE CustomerComplaints (\\n    ComplaintID INT PRIMARY KEY,\\n    CustomerID INT,\\n    DateReceived DATE,\\n    ComplaintText VARCHAR2(4000),\\n    Status VARCHAR2(50)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE CustomerComplaints (\\n    Co...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>SELECT ar.Drug_Name, ar.Severity_Level, ar.Report_Date\\nFROM Adverse_Reactions ar\\nWHERE ar.Report_Date &gt;= ADD_MONTHS(SYSDATE, -12);</td>\n",
       "      <td>CREATE TABLE Adverse_Reactions (\\n    Reaction_ID VARCHAR2(50),\\n    Report_Date DATE,\\n    Drug_Name VARCHAR2(100),\\n    Severity_Level VARCHAR2(50)\\n);\\nCREATE TABLE Drugs (\\n    Drug_ID VARCHAR2(50),\\n    Drug_Name VARCHAR2(100)\\n);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     Reaction_ID VARCHAR2(50),\\n                        ^\\n\\n[SQL: CREATE TABLE Adverse_Reactions (\\n    Reaction_ID VARCHAR2(50),\\n    Report_Date DATE,\\n    Drug_Name VARCHAR2(100),\\n    Severity_Level VARCHAR2(50)\\n);\\nCREATE TABLE Drugs (\\n    Drug_ID VARCHAR2(50),\\n    Drug_Name VARCHAR2(100)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Adverse_Reactions (\\n    Rea...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>SELECT AVG(grade) AS average_grade FROM Students WHERE course = 'Mathematics';</td>\n",
       "      <td>CREATE TABLE Students (\\n    student_id VARCHAR2(10),\\n    name VARCHAR2(100),\\n    age NUMBER,\\n    grade NUMBER,\\n    course VARCHAR2(50)\\n);\\n\\nCREATE TABLE Courses (\\n    course_id VARCHAR2(10),\\n    course_name VARCHAR2(100)\\n);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     student_id VARCHAR2(10),\\n                       ^\\n\\n[SQL: CREATE TABLE Students (\\n    student_id VARCHAR2(10),\\n    name VARCHAR2(100),\\n    age NUMBER,\\n    grade NUMBER,\\n    course VARCHAR2(50)\\n);\\n\\nCREATE TABLE Courses (\\n    course_id VARCHAR2(10),\\n    course_name VARCHAR2(100)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Students (\\n    student_id V...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>SELECT p.product_name, AVG(r.rating) AS average_rating FROM products p JOIN reviews r ON p.product_id = r.product_id GROUP BY p.product_name;</td>\n",
       "      <td>CREATE TABLE customers (customer_id VARCHAR2(50), name VARCHAR2(100), email VARCHAR2(100)); CREATE TABLE products (product_id VARCHAR2(50), product_name VARCHAR2(100), category VARCHAR2(100)); CREATE TABLE reviews (review_id VARCHAR2(50), customer_id VARCHAR2(50), product_id VARCHAR2(50), rating NUMBER(3), review_date DATE);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 1: CREATE TABLE customers (customer_id VARCHAR2(50), name VARCH...\\n                                            ^\\n\\n[SQL: CREATE TABLE customers (customer_id VARCHAR2(50), name VARCHAR2(100), email VARCHAR2(100)); CREATE TABLE products (product_id VARCHAR2(50), product_name VARCHAR2(100), category VARCHAR2(100)); CREATE TABLE reviews (review_id VARCHAR2(50), customer_id VARCHAR2(50), product_id VARCHAR2(50), rating NUMBER(3), review_date DATE);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE customers (customer_id VARC...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>SELECT City, COUNT(UserID) AS ActiveUsers FROM 5GUsers WHERE IsActive = 1 GROUP BY City;</td>\n",
       "      <td>CREATE TABLE 5GUsers (UserID VARCHAR(255), UserName VARCHAR(255), City VARCHAR(255), IsActive INT, SubscriptionDate DATE);</td>\n",
       "      <td>(psycopg2.errors.SyntaxError) trailing junk after numeric literal at or near \"5G\"\\nLINE 1: CREATE TABLE 5GUsers (UserID VARCHAR(255), UserName VARCHAR(...\\n                     ^\\n\\n[SQL: CREATE TABLE 5GUsers (UserID VARCHAR(255), UserName VARCHAR(255), City VARCHAR(255), IsActive INT, SubscriptionDate DATE);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>***Schema error: Expected table name but got &lt;Token token_type: TokenType.NUMBER, text: 5, line: 1, col: 14, start: 13, end: 13, comments: []&gt;. Line 1, Col: 14.\\n  CREATE TABLE \u001b[4m5\u001b[0mGUsers (UserID VARCHAR(255), UserName VARCHAR(255), City VARCHAR(255), IsActive INT, SubscriptionDat***Query error: Expected table name but got &lt;Token token_type: TokenType.NUMBER, text: 5, line: 1, col: 48, start: 47, end: 47, comments: []&gt;. Line 1, Col: 48.\\n  SELECT City, COUNT(UserID) AS ActiveUsers FROM \u001b[4m5\u001b[0mGUsers WHERE IsActive = 1 GROUP BY City;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>SELECT w.warehouse_name, SUM(i.quantity) AS total_items FROM Warehouses w JOIN Inventory i ON w.warehouse_id = i.warehouse_id GROUP BY w.warehouse_name;</td>\n",
       "      <td>CREATE TABLE Warehouses (warehouse_id NUMBER PRIMARY KEY, warehouse_name VARCHAR2(100));\\nCREATE TABLE Inventory (item_id NUMBER PRIMARY KEY, warehouse_id NUMBER, quantity NUMBER, FOREIGN KEY (warehouse_id) REFERENCES Warehouses(warehouse_id));</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 1: CREATE TABLE Warehouses (warehouse_id NUMBER PRIMARY KEY, wa...\\n                                              ^\\n\\n[SQL: CREATE TABLE Warehouses (warehouse_id NUMBER PRIMARY KEY, warehouse_name VARCHAR2(100));\\nCREATE TABLE Inventory (item_id NUMBER PRIMARY KEY, warehouse_id NUMBER, quantity NUMBER, FOREIGN KEY (warehouse_id) REFERENCES Warehouses(warehouse_id));]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Warehouses (warehouse_id NU...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>SELECT p.PrescriptionID, pa.Name AS PatientName, pr.Medication, pr.Dosage, pr.Date FROM Prescriptions pr JOIN Doctors d ON pr.DoctorID = d.DoctorID JOIN Patients pa ON pr.PatientID = pa.PatientID WHERE d.Name = 'Dr. Smith' AND pr.Date &gt;= CURRENT_DATE - INTERVAL '1 month';</td>\n",
       "      <td>CREATE TABLE Doctors (DoctorID VARCHAR PRIMARY KEY, Name VARCHAR NOT NULL, Specialty VARCHAR);\\nCREATE TABLE Patients (PatientID VARCHAR PRIMARY KEY, Name VARCHAR NOT NULL, BirthDate DATE);\\nCREATE TABLE Prescriptions (PrescriptionID VARCHAR PRIMARY KEY, DoctorID VARCHAR REFERENCES Doctors(DoctorID), PatientID VARCHAR REFERENCES Patients(PatientID), Date DATE, Medication VARCHAR, Dosage VARCHAR);</td>\n",
       "      <td>(psycopg2.errors.UndefinedTable) missing FROM-clause entry for table \"p\"\\nLINE 1: SELECT p.PrescriptionID, pa.Name AS PatientName, pr.Medicati...\\n               ^\\n\\n[SQL: SELECT p.PrescriptionID, pa.Name AS PatientName, pr.Medication, pr.Dosage, pr.Date FROM Prescriptions pr JOIN Doctors d ON pr.DoctorID = d.DoctorID JOIN Patients pa ON pr.PatientID = pa.PatientID WHERE d.Name = 'Dr. Smith' AND pr.Date &gt;= CURRENT_DATE - INTERVAL '1 month';]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>SELECT p.product_name, p.price, sc.quantity FROM ShoppingCart sc JOIN Products p ON sc.product_id = p.product_id WHERE sc.user_id = 123;</td>\n",
       "      <td>CREATE TABLE ShoppingCart (user_id NUMBER, product_id NUMBER, quantity NUMBER);\\nCREATE TABLE Products (product_id NUMBER, product_name VARCHAR2(100), price NUMBER);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 1: CREATE TABLE ShoppingCart (user_id NUMBER, product_id NUMBER...\\n                                           ^\\n\\n[SQL: CREATE TABLE ShoppingCart (user_id NUMBER, product_id NUMBER, quantity NUMBER);\\nCREATE TABLE Products (product_id NUMBER, product_name VARCHAR2(100), price NUMBER);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 2, Position 1: Found unparsable section: 'CREATE TABLE Products (product_id NUMBER...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>SELECT p.name, g.gene_name, r.factor_description FROM patients p JOIN genes g ON p.patient_id = g.patient_id JOIN patient_diseases pd ON p.patient_id = pd.patient_id JOIN risk_factors r ON p.patient_id = r.patient_id JOIN diseases d ON pd.disease_id = d.disease_id WHERE d.disease_name = 'Breast Cancer';</td>\n",
       "      <td>CREATE TABLE patients (patient_id VARCHAR2(20), name VARCHAR2(100), birth_date DATE, gender VARCHAR2(10)); CREATE TABLE genes (gene_id VARCHAR2(20), patient_id VARCHAR2(20), gene_name VARCHAR2(50), mutation_type VARCHAR2(50)); CREATE TABLE diseases (disease_id VARCHAR2(20), disease_name VARCHAR2(50)); CREATE TABLE patient_diseases (patient_id VARCHAR2(20), disease_id VARCHAR2(20)); CREATE TABLE risk_factors (risk_factor_id VARCHAR2(20), patient_id VARCHAR2(20), factor_description VARCHAR2(255));</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 1: CREATE TABLE patients (patient_id VARCHAR2(20), name VARCHAR...\\n                                          ^\\n\\n[SQL: CREATE TABLE patients (patient_id VARCHAR2(20), name VARCHAR2(100), birth_date DATE, gender VARCHAR2(10)); CREATE TABLE genes (gene_id VARCHAR2(20), patient_id VARCHAR2(20), gene_name VARCHAR2(50), mutation_type VARCHAR2(50)); CREATE TABLE diseases (disease_id VARCHAR2(20), disease_name VARCHAR2(50)); CREATE TABLE patient_diseases (patient_id VARCHAR2(20), disease_id VARCHAR2(20)); CREATE TABLE risk_factors (risk_factor_id VARCHAR2(20), patient_id VARCHAR2(20), factor_description VARCHAR2(255));]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE patients (patient_id VARCHA...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>SELECT Properties.address, Properties.rental_price FROM Properties INNER JOIN Managers ON Properties.manager_id = Managers.manager_id WHERE Managers.name = 'John Doe';</td>\n",
       "      <td>CREATE TABLE Managers (\\n    manager_id NUMBER PRIMARY KEY,\\n    name VARCHAR2(100)\\n);\\nCREATE TABLE Properties (\\n    property_id NUMBER PRIMARY KEY,\\n    address VARCHAR2(255),\\n    rental_price NUMBER,\\n    manager_id NUMBER,\\n    FOREIGN KEY (manager_id) REFERENCES Managers(manager_id)\\n);</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 2:     manager_id NUMBER PRIMARY KEY,\\n                       ^\\n\\n[SQL: CREATE TABLE Managers (\\n    manager_id NUMBER PRIMARY KEY,\\n    name VARCHAR2(100)\\n);\\nCREATE TABLE Properties (\\n    property_id NUMBER PRIMARY KEY,\\n    address VARCHAR2(255),\\n    rental_price NUMBER,\\n    manager_id NUMBER,\\n    FOREIGN KEY (manager_id) REFERENCES Managers(manager_id)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Managers (\\n    manager_id N...'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>SELECT * FROM Clinical_Trials WHERE disease = 'Alzheimer\\'s disease' AND status = 'ongoing';</td>\n",
       "      <td>CREATE TABLE Clinical_Trials (trial_id SERIAL PRIMARY KEY, trial_name VARCHAR(255), disease VARCHAR(255), status VARCHAR(50));</td>\n",
       "      <td>(psycopg2.errors.SyntaxError) syntax error at or near \"s\"\\nLINE 1: ... FROM Clinical_Trials WHERE disease = 'Alzheimer\\'s disease'...\\n                                                             ^\\n\\n[SQL: SELECT * FROM Clinical_Trials WHERE disease = 'Alzheimer\\'s disease' AND status = 'ongoing';]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Query error: PRS: Line 1, Position 59: Found unparsable section: \"s disease' AND status = 'ongoing';\"</td>\n",
       "      <td></td>\n",
       "      <td>***Query error: Error tokenizing 'e = 'Alzheimer\\'s disease' AND status = 'ongoing''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>SELECT ProductName, AVG(Rating) as AverageRating FROM ProductReviews GROUP BY ProductName ORDER BY AverageRating DESC FETCH FIRST 5 ROWS ONLY;</td>\n",
       "      <td>CREATE TABLE ProductReviews (ProductID VARCHAR2(50), ProductName VARCHAR2(255), Rating NUMBER(2, 1), ReviewText VARCHAR2(4000));</td>\n",
       "      <td>(psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 1: CREATE TABLE ProductReviews (ProductID VARCHAR2(50), Product...\\n                                               ^\\n\\n[SQL: CREATE TABLE ProductReviews (ProductID VARCHAR2(50), ProductName VARCHAR2(255), Rating NUMBER(2, 1), ReviewText VARCHAR2(4000));]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE ProductReviews (ProductID V...'***Query error: PRS: Line 1, Position 119: Found unparsable section: 'FETCH FIRST 5 ROWS ONLY'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>SELECT product_name FROM Inventory WHERE quantity = 0;</td>\n",
       "      <td>CREATE TABLE Inventory (product_id VARCHAR2(20 PRIMARY KEY, product_name VARCHAR2(100), quantity NUMBER, last_updated DATE);</td>\n",
       "      <td>(psycopg2.errors.SyntaxError) syntax error at or near \"PRIMARY\"\\nLINE 1: CREATE TABLE Inventory (product_id VARCHAR2(20 PRIMARY KEY, ...\\n                                                       ^\\n\\n[SQL: CREATE TABLE Inventory (product_id VARCHAR2(20 PRIMARY KEY, product_name VARCHAR2(100), quantity NUMBER, last_updated DATE);]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td>***Schema error: PRS: Couldn't find closing bracket for opening bracket.</td>\n",
       "      <td></td>\n",
       "      <td>***Schema error: Expecting ). Line 1, Col: 43.\\n  CREATE TABLE Inventory (product_id \u001b[4mVARCHAR2\u001b[0m(20 PRIMARY KEY, product_name VARCHAR2(100), quantity NUMBER, last_updated DATE);</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>SELECT patients.patient_id, mri_scans.findings FROM patients JOIN mri_scans ON patients.patient_id = mri_scans.patient_id;</td>\n",
       "      <td>CREATE TABLE patients (patient_id VARCHAR(20), name VARCHAR(50), age INT);\\nCREATE TABLE mri_scans (scan_id VARCHAR(20), patient_id VARCHAR(20), findings TEXT, scan_date DATE, FOREIGN KEY (patient_id) REFERENCES patients(patient_id));</td>\n",
       "      <td>(psycopg2.errors.InvalidForeignKey) there is no unique constraint matching given keys for referenced table \"patients\"\\n\\n[SQL: CREATE TABLE patients (patient_id VARCHAR(20), name VARCHAR(50), age INT);\\nCREATE TABLE mri_scans (scan_id VARCHAR(20), patient_id VARCHAR(20), findings TEXT, scan_date DATE, FOREIGN KEY (patient_id) REFERENCES patients(patient_id));]\\n(Background on this error at: http://sqlalche.me/e/f405)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                            SQL Query  \\\n",
       "63                                                                                                                              SELECT AVG(HeartRate) AS AverageHeartRate FROM Patients WHERE Age > 60 AND VisitDate BETWEEN ADD_MONTHS(TRUNC(SYSDATE, 'MM'), -1) AND LAST_DAY(ADD_MONTHS(TRUNC(SYSDATE, 'MM'), -1));   \n",
       "136                                                                                                                                                            SELECT p.name, AVG(r.rating) AS average_rating FROM products p JOIN reviews r ON p.id = r.product_id WHERE p.category = 'electronics' GROUP BY p.name;   \n",
       "152                                                                                                                                                                     SELECT p.product_name, p.price FROM products p JOIN inventory i ON p.product_id = i.product_id WHERE p.available = 'true' AND i.quantity > 0;   \n",
       "155                                                   SELECT d.name, SUM(s.quantity_sold) as total_sales FROM sales s JOIN drugs d ON s.drug_id = d.id WHERE DATE_PART('month', s.sale_date) = DATE_PART('month', CURRENT_DATE) AND DATE_PART('year', s.sale_date) = DATE_PART('year', CURRENT_DATE) GROUP BY d.name;   \n",
       "206                                                                                                                                                                                                                                SELECT City, AVG(BroadbandSpeed) AS AverageSpeed FROM BroadbandData GROUP BY City;   \n",
       "232                                                                                                                                                              SELECT p.PropertyType, SUM(i.Amount) AS TotalInvestment FROM Investments i JOIN Properties p ON i.PropertyID = p.PropertyID GROUP BY p.PropertyType;   \n",
       "261                                                                         SELECT P.name FROM Patients P JOIN Appointments A ON P.patient_id = A.patient_id JOIN Doctors D ON A.doctor_id = D.doctor_id WHERE D.name = 'Dr. Smith' AND appointment_date BETWEEN CURRENT_DATE AND (CURRENT_DATE + INTERVAL '7 days');   \n",
       "298                                                                                                                                                                                                                                           SELECT product_name FROM products WHERE in_stock = TRUE AND price > 50;   \n",
       "311                                                                                                                                                                                                                          SELECT AVG(grade) AS average_grade FROM Students WHERE course_name = 'Data Science 101';   \n",
       "340                                                                                                                                                                                                                          SELECT COUNT(*)\\nFROM CustomerComplaints\\nWHERE DateReceived >= ADD_MONTHS(SYSDATE, -1);   \n",
       "366                                                                                                                                                                              SELECT ar.Drug_Name, ar.Severity_Level, ar.Report_Date\\nFROM Adverse_Reactions ar\\nWHERE ar.Report_Date >= ADD_MONTHS(SYSDATE, -12);   \n",
       "390                                                                                                                                                                                                                                    SELECT AVG(grade) AS average_grade FROM Students WHERE course = 'Mathematics';   \n",
       "395                                                                                                                                                                     SELECT p.product_name, AVG(r.rating) AS average_rating FROM products p JOIN reviews r ON p.product_id = r.product_id GROUP BY p.product_name;   \n",
       "409                                                                                                                                                                                                                          SELECT City, COUNT(UserID) AS ActiveUsers FROM 5GUsers WHERE IsActive = 1 GROUP BY City;   \n",
       "554                                                                                                                                                          SELECT w.warehouse_name, SUM(i.quantity) AS total_items FROM Warehouses w JOIN Inventory i ON w.warehouse_id = i.warehouse_id GROUP BY w.warehouse_name;   \n",
       "645                                  SELECT p.PrescriptionID, pa.Name AS PatientName, pr.Medication, pr.Dosage, pr.Date FROM Prescriptions pr JOIN Doctors d ON pr.DoctorID = d.DoctorID JOIN Patients pa ON pr.PatientID = pa.PatientID WHERE d.Name = 'Dr. Smith' AND pr.Date >= CURRENT_DATE - INTERVAL '1 month';   \n",
       "820                                                                                                                                                                          SELECT p.product_name, p.price, sc.quantity FROM ShoppingCart sc JOIN Products p ON sc.product_id = p.product_id WHERE sc.user_id = 123;   \n",
       "848  SELECT p.name, g.gene_name, r.factor_description FROM patients p JOIN genes g ON p.patient_id = g.patient_id JOIN patient_diseases pd ON p.patient_id = pd.patient_id JOIN risk_factors r ON p.patient_id = r.patient_id JOIN diseases d ON pd.disease_id = d.disease_id WHERE d.disease_name = 'Breast Cancer';   \n",
       "864                                                                                                                                           SELECT Properties.address, Properties.rental_price FROM Properties INNER JOIN Managers ON Properties.manager_id = Managers.manager_id WHERE Managers.name = 'John Doe';   \n",
       "869                                                                                                                                                                                                                      SELECT * FROM Clinical_Trials WHERE disease = 'Alzheimer\\'s disease' AND status = 'ongoing';   \n",
       "872                                                                                                                                                                    SELECT ProductName, AVG(Rating) as AverageRating FROM ProductReviews GROUP BY ProductName ORDER BY AverageRating DESC FETCH FIRST 5 ROWS ONLY;   \n",
       "890                                                                                                                                                                                                                                                            SELECT product_name FROM Inventory WHERE quantity = 0;   \n",
       "902                                                                                                                                                                                        SELECT patients.patient_id, mri_scans.findings FROM patients JOIN mri_scans ON patients.patient_id = mri_scans.patient_id;   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Context  \\\n",
       "63                                                                                                                                                                                                                                                                                                                                                                             CREATE TABLE Patients (\\n    PatientID INT PRIMARY KEY,\\n    Name VARCHAR2(255),\\n    Age INT,\\n    VisitDate DATE,\\n    HeartRate INT\\n);   \n",
       "136                                                                 CREATE TABLE customers (id NUMBER PRIMARY KEY, name VARCHAR2(50), email VARCHAR2(100)); CREATE TABLE products (id NUMBER PRIMARY KEY, name VARCHAR2(100), category VARCHAR2(50)); CREATE TABLE reviews (id NUMBER PRIMARY KEY, customer_id NUMBER, product_id NUMBER, rating NUMBER, review TEXT, CONSTRAINT fk_customer FOREIGN KEY (customer_id) REFERENCES customers(id), CONSTRAINT fk_product FOREIGN KEY (product_id) REFERENCES products(id));   \n",
       "152                                                                                                                                                                                                CREATE TABLE products (\\n    product_id VARCHAR2(50) PRIMARY KEY,\\n    product_name VARCHAR2(255),\\n    price NUMBER(10, 2),\\n    available BOOLEAN\\n);\\n\\nCREATE TABLE inventory (\\n    inventory_id VARCHAR2(50) PRIMARY KEY,\\n    product_id VARCHAR2(50) REFERENCES products(product_id),\\n    quantity NUMBER\\n);   \n",
       "155                                                                                                                                                                                                                                                                                                                     CREATE TABLE sales (id SERIAL PRIMARY KEY, drug_id INTEGER REFERENCES drugs(id), quantity_sold INTEGER, sale_date DATE);\\nCREATE TABLE drugs (id SERIAL PRIMARY KEY, name VARCHAR(255) NOT NULL);   \n",
       "206                                                                                                                                                                                                                                                                                                                                                                                                                                CREATE TABLE BroadbandData (\\n    City VARCHAR2(100),\\n    BroadbandSpeed NUMBER\\n);\\n   \n",
       "232                                                                                                                                                                                                                                                               CREATE TABLE Investments (InvestmentID VARCHAR2(20), InvestorID VARCHAR2(20), PropertyID VARCHAR2(20), Amount NUMBER(10, 2), InvestmentDate DATE); CREATE TABLE Properties (PropertyID VARCHAR2(20), PropertyType VARCHAR2(50), Address VARCHAR2(255));   \n",
       "261                                                                              CREATE TABLE Patients (patient_id SERIAL PRIMARY KEY, name VARCHAR(100), age INT, gender CHAR(1)); CREATE TABLE Appointments (appointment_id SERIAL PRIMARY KEY, patient_id INT, doctor_id INT, appointment_date DATE, FOREIGN KEY (patient_id) REFERENCES Patients(patient_id), FOREIGN KEY (doctor_id) REFERENCES Doctors(doctor_id)); CREATE TABLE Doctors (doctor_id SERIAL PRIMARY KEY, name VARCHAR(100), specialty VARCHAR(100));   \n",
       "298                                                                                                                                                                                                                                                                                                                                                                                                    CREATE TABLE products (product_id NUMBER PRIMARY KEY, product_name VARCHAR2(255), price NUMBER, in_stock BOOLEAN);   \n",
       "311                                                                                                                                                                                                                                           CREATE TABLE Students (\\n    student_id VARCHAR2(50),\\n    student_name VARCHAR2(100),\\n    grade NUMBER(3, 2),\\n    course_name VARCHAR2(100)\\n);\\n\\nCREATE TABLE Courses (\\n    course_id VARCHAR2(50),\\n    course_name VARCHAR2(100),\\n    instructor VARCHAR2(100)\\n);   \n",
       "340                                                                                                                                                                                                                                                                                                                                      CREATE TABLE CustomerComplaints (\\n    ComplaintID INT PRIMARY KEY,\\n    CustomerID INT,\\n    DateReceived DATE,\\n    ComplaintText VARCHAR2(4000),\\n    Status VARCHAR2(50)\\n);   \n",
       "366                                                                                                                                                                                                                                                                           CREATE TABLE Adverse_Reactions (\\n    Reaction_ID VARCHAR2(50),\\n    Report_Date DATE,\\n    Drug_Name VARCHAR2(100),\\n    Severity_Level VARCHAR2(50)\\n);\\nCREATE TABLE Drugs (\\n    Drug_ID VARCHAR2(50),\\n    Drug_Name VARCHAR2(100)\\n);   \n",
       "390                                                                                                                                                                                                                                                                             CREATE TABLE Students (\\n    student_id VARCHAR2(10),\\n    name VARCHAR2(100),\\n    age NUMBER,\\n    grade NUMBER,\\n    course VARCHAR2(50)\\n);\\n\\nCREATE TABLE Courses (\\n    course_id VARCHAR2(10),\\n    course_name VARCHAR2(100)\\n);   \n",
       "395                                                                                                                                                                                CREATE TABLE customers (customer_id VARCHAR2(50), name VARCHAR2(100), email VARCHAR2(100)); CREATE TABLE products (product_id VARCHAR2(50), product_name VARCHAR2(100), category VARCHAR2(100)); CREATE TABLE reviews (review_id VARCHAR2(50), customer_id VARCHAR2(50), product_id VARCHAR2(50), rating NUMBER(3), review_date DATE);   \n",
       "409                                                                                                                                                                                                                                                                                                                                                                                            CREATE TABLE 5GUsers (UserID VARCHAR(255), UserName VARCHAR(255), City VARCHAR(255), IsActive INT, SubscriptionDate DATE);   \n",
       "554                                                                                                                                                                                                                                                                  CREATE TABLE Warehouses (warehouse_id NUMBER PRIMARY KEY, warehouse_name VARCHAR2(100));\\nCREATE TABLE Inventory (item_id NUMBER PRIMARY KEY, warehouse_id NUMBER, quantity NUMBER, FOREIGN KEY (warehouse_id) REFERENCES Warehouses(warehouse_id));   \n",
       "645                                                                                                       CREATE TABLE Doctors (DoctorID VARCHAR PRIMARY KEY, Name VARCHAR NOT NULL, Specialty VARCHAR);\\nCREATE TABLE Patients (PatientID VARCHAR PRIMARY KEY, Name VARCHAR NOT NULL, BirthDate DATE);\\nCREATE TABLE Prescriptions (PrescriptionID VARCHAR PRIMARY KEY, DoctorID VARCHAR REFERENCES Doctors(DoctorID), PatientID VARCHAR REFERENCES Patients(PatientID), Date DATE, Medication VARCHAR, Dosage VARCHAR);   \n",
       "820                                                                                                                                                                                                                                                                                                                                                 CREATE TABLE ShoppingCart (user_id NUMBER, product_id NUMBER, quantity NUMBER);\\nCREATE TABLE Products (product_id NUMBER, product_name VARCHAR2(100), price NUMBER);   \n",
       "848  CREATE TABLE patients (patient_id VARCHAR2(20), name VARCHAR2(100), birth_date DATE, gender VARCHAR2(10)); CREATE TABLE genes (gene_id VARCHAR2(20), patient_id VARCHAR2(20), gene_name VARCHAR2(50), mutation_type VARCHAR2(50)); CREATE TABLE diseases (disease_id VARCHAR2(20), disease_name VARCHAR2(50)); CREATE TABLE patient_diseases (patient_id VARCHAR2(20), disease_id VARCHAR2(20)); CREATE TABLE risk_factors (risk_factor_id VARCHAR2(20), patient_id VARCHAR2(20), factor_description VARCHAR2(255));   \n",
       "864                                                                                                                                                                                                               CREATE TABLE Managers (\\n    manager_id NUMBER PRIMARY KEY,\\n    name VARCHAR2(100)\\n);\\nCREATE TABLE Properties (\\n    property_id NUMBER PRIMARY KEY,\\n    address VARCHAR2(255),\\n    rental_price NUMBER,\\n    manager_id NUMBER,\\n    FOREIGN KEY (manager_id) REFERENCES Managers(manager_id)\\n);   \n",
       "869                                                                                                                                                                                                                                                                                                                                                                                        CREATE TABLE Clinical_Trials (trial_id SERIAL PRIMARY KEY, trial_name VARCHAR(255), disease VARCHAR(255), status VARCHAR(50));   \n",
       "872                                                                                                                                                                                                                                                                                                                                                                                      CREATE TABLE ProductReviews (ProductID VARCHAR2(50), ProductName VARCHAR2(255), Rating NUMBER(2, 1), ReviewText VARCHAR2(4000));   \n",
       "890                                                                                                                                                                                                                                                                                                                                                                                          CREATE TABLE Inventory (product_id VARCHAR2(20 PRIMARY KEY, product_name VARCHAR2(100), quantity NUMBER, last_updated DATE);   \n",
       "902                                                                                                                                                                                                                                                                            CREATE TABLE patients (patient_id VARCHAR(20), name VARCHAR(50), age INT);\\nCREATE TABLE mri_scans (scan_id VARCHAR(20), patient_id VARCHAR(20), findings TEXT, scan_date DATE, FOREIGN KEY (patient_id) REFERENCES patients(patient_id));   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                error_msg_postgresql  \\\n",
       "63                                                                                                                                                                                                                                                                                                                                                                                                                                              (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 3:     Name VARCHAR2(255),\\n                 ^\\n\\n[SQL: CREATE TABLE Patients (\\n    PatientID INT PRIMARY KEY,\\n    Name VARCHAR2(255),\\n    Age INT,\\n    VisitDate DATE,\\n    HeartRate INT\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "136                                                                          (psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 1: CREATE TABLE customers (id NUMBER PRIMARY KEY, name VARCHAR2...\\n                                   ^\\n\\n[SQL: CREATE TABLE customers (id NUMBER PRIMARY KEY, name VARCHAR2(50), email VARCHAR2(100)); CREATE TABLE products (id NUMBER PRIMARY KEY, name VARCHAR2(100), category VARCHAR2(50)); CREATE TABLE reviews (id NUMBER PRIMARY KEY, customer_id NUMBER, product_id NUMBER, rating NUMBER, review TEXT, CONSTRAINT fk_customer FOREIGN KEY (customer_id) REFERENCES customers(id), CONSTRAINT fk_product FOREIGN KEY (product_id) REFERENCES products(id));]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "152                                                                                                                                                                                                                                          (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     product_id VARCHAR2(50) PRIMARY KEY,\\n                       ^\\n\\n[SQL: CREATE TABLE products (\\n    product_id VARCHAR2(50) PRIMARY KEY,\\n    product_name VARCHAR2(255),\\n    price NUMBER(10, 2),\\n    available BOOLEAN\\n);\\n\\nCREATE TABLE inventory (\\n    inventory_id VARCHAR2(50) PRIMARY KEY,\\n    product_id VARCHAR2(50) REFERENCES products(product_id),\\n    quantity NUMBER\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "155                                                                                                                                                                                                                                                                                                                                                                                                                                           (psycopg2.errors.UndefinedTable) relation \"drugs\" does not exist\\n\\n[SQL: CREATE TABLE sales (id SERIAL PRIMARY KEY, drug_id INTEGER REFERENCES drugs(id), quantity_sold INTEGER, sale_date DATE);\\nCREATE TABLE drugs (id SERIAL PRIMARY KEY, name VARCHAR(255) NOT NULL);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "206                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     City VARCHAR2(100),\\n                 ^\\n\\n[SQL: CREATE TABLE BroadbandData (\\n    City VARCHAR2(100),\\n    BroadbandSpeed NUMBER\\n);\\n]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "232                                                                                                                                                                                                                                                          (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 1: CREATE TABLE Investments (InvestmentID VARCHAR2(20), Investo...\\n                                               ^\\n\\n[SQL: CREATE TABLE Investments (InvestmentID VARCHAR2(20), InvestorID VARCHAR2(20), PropertyID VARCHAR2(20), Amount NUMBER(10, 2), InvestmentDate DATE); CREATE TABLE Properties (PropertyID VARCHAR2(20), PropertyType VARCHAR2(50), Address VARCHAR2(255));]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "261                                                                                                                                                                                                  (psycopg2.errors.UndefinedTable) relation \"doctors\" does not exist\\n\\n[SQL: CREATE TABLE Patients (patient_id SERIAL PRIMARY KEY, name VARCHAR(100), age INT, gender CHAR(1)); CREATE TABLE Appointments (appointment_id SERIAL PRIMARY KEY, patient_id INT, doctor_id INT, appointment_date DATE, FOREIGN KEY (patient_id) REFERENCES Patients(patient_id), FOREIGN KEY (doctor_id) REFERENCES Doctors(doctor_id)); CREATE TABLE Doctors (doctor_id SERIAL PRIMARY KEY, name VARCHAR(100), specialty VARCHAR(100));]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "298                                                                                                                                                                                                                                                                                                                                                                                                      (psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 1: CREATE TABLE products (product_id NUMBER PRIMARY KEY, produc...\\n                                          ^\\n\\n[SQL: CREATE TABLE products (product_id NUMBER PRIMARY KEY, product_name VARCHAR2(255), price NUMBER, in_stock BOOLEAN);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "311                                                                                                                                                                                                                                                                                                 (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     student_id VARCHAR2(50),\\n                       ^\\n\\n[SQL: CREATE TABLE Students (\\n    student_id VARCHAR2(50),\\n    student_name VARCHAR2(100),\\n    grade NUMBER(3, 2),\\n    course_name VARCHAR2(100)\\n);\\n\\nCREATE TABLE Courses (\\n    course_id VARCHAR2(50),\\n    course_name VARCHAR2(100),\\n    instructor VARCHAR2(100)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "340                                                                                                                                                                                                                                                                                                                                                                                    (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 5:     ComplaintText VARCHAR2(4000),\\n                          ^\\n\\n[SQL: CREATE TABLE CustomerComplaints (\\n    ComplaintID INT PRIMARY KEY,\\n    CustomerID INT,\\n    DateReceived DATE,\\n    ComplaintText VARCHAR2(4000),\\n    Status VARCHAR2(50)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "366                                                                                                                                                                                                                                                                                                                               (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     Reaction_ID VARCHAR2(50),\\n                        ^\\n\\n[SQL: CREATE TABLE Adverse_Reactions (\\n    Reaction_ID VARCHAR2(50),\\n    Report_Date DATE,\\n    Drug_Name VARCHAR2(100),\\n    Severity_Level VARCHAR2(50)\\n);\\nCREATE TABLE Drugs (\\n    Drug_ID VARCHAR2(50),\\n    Drug_Name VARCHAR2(100)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "390                                                                                                                                                                                                                                                                                                                                   (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 2:     student_id VARCHAR2(10),\\n                       ^\\n\\n[SQL: CREATE TABLE Students (\\n    student_id VARCHAR2(10),\\n    name VARCHAR2(100),\\n    age NUMBER,\\n    grade NUMBER,\\n    course VARCHAR2(50)\\n);\\n\\nCREATE TABLE Courses (\\n    course_id VARCHAR2(10),\\n    course_name VARCHAR2(100)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "395                                                                                                                                                                              (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 1: CREATE TABLE customers (customer_id VARCHAR2(50), name VARCH...\\n                                            ^\\n\\n[SQL: CREATE TABLE customers (customer_id VARCHAR2(50), name VARCHAR2(100), email VARCHAR2(100)); CREATE TABLE products (product_id VARCHAR2(50), product_name VARCHAR2(100), category VARCHAR2(100)); CREATE TABLE reviews (review_id VARCHAR2(50), customer_id VARCHAR2(50), product_id VARCHAR2(50), rating NUMBER(3), review_date DATE);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "409                                                                                                                                                                                                                                                                                                                                                                                                (psycopg2.errors.SyntaxError) trailing junk after numeric literal at or near \"5G\"\\nLINE 1: CREATE TABLE 5GUsers (UserID VARCHAR(255), UserName VARCHAR(...\\n                     ^\\n\\n[SQL: CREATE TABLE 5GUsers (UserID VARCHAR(255), UserName VARCHAR(255), City VARCHAR(255), IsActive INT, SubscriptionDate DATE);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "554                                                                                                                                                                                                                                                                (psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 1: CREATE TABLE Warehouses (warehouse_id NUMBER PRIMARY KEY, wa...\\n                                              ^\\n\\n[SQL: CREATE TABLE Warehouses (warehouse_id NUMBER PRIMARY KEY, warehouse_name VARCHAR2(100));\\nCREATE TABLE Inventory (item_id NUMBER PRIMARY KEY, warehouse_id NUMBER, quantity NUMBER, FOREIGN KEY (warehouse_id) REFERENCES Warehouses(warehouse_id));]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "645                                                                                                                                                                                                                                                         (psycopg2.errors.UndefinedTable) missing FROM-clause entry for table \"p\"\\nLINE 1: SELECT p.PrescriptionID, pa.Name AS PatientName, pr.Medicati...\\n               ^\\n\\n[SQL: SELECT p.PrescriptionID, pa.Name AS PatientName, pr.Medication, pr.Dosage, pr.Date FROM Prescriptions pr JOIN Doctors d ON pr.DoctorID = d.DoctorID JOIN Patients pa ON pr.PatientID = pa.PatientID WHERE d.Name = 'Dr. Smith' AND pr.Date >= CURRENT_DATE - INTERVAL '1 month';]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "820                                                                                                                                                                                                                                                                                                                                                  (psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 1: CREATE TABLE ShoppingCart (user_id NUMBER, product_id NUMBER...\\n                                           ^\\n\\n[SQL: CREATE TABLE ShoppingCart (user_id NUMBER, product_id NUMBER, quantity NUMBER);\\nCREATE TABLE Products (product_id NUMBER, product_name VARCHAR2(100), price NUMBER);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "848  (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 1: CREATE TABLE patients (patient_id VARCHAR2(20), name VARCHAR...\\n                                          ^\\n\\n[SQL: CREATE TABLE patients (patient_id VARCHAR2(20), name VARCHAR2(100), birth_date DATE, gender VARCHAR2(10)); CREATE TABLE genes (gene_id VARCHAR2(20), patient_id VARCHAR2(20), gene_name VARCHAR2(50), mutation_type VARCHAR2(50)); CREATE TABLE diseases (disease_id VARCHAR2(20), disease_name VARCHAR2(50)); CREATE TABLE patient_diseases (patient_id VARCHAR2(20), disease_id VARCHAR2(20)); CREATE TABLE risk_factors (risk_factor_id VARCHAR2(20), patient_id VARCHAR2(20), factor_description VARCHAR2(255));]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "864                                                                                                                                                                                                                                                                 (psycopg2.errors.UndefinedObject) type \"number\" does not exist\\nLINE 2:     manager_id NUMBER PRIMARY KEY,\\n                       ^\\n\\n[SQL: CREATE TABLE Managers (\\n    manager_id NUMBER PRIMARY KEY,\\n    name VARCHAR2(100)\\n);\\nCREATE TABLE Properties (\\n    property_id NUMBER PRIMARY KEY,\\n    address VARCHAR2(255),\\n    rental_price NUMBER,\\n    manager_id NUMBER,\\n    FOREIGN KEY (manager_id) REFERENCES Managers(manager_id)\\n);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "869                                                                                                                                                                                                                                                                                                                                                                                                           (psycopg2.errors.SyntaxError) syntax error at or near \"s\"\\nLINE 1: ... FROM Clinical_Trials WHERE disease = 'Alzheimer\\'s disease'...\\n                                                             ^\\n\\n[SQL: SELECT * FROM Clinical_Trials WHERE disease = 'Alzheimer\\'s disease' AND status = 'ongoing';]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "872                                                                                                                                                                                                                                                                                                                                                                                 (psycopg2.errors.UndefinedObject) type \"varchar2\" does not exist\\nLINE 1: CREATE TABLE ProductReviews (ProductID VARCHAR2(50), Product...\\n                                               ^\\n\\n[SQL: CREATE TABLE ProductReviews (ProductID VARCHAR2(50), ProductName VARCHAR2(255), Rating NUMBER(2, 1), ReviewText VARCHAR2(4000));]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "890                                                                                                                                                                                                                                                                                                                                                                              (psycopg2.errors.SyntaxError) syntax error at or near \"PRIMARY\"\\nLINE 1: CREATE TABLE Inventory (product_id VARCHAR2(20 PRIMARY KEY, ...\\n                                                       ^\\n\\n[SQL: CREATE TABLE Inventory (product_id VARCHAR2(20 PRIMARY KEY, product_name VARCHAR2(100), quantity NUMBER, last_updated DATE);]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "902                                                                                                                                                                                                                                                                                                                                             (psycopg2.errors.InvalidForeignKey) there is no unique constraint matching given keys for referenced table \"patients\"\\n\\n[SQL: CREATE TABLE patients (patient_id VARCHAR(20), name VARCHAR(50), age INT);\\nCREATE TABLE mri_scans (scan_id VARCHAR(20), patient_id VARCHAR(20), findings TEXT, scan_date DATE, FOREIGN KEY (patient_id) REFERENCES patients(patient_id));]\\n(Background on this error at: http://sqlalche.me/e/f405)   \n",
       "\n",
       "                                                                                                                                                                                                 error_msgs_sqlfluff  \\\n",
       "63                                                                                                ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Patients (\\n    PatientID IN...'   \n",
       "136                                                                                                ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE customers (id NUMBER PRIMAR...'   \n",
       "152                                                                                               ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE products (\\n    product_id V...'   \n",
       "155                                                                                                                                                                                                                    \n",
       "206                                                                                               ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE BroadbandData (\\n    City VA...'   \n",
       "232                                                                                                ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Investments (InvestmentID V...'   \n",
       "261                                                                                                                                                                                                                    \n",
       "298                                                                                                ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE products (product_id NUMBER...'   \n",
       "311                                                                                               ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Students (\\n    student_id V...'   \n",
       "340                                                                                               ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE CustomerComplaints (\\n    Co...'   \n",
       "366                                                                                               ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Adverse_Reactions (\\n    Rea...'   \n",
       "390                                                                                               ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Students (\\n    student_id V...'   \n",
       "395                                                                                                ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE customers (customer_id VARC...'   \n",
       "409                                                                                                                                                                                                                    \n",
       "554                                                                                                ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Warehouses (warehouse_id NU...'   \n",
       "645                                                                                                                                                                                                                    \n",
       "820                                                                                                ***Schema error: PRS: Line 2, Position 1: Found unparsable section: 'CREATE TABLE Products (product_id NUMBER...'   \n",
       "848                                                                                                ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE patients (patient_id VARCHA...'   \n",
       "864                                                                                               ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE Managers (\\n    manager_id N...'   \n",
       "869                                                                                                         ***Query error: PRS: Line 1, Position 59: Found unparsable section: \"s disease' AND status = 'ongoing';\"   \n",
       "872  ***Schema error: PRS: Line 1, Position 1: Found unparsable section: 'CREATE TABLE ProductReviews (ProductID V...'***Query error: PRS: Line 1, Position 119: Found unparsable section: 'FETCH FIRST 5 ROWS ONLY'   \n",
       "890                                                                                                                                         ***Schema error: PRS: Couldn't find closing bracket for opening bracket.   \n",
       "902                                                                                                                                                                                                                    \n",
       "\n",
       "    error_msgs_sqlquery  \\\n",
       "63                        \n",
       "136                       \n",
       "152                       \n",
       "155                       \n",
       "206                       \n",
       "232                       \n",
       "261                       \n",
       "298                       \n",
       "311                       \n",
       "340                       \n",
       "366                       \n",
       "390                       \n",
       "395                       \n",
       "409                       \n",
       "554                       \n",
       "645                       \n",
       "820                       \n",
       "848                       \n",
       "864                       \n",
       "869                       \n",
       "872                       \n",
       "890                       \n",
       "902                       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    error_msgs_sqlglot  \n",
       "63                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "136                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "152                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "155                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "206                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "232                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "261                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "298                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "311                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "340                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "366                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "390                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "395                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "409  ***Schema error: Expected table name but got <Token token_type: TokenType.NUMBER, text: 5, line: 1, col: 14, start: 13, end: 13, comments: []>. Line 1, Col: 14.\\n  CREATE TABLE \u001b[4m5\u001b[0mGUsers (UserID VARCHAR(255), UserName VARCHAR(255), City VARCHAR(255), IsActive INT, SubscriptionDat***Query error: Expected table name but got <Token token_type: TokenType.NUMBER, text: 5, line: 1, col: 48, start: 47, end: 47, comments: []>. Line 1, Col: 48.\\n  SELECT City, COUNT(UserID) AS ActiveUsers FROM \u001b[4m5\u001b[0mGUsers WHERE IsActive = 1 GROUP BY City;  \n",
       "554                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "645                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "820                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "848                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "864                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "869                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ***Query error: Error tokenizing 'e = 'Alzheimer\\'s disease' AND status = 'ongoing''  \n",
       "872                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "890                                                                                                                                                                                                                                                                                                                                                                             ***Schema error: Expecting ). Line 1, Col: 43.\\n  CREATE TABLE Inventory (product_id \u001b[4mVARCHAR2\u001b[0m(20 PRIMARY KEY, product_name VARCHAR2(100), quantity NUMBER, last_updated DATE);  \n",
       "902                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect = dialects[1]\n",
    "dialect_name = dialect.lower().replace(' ', '')\n",
    "print(dialect)\n",
    "df = sql_queries[(sql_queries['Dialect'] == dialect) & \n",
    "                 ((sql_queries['is_valid_sql_aggregate'] == False) | \n",
    "                  (sql_queries[f'is_valid_{dialect_name}'] == False))]\n",
    "df[['SQL Query', 'Context', f'error_msg_{dialect_name}', 'error_msgs_sqlfluff', 'error_msgs_sqlquery', 'error_msgs_sqlglot']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    CREATE TABLE Properties (PropertyID INT PRIMARY KEY, Address NVARCHAR(255), OwnerID INT); CREATE TABLE Rentals (RentalID INT PRIMARY KEY, PropertyID INT FOREIGN KEY REFERENCES Properties(PropertyID), TenantID INT, RentAmount DECIMAL(10,2), RentDate DATE); CREATE TABLE Owners (OwnerID INT PRIMARY KEY, OwnerName NVARCHAR(255));\n",
      "5                                                                                                                                                                                                                       CREATE TABLE Machines (\\n  machine_id SERIAL PRIMARY KEY,\\n  machine_name VARCHAR(255),\\n  last_active_date DATE\\n);\n",
      "Name: Context, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sql_queries['Context'].loc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Code Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_code_with_method(df, method='compile', language='python'):\n",
    "    if language == 'python':\n",
    "        methods = python_check_methods\n",
    "    elif language == 'typescript':\n",
    "        methods = typescript_check_methods\n",
    "    elif language == 'sql':\n",
    "        raise ValueError('SQL not supported as it requires a schema as input')\n",
    "    else:\n",
    "        raise ValueError('language not supported')\n",
    "    func = methods[method]\n",
    "    df[f'check_{method}'] = df['code'].apply(func)\n",
    "    df[f'is_valid_{language}_with_{method}'] = df[f'check_{method}'].apply(lambda x: x[0])\n",
    "    df[f'{method}_error'] = df[f'check_{method}'].apply(lambda x: x[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_valid_python_with_compile\n",
      "True     976\n",
      "False     24\n",
      "Name: count, dtype: int64\n",
      "is_valid_python_with_ast\n",
      "True     976\n",
      "False     24\n",
      "Name: count, dtype: int64\n",
      "is_valid_python_with_pyflakes\n",
      "True     667\n",
      "False    333\n",
      "Name: count, dtype: int64\n",
      "is_valid_python_with_parso\n",
      "True    1000\n",
      "Name: count, dtype: int64\n",
      "is_valid_python_with_mypy\n",
      "True     913\n",
      "False     87\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "python_check_methods = {\n",
    "    'compile': is_valid_python_with_complie,\n",
    "    'ast': is_valid_python_with_ast,\n",
    "    'pyflakes': is_valid_python_with_pyflakes,\n",
    "    'parso': is_valid_python_with_parso,\n",
    "    'mypy': is_valid_python_with_mypy\n",
    "}\n",
    "\n",
    "for method in python_check_methods.keys():\n",
    "    python_codes = check_code_with_method(python_codes, method)\n",
    "    print(python_codes[f'is_valid_python_with_{method}'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>compile_error</th>\n",
       "      <th>ast_error</th>\n",
       "      <th>is_valid_python_with_pyflakes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>import threading\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Function to process user sessions in parallel\\ndef process_session(session):\\n    # Analyze user behavior in real-time\\n    user_behavior = analyze_user_behavior(session)\\n\\n    # Detect signs of potential cart abandonment\\n    is_abandonment = detect_abandonment(user_behavior)\\n\\n    if is_abandonment:\\n        # Trigger appropriate interventions (e.g., sending a reminder email or push notification)\\n        trigger_intervention(session)\\n\\n# Function to analyze user behavior in real-time\\ndef analyze_user_behavior(session):\\n    # Implement logic to analyze user behavior\\n    # ...\\n\\n    return user_behavior\\n\\n# Function to detect signs of potential cart abandonment\\ndef detect_abandonment(user_behavior):\\n    # Implement logic to detect signs of potential cart abandonment\\n    # ...\\n\\n    return is_abandonment\\n\\n# Function to trigger appropriate interventions (e.g., sending a remi...</td>\n",
       "      <td>expected an indented block (&lt;string&gt;, line 37)</td>\n",
       "      <td>expected an indented block (&lt;unknown&gt;, line 37)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nfrom multiprocessing import Pool\\n\\n# Preprocess the data\\ndef preprocess_data(data):\\n    # Perform data cleaning, feature engineering, and transformation\\n    # ...\\n\\n    return processed_data\\n\\n# Design a concurrent and parallel processing system\\ndef process_data_parallel(data_chunks):\\n    with Pool() as pool:\\n        processed_data = pool.map(preprocess_data, data_chunks)\\n\\n    return processed_data\\n\\n# Build the CLV prediction model\\ndef build_clv_model(processed_data):\\n    # Split the data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        processed_data.drop('CLV', axis=1),\\n        processed_data['CLV'],\\n        test_size=0.2,\\n        random_state=42\\n    )\\n\\n    # Train a random forest regression model\\n    model = RandomFor...</td>\n",
       "      <td>expected an indented block (&lt;string&gt;, line 48)</td>\n",
       "      <td>expected an indented block (&lt;unknown&gt;, line 48)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>import asyncio\\n\\nasync def ingest_data(spacecraft):\\n    # Connect to spacecraft and start streaming data\\n    while True:\\n        data = await spacecraft.receive_data()\\n        yield data\\n```\\n\\n2. **Data Processing**: Use `pandas` for data processing and analysis. This will allow us to handle large volumes of data efficiently and perform various operations on it.\\n\\n```python\\nimport pandas as pd\\n\\nasync def process_data(data):\\n    # Convert data to pandas DataFrame\\n    df = pd.DataFrame(data)\\n\\n    # Perform various operations on DataFrame (filtering, aggregation, etc.)\\n    processed_df = df.groupby('timestamp').mean()\\n\\n    return processed_df\\n```\\n\\n3. **Data Analysis**: Use `seaborn` or `matplotlib` for data visualization. This will allow us to gain insights from our data.\\n\\n```python\\nimport seaborn as sns\\n\\nasync def analyze_data(processed_df):\\n    # Generate a heatmap of the data\\n    sns.heatmap(processed_df.corr())\\n```\\n\\n4. **Error Handling**: Implement e...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 8)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 8)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>import numpy as np\\nimport matplotlib.pyplot as plt\\n\\ndef q_learning(state_space, action_space, reward_function, learning_rate, discount_factor, num_episodes, epsilon=0.1):\\n    # Initialize Q-table with zeros\\n    q_table = np.zeros((state_space, action_space))\\n\\n    # Initialize list to store learning curve\\n    learning_curve = []\\n\\n    # Loop through episodes\\n    for episode in range(num_episodes):\\n        # Reset state at beginning of episode\\n        state = 0\\n\\n        # Initialize total reward for episode\\n        total_reward = 0\\n\\n        # Loop through steps in episode\\n        for step in range(100):\\n            # Select action based on epsilon-greedy policy\\n            if np.random.uniform() &lt; epsilon:\\n                action = np.random.choice(action_space)\\n            else:\\n                action = np.argmax(q_table[state])\\n\\n            # Receive reward and next state from environment\\n            reward = reward_function(state, action)\\n            next...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 55)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 55)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>import sys\\n\\ndef count_error_code(log_file_path, error_code):\\n    count = 0\\n    with open(log_file_path, 'r') as file:\\n        for line in file:\\n            if error_code in line:\\n                count += 1\\n    return count\\n\\nif __name__ == \"__main__\":\\n    if len(sys.argv) != 3:\\n        print(\"Usage: python script.py &lt;log_file_path&gt; &lt;error_code&gt;\")\\n        sys.exit(1)\\n\\n    log_file_path = sys.argv[1]\\n    error_code = sys.argv[2]\\n\\n    error_code_count = count_error_code(log_file_path, error_code)\\n    print(f\"The count of error code '{error_code}' in the log file is: {error_code_count}\")\\n```\\n\\nTo use this script, save it as `count_error_code.py` and run it using the command:\\n\\n```bash\\npython count_error_code.py &lt;log_file_path&gt; &lt;error_code&gt;</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 21)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 21)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>import numpy as np\\n\\nclass MRI_Scanner:\\n    def __init__(self, patient_id, scan_date, scan_type):\\n        self.patient_id = patient_id\\n        self.scan_date = scan_date\\n        self.scan_type = scan_type\\n\\n    def simulate_scanning(self):\\n        try:\\n            if not isinstance(self.patient_id, int) or self.patient_id &lt;= 0:\\n                raise ValueError(\"Invalid patient ID\")\\n\\n            if not isinstance(self.scan_date, str) or len(self.scan_date.split(\"-\")) != 3:\\n                raise ValueError(\"Incorrect scan date format. Expected format: YYYY-MM-DD\")\\n\\n            if self.scan_type not in [\"T1\", \"T2\", \"FLAIR\"]:\\n                raise ValueError(\"Unsupported scan type. Expected values: T1, T2, FLAIR\")\\n\\n            np.random.seed(hash(self.patient_id) ^ hash(self.scan_date) ^ hash(self.scan_type))\\n            synthetic_image = np.random.randint(0, 256, (128, 128, 128))\\n\\n            return synthetic_image\\n        except ValueError as e:\\n            retu...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 28)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 28)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>class VirtualClassroom:\\n    def __init__(self, teacher=None, students=None, subject=None, room_capacity=0):\\n        self.teacher = teacher\\n        self.students = students if students else []\\n        self.subject = subject\\n        self.room_capacity = room_capacity\\n\\n    def add_student(self, student):\\n        if len(self.students) &gt;= self.room_capacity:\\n            raise Exception(\"Room capacity exceeded\")\\n        self.students.append(student)\\n\\n    def remove_student(self, student):\\n        if student in self.students:\\n            self.students.remove(student)\\n\\n    def assign_teacher(self, teacher):\\n        if self.teacher:\\n            raise Exception(\"Teacher already assigned\")\\n        self.teacher = teacher\\n\\n    def change_subject(self, subject):\\n        self.subject = subject\\n\\n    def display_classroom_details(self):\\n        print(f\"Teacher: {self.teacher}\")\\n        print(f\"Students: {', '.join(self.students)}\")\\n        print(f\"Subject: {self.subject}\"...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 30)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 30)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>import pandas as pd\\nimport random\\n\\ndef quiz_generator(questions_file_path):\\n    try:\\n        # Read the CSV file using pandas\\n        df = pd.read_csv(questions_file_path)\\n\\n        # Check if the file is empty\\n        if df.empty:\\n            return \"Error: The file is empty.\"\\n\\n        # Filter the questions by difficulty level\\n        easy_questions = df[df['difficulty'] == 'easy']\\n        medium_questions = df[df['difficulty'] == 'medium']\\n        hard_questions = df[df['difficulty'] == 'hard']\\n\\n        # Check if there are at least 3 questions of each difficulty level\\n        if len(easy_questions) &lt; 3 or len(medium_questions) &lt; 3 or len(hard_questions) &lt; 3:\\n            return \"Error: There should be at least 3 questions of each difficulty level.\"\\n\\n        # Randomly select 3 questions of each difficulty level\\n        selected_easy = easy_questions.sample(3)\\n        selected_medium = medium_questions.sample(3)\\n        selected_hard = hard_questions.sample...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 36)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 36)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>import numpy as np\\nfrom PIL import Image, ImageFilter\\n\\nclass ImageProcessor:\\n    def __init__(self, image_path):\\n        self.image_path = image_path\\n        try:\\n            self.image = Image.open(image_path)\\n        except Exception as e:\\n            print(f\"Error opening image: {e}\")\\n\\n    def to_grayscale(self):\\n        try:\\n            self.image = self.image.convert('L')\\n        except Exception as e:\\n            print(f\"Error converting to grayscale: {e}\")\\n\\n    def resize(self, size):\\n        try:\\n            self.image = self.image.resize(size)\\n        except Exception as e:\\n            print(f\"Error resizing image: {e}\")\\n\\n    def apply_gaussian_blur(self, radius=5):\\n        try:\\n            self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\\n        except Exception as e:\\n            print(f\"Error applying Gaussian blur: {e}\")\\n\\n    def get_image_data(self):\\n        try:\\n            return np.asarray(self.image)\\n        except Ex...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 35)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 35)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>To design a Python-based concurrent game engine for a multiplayer online battle arena (MOBA) game, we can utilize parallel processing for efficient real-time simulation of multiple player actions and metaprogramming for dynamic game object creation. The engine should include features such as network synchronization, collision detection, and physics simulation.\\n\\nHere is an overview of the design:\\n\\n1. Libraries and Frameworks:\\n   - `asyncio`: To handle concurrent processing for network synchronization.\\n   - `numpy`: For efficient numerical operations and physics simulation.\\n   - `pygame`: For creating the graphical user interface (GUI) and handling user input.\\n   - `tensorflow`: If needed for machine learning algorithms or predictions.\\n\\n2. High-Level Overview of the Design:\\n   - Game Objects: Represent players, characters, buildings, towers, and other game objects.\\n   - Game World: Manages the game state, including the list of game objects, terrain, and physics simulation...</td>\n",
       "      <td>invalid syntax (&lt;string&gt;, line 1)</td>\n",
       "      <td>invalid syntax (&lt;unknown&gt;, line 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        code  \\\n",
       "15   import threading\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Function to process user sessions in parallel\\ndef process_session(session):\\n    # Analyze user behavior in real-time\\n    user_behavior = analyze_user_behavior(session)\\n\\n    # Detect signs of potential cart abandonment\\n    is_abandonment = detect_abandonment(user_behavior)\\n\\n    if is_abandonment:\\n        # Trigger appropriate interventions (e.g., sending a reminder email or push notification)\\n        trigger_intervention(session)\\n\\n# Function to analyze user behavior in real-time\\ndef analyze_user_behavior(session):\\n    # Implement logic to analyze user behavior\\n    # ...\\n\\n    return user_behavior\\n\\n# Function to detect signs of potential cart abandonment\\ndef detect_abandonment(user_behavior):\\n    # Implement logic to detect signs of potential cart abandonment\\n    # ...\\n\\n    return is_abandonment\\n\\n# Function to trigger appropriate interventions (e.g., sending a remi...   \n",
       "26   import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nfrom multiprocessing import Pool\\n\\n# Preprocess the data\\ndef preprocess_data(data):\\n    # Perform data cleaning, feature engineering, and transformation\\n    # ...\\n\\n    return processed_data\\n\\n# Design a concurrent and parallel processing system\\ndef process_data_parallel(data_chunks):\\n    with Pool() as pool:\\n        processed_data = pool.map(preprocess_data, data_chunks)\\n\\n    return processed_data\\n\\n# Build the CLV prediction model\\ndef build_clv_model(processed_data):\\n    # Split the data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        processed_data.drop('CLV', axis=1),\\n        processed_data['CLV'],\\n        test_size=0.2,\\n        random_state=42\\n    )\\n\\n    # Train a random forest regression model\\n    model = RandomFor...   \n",
       "115  import asyncio\\n\\nasync def ingest_data(spacecraft):\\n    # Connect to spacecraft and start streaming data\\n    while True:\\n        data = await spacecraft.receive_data()\\n        yield data\\n```\\n\\n2. **Data Processing**: Use `pandas` for data processing and analysis. This will allow us to handle large volumes of data efficiently and perform various operations on it.\\n\\n```python\\nimport pandas as pd\\n\\nasync def process_data(data):\\n    # Convert data to pandas DataFrame\\n    df = pd.DataFrame(data)\\n\\n    # Perform various operations on DataFrame (filtering, aggregation, etc.)\\n    processed_df = df.groupby('timestamp').mean()\\n\\n    return processed_df\\n```\\n\\n3. **Data Analysis**: Use `seaborn` or `matplotlib` for data visualization. This will allow us to gain insights from our data.\\n\\n```python\\nimport seaborn as sns\\n\\nasync def analyze_data(processed_df):\\n    # Generate a heatmap of the data\\n    sns.heatmap(processed_df.corr())\\n```\\n\\n4. **Error Handling**: Implement e...   \n",
       "146  import numpy as np\\nimport matplotlib.pyplot as plt\\n\\ndef q_learning(state_space, action_space, reward_function, learning_rate, discount_factor, num_episodes, epsilon=0.1):\\n    # Initialize Q-table with zeros\\n    q_table = np.zeros((state_space, action_space))\\n\\n    # Initialize list to store learning curve\\n    learning_curve = []\\n\\n    # Loop through episodes\\n    for episode in range(num_episodes):\\n        # Reset state at beginning of episode\\n        state = 0\\n\\n        # Initialize total reward for episode\\n        total_reward = 0\\n\\n        # Loop through steps in episode\\n        for step in range(100):\\n            # Select action based on epsilon-greedy policy\\n            if np.random.uniform() < epsilon:\\n                action = np.random.choice(action_space)\\n            else:\\n                action = np.argmax(q_table[state])\\n\\n            # Receive reward and next state from environment\\n            reward = reward_function(state, action)\\n            next...   \n",
       "151                                                                                                                                                                                                                                          import sys\\n\\ndef count_error_code(log_file_path, error_code):\\n    count = 0\\n    with open(log_file_path, 'r') as file:\\n        for line in file:\\n            if error_code in line:\\n                count += 1\\n    return count\\n\\nif __name__ == \"__main__\":\\n    if len(sys.argv) != 3:\\n        print(\"Usage: python script.py <log_file_path> <error_code>\")\\n        sys.exit(1)\\n\\n    log_file_path = sys.argv[1]\\n    error_code = sys.argv[2]\\n\\n    error_code_count = count_error_code(log_file_path, error_code)\\n    print(f\"The count of error code '{error_code}' in the log file is: {error_code_count}\")\\n```\\n\\nTo use this script, save it as `count_error_code.py` and run it using the command:\\n\\n```bash\\npython count_error_code.py <log_file_path> <error_code>   \n",
       "160  import numpy as np\\n\\nclass MRI_Scanner:\\n    def __init__(self, patient_id, scan_date, scan_type):\\n        self.patient_id = patient_id\\n        self.scan_date = scan_date\\n        self.scan_type = scan_type\\n\\n    def simulate_scanning(self):\\n        try:\\n            if not isinstance(self.patient_id, int) or self.patient_id <= 0:\\n                raise ValueError(\"Invalid patient ID\")\\n\\n            if not isinstance(self.scan_date, str) or len(self.scan_date.split(\"-\")) != 3:\\n                raise ValueError(\"Incorrect scan date format. Expected format: YYYY-MM-DD\")\\n\\n            if self.scan_type not in [\"T1\", \"T2\", \"FLAIR\"]:\\n                raise ValueError(\"Unsupported scan type. Expected values: T1, T2, FLAIR\")\\n\\n            np.random.seed(hash(self.patient_id) ^ hash(self.scan_date) ^ hash(self.scan_type))\\n            synthetic_image = np.random.randint(0, 256, (128, 128, 128))\\n\\n            return synthetic_image\\n        except ValueError as e:\\n            retu...   \n",
       "163  class VirtualClassroom:\\n    def __init__(self, teacher=None, students=None, subject=None, room_capacity=0):\\n        self.teacher = teacher\\n        self.students = students if students else []\\n        self.subject = subject\\n        self.room_capacity = room_capacity\\n\\n    def add_student(self, student):\\n        if len(self.students) >= self.room_capacity:\\n            raise Exception(\"Room capacity exceeded\")\\n        self.students.append(student)\\n\\n    def remove_student(self, student):\\n        if student in self.students:\\n            self.students.remove(student)\\n\\n    def assign_teacher(self, teacher):\\n        if self.teacher:\\n            raise Exception(\"Teacher already assigned\")\\n        self.teacher = teacher\\n\\n    def change_subject(self, subject):\\n        self.subject = subject\\n\\n    def display_classroom_details(self):\\n        print(f\"Teacher: {self.teacher}\")\\n        print(f\"Students: {', '.join(self.students)}\")\\n        print(f\"Subject: {self.subject}\"...   \n",
       "229  import pandas as pd\\nimport random\\n\\ndef quiz_generator(questions_file_path):\\n    try:\\n        # Read the CSV file using pandas\\n        df = pd.read_csv(questions_file_path)\\n\\n        # Check if the file is empty\\n        if df.empty:\\n            return \"Error: The file is empty.\"\\n\\n        # Filter the questions by difficulty level\\n        easy_questions = df[df['difficulty'] == 'easy']\\n        medium_questions = df[df['difficulty'] == 'medium']\\n        hard_questions = df[df['difficulty'] == 'hard']\\n\\n        # Check if there are at least 3 questions of each difficulty level\\n        if len(easy_questions) < 3 or len(medium_questions) < 3 or len(hard_questions) < 3:\\n            return \"Error: There should be at least 3 questions of each difficulty level.\"\\n\\n        # Randomly select 3 questions of each difficulty level\\n        selected_easy = easy_questions.sample(3)\\n        selected_medium = medium_questions.sample(3)\\n        selected_hard = hard_questions.sample...   \n",
       "243  import numpy as np\\nfrom PIL import Image, ImageFilter\\n\\nclass ImageProcessor:\\n    def __init__(self, image_path):\\n        self.image_path = image_path\\n        try:\\n            self.image = Image.open(image_path)\\n        except Exception as e:\\n            print(f\"Error opening image: {e}\")\\n\\n    def to_grayscale(self):\\n        try:\\n            self.image = self.image.convert('L')\\n        except Exception as e:\\n            print(f\"Error converting to grayscale: {e}\")\\n\\n    def resize(self, size):\\n        try:\\n            self.image = self.image.resize(size)\\n        except Exception as e:\\n            print(f\"Error resizing image: {e}\")\\n\\n    def apply_gaussian_blur(self, radius=5):\\n        try:\\n            self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\\n        except Exception as e:\\n            print(f\"Error applying Gaussian blur: {e}\")\\n\\n    def get_image_data(self):\\n        try:\\n            return np.asarray(self.image)\\n        except Ex...   \n",
       "292  To design a Python-based concurrent game engine for a multiplayer online battle arena (MOBA) game, we can utilize parallel processing for efficient real-time simulation of multiple player actions and metaprogramming for dynamic game object creation. The engine should include features such as network synchronization, collision detection, and physics simulation.\\n\\nHere is an overview of the design:\\n\\n1. Libraries and Frameworks:\\n   - `asyncio`: To handle concurrent processing for network synchronization.\\n   - `numpy`: For efficient numerical operations and physics simulation.\\n   - `pygame`: For creating the graphical user interface (GUI) and handling user input.\\n   - `tensorflow`: If needed for machine learning algorithms or predictions.\\n\\n2. High-Level Overview of the Design:\\n   - Game Objects: Represent players, characters, buildings, towers, and other game objects.\\n   - Game World: Manages the game state, including the list of game objects, terrain, and physics simulation...   \n",
       "\n",
       "                                      compile_error  \\\n",
       "15   expected an indented block (<string>, line 37)   \n",
       "26   expected an indented block (<string>, line 48)   \n",
       "115               invalid syntax (<string>, line 8)   \n",
       "146              invalid syntax (<string>, line 55)   \n",
       "151              invalid syntax (<string>, line 21)   \n",
       "160              invalid syntax (<string>, line 28)   \n",
       "163              invalid syntax (<string>, line 30)   \n",
       "229              invalid syntax (<string>, line 36)   \n",
       "243              invalid syntax (<string>, line 35)   \n",
       "292               invalid syntax (<string>, line 1)   \n",
       "\n",
       "                                           ast_error  \\\n",
       "15   expected an indented block (<unknown>, line 37)   \n",
       "26   expected an indented block (<unknown>, line 48)   \n",
       "115               invalid syntax (<unknown>, line 8)   \n",
       "146              invalid syntax (<unknown>, line 55)   \n",
       "151              invalid syntax (<unknown>, line 21)   \n",
       "160              invalid syntax (<unknown>, line 28)   \n",
       "163              invalid syntax (<unknown>, line 30)   \n",
       "229              invalid syntax (<unknown>, line 36)   \n",
       "243              invalid syntax (<unknown>, line 35)   \n",
       "292               invalid syntax (<unknown>, line 1)   \n",
       "\n",
       "     is_valid_python_with_pyflakes  \n",
       "15                           False  \n",
       "26                           False  \n",
       "115                          False  \n",
       "146                          False  \n",
       "151                          False  \n",
       "160                          False  \n",
       "163                          False  \n",
       "229                          False  \n",
       "243                          False  \n",
       "292                          False  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_codes[python_codes.is_valid_python_with_compile == False][['code', 'compile_error', 'ast_error', 'is_valid_python_with_pyflakes']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes[(python_codes.is_valid_python_with_complie == True) & (python_codes.is_valid_python_with_pyflakes == False)][['code', 'pyflakes_error']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_error_category('pandas is imported but unused')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyflakes_error_category\n",
       "imported but unused           226\n",
       "undefined name                 53\n",
       "assigned to but never used     29\n",
       "Invalid Syntax                 24\n",
       "Other                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_error_category(pyflakes_error: str) -> str:\n",
    "    pyflakes_error_categories = ['undefined name', 'assigned to but never used', 'imported but unused']\n",
    "    for category in pyflakes_error_categories:\n",
    "        if pyflakes_error is not None:\n",
    "            if category in str(pyflakes_error):\n",
    "                return category\n",
    "    return None\n",
    "\n",
    "python_codes['pyflakes_error_category'] = python_codes['pyflakes_error'].apply(get_error_category)\n",
    "python_codes['pyflakes_error_category'][python_codes.is_valid_python_with_compile == False] = 'Invalid Syntax'\n",
    "python_codes['pyflakes_error_category'][(python_codes.is_valid_python_with_pyflakes == False) & (python_codes.pyflakes_error_category.isnull())] = 'Other'\n",
    "\n",
    "python_codes['pyflakes_error_category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.to_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/python_codes_with_checks.csv', index=False)\n",
    "# python_codes = pd.read_csv('/mnt/foundation-shared/nina_xu_gretel_ai/datasets/python_codes_with_checks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python_codes[python_codes.is_valid_python_with_pyflakes == False][['code', 'pyflakes_error', 'is_valid_python_with_compile']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert Python Developer Needed for Autonomous Driving Software: We require an expert Python developer to create a concurrent and parallel processing system that can handle multiple data streams from various sensors (e.g., LIDAR, RADAR, cameras) in real-time. The system should be capable of metaprogramming to adapt to different vehicle models and their unique sensor configurations. The final code will be integrated into our autonomous driving software for the automotive industry. Please provide a detailed solution that demonstrates your expertise in concurrency, parallel processing, and metaprogramming.\n",
      "\n",
      "### Instructions\n",
      "    * The code should have a complexity of \"Expert: Concurrency, parallel processing, and metaprogramming\".\n",
      "    * Write code that might be used in the \"Automotive Software\" industry within a \"Autonomous Driving\" context.\n",
      "    * Try to include at least 1 of the following Python packages:  `numpy`.\n",
      "    * Include only the code, without any comments or additional text.\n",
      "\n",
      "----------\n",
      "\n",
      "import concurrent.futures\n",
      "import numpy as np\n",
      "\n",
      "# Simulated sensor data streams\n",
      "sensor_data = {\n",
      "    'lidar': np.random.rand(100, 3),\n",
      "    'radar': np.random.rand(100, 2),\n",
      "    'camera': np.random.rand(100, 4)\n",
      "}\n",
      "\n",
      "# Function to process sensor data\n",
      "def process_sensor_data(sensor_name, data):\n",
      "    # Perform some processing on the data\n",
      "    processed_data = data * 2\n",
      "    return sensor_name, processed_data\n",
      "\n",
      "# Create a thread pool executor\n",
      "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
      "    # Submit the processing tasks to the executor\n",
      "    futures = {sensor_name: executor.submit(process_sensor_data, sensor_name, data)\n",
      "               for sensor_name, data in sensor_data.items()}\n",
      "\n",
      "    # Get the results from the completed tasks\n",
      "    results = {sensor_name: future.result() for sensor_name, future in concurrent.futures.as_completed(futures)}\n",
      "\n",
      "# Print the results\n",
      "for sensor_name, processed_data in results.items():\n",
      "    print(f\"Processed {sensor_name} data:\")\n",
      "    print(processed_data)\n",
      "    print()\n"
     ]
    }
   ],
   "source": [
    "# compile errors\n",
    "ind = 15\n",
    "ind = 115\n",
    "# pyflakes errors\n",
    "ind = 2 # imported but unused\n",
    "ind = 69 # assigned to but never used\n",
    "ind = 36 # undefined name\n",
    "# mypy errors\n",
    "ind = 576 # missing positional argument\n",
    "ind = 743 # unsupported operand types\n",
    "ind = 545 # has no attribute X\n",
    "# incomplete code\n",
    "ind = 261\n",
    "\n",
    "ind = 509\n",
    "print(python_codes.prompt[ind])\n",
    "print('----------\\n')\n",
    "print(python_codes.code[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.error_category[(python_codes.is_valid_python_with_mypy == False)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mypy_error</th>\n",
       "      <th>pyflakes_error_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;string&gt;:37: \u001b[1m\u001b[31merror:\u001b[m expected an indented block  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;string&gt;:48: \u001b[1m\u001b[31merror:\u001b[m expected an indented block  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>&lt;string&gt;:18: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>assigned to but never used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>&lt;string&gt;:8: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>&lt;string&gt;:55: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>&lt;string&gt;:21: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>&lt;string&gt;:35: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queues\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n&lt;string&gt;:36: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"alert_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 2 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>&lt;string&gt;:28: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>&lt;string&gt;:30: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>&lt;string&gt;:29: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"output_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>&lt;string&gt;:1: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>&lt;string&gt;:37: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:38: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:39: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:40: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 4 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>&lt;string&gt;:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream3\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 3 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>&lt;string&gt;:9: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"frame_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n&lt;string&gt;:51: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"preprocess_frame\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 2 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>&lt;string&gt;:36: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>&lt;string&gt;:12: \u001b[1m\u001b[31merror:\u001b[m Incompatible types in assignment (expression has type \u001b[m\u001b[1m\"float\"\u001b[m, variable has type \u001b[m\u001b[1m\"int\"\u001b[m)  \u001b[m\u001b[33m[assignment]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>&lt;string&gt;:29: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>&lt;string&gt;:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"sphere\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:9: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:9: \u001b...</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>&lt;string&gt;:35: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>&lt;string&gt;:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"submission1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"student_id1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"submission2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"student_id2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 4 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>&lt;string&gt;:3: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:3: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:3: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:3: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data3\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data4\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n&lt;string&gt;:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data5\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 5 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>undefined name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>&lt;string&gt;:1: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:1: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>&lt;string&gt;:1: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n</td>\n",
       "      <td>Invalid Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>&lt;string&gt;:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n&lt;string&gt;:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>&lt;string&gt;:48: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_list\"\u001b[m (hint: \u001b[m\u001b[1m\"data_list: list[&lt;type&gt;] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n&lt;string&gt;:49: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"central_server_data\"\u001b[m (hint: \u001b[m\u001b[1m\"central_server_data: list[&lt;type&gt;] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n&lt;string&gt;:50: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"error_data_list\"\u001b[m (hint: \u001b[m\u001b[1m\"error_data_list: list[&lt;type&gt;] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 3 errors in 1 file (checked 1 source file)\u001b[m\\n</td>\n",
       "      <td>imported but unused</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  mypy_error  \\\n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <string>:37: \u001b[1m\u001b[31merror:\u001b[m expected an indented block  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <string>:48: \u001b[1m\u001b[31merror:\u001b[m expected an indented block  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "69                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <string>:18: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "72                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "115                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <string>:8: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "146                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:55: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "151                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:21: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "157                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <string>:35: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queues\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n<string>:36: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"alert_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 2 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "160                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:28: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "163                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:30: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "164                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <string>:29: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"output_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "166                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "175                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:1: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "180                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <string>:37: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:38: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:39: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:40: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"i\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 4 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "191                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <string>:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:30: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"stream3\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 3 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "219                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:9: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"frame_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n<string>:51: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"preprocess_frame\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 2 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "229                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:36: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "231                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:12: \u001b[1m\u001b[31merror:\u001b[m Incompatible types in assignment (expression has type \u001b[m\u001b[1m\"float\"\u001b[m, variable has type \u001b[m\u001b[1m\"int\"\u001b[m)  \u001b[m\u001b[33m[assignment]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "234                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <string>:29: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_queue\"\u001b[m  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "240  <string>:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"sphere\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:4: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:7: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"vector\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:8: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"color\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:9: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"cylinder\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:9: \u001b...   \n",
       "243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:35: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "244                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"submission1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"student_id1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"submission2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:17: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"student_id2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 4 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "249                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:3: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:3: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:3: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:3: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "259                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data1\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data2\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data3\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data4\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n<string>:41: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"data5\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\\n\u001b[1m\u001b[31mFound 5 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "261                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:1: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:1: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "292                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <string>:1: \u001b[1m\u001b[31merror:\u001b[m invalid syntax  \u001b[m\u001b[33m[syntax]\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (errors prevented further checking)\u001b[m\\n   \n",
       "316                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:2: \u001b[1m\u001b[31merror:\u001b[m Library stubs not installed for \u001b[m\u001b[1m\"requests\"\u001b[m  \u001b[m\u001b[33m[import-untyped]\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m Hint: \u001b[m\u001b[1m\"python3 -m pip install types-requests\"\u001b[m\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m (or run \u001b[m\u001b[1m\"mypy --install-types\"\u001b[m to install all missing stub packages)\u001b[m\\n<string>:2: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\u001b[m\u001b[m\\n\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "321                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:48: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"data_list\"\u001b[m (hint: \u001b[m\u001b[1m\"data_list: list[<type>] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n<string>:49: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"central_server_data\"\u001b[m (hint: \u001b[m\u001b[1m\"central_server_data: list[<type>] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n<string>:50: \u001b[1m\u001b[31merror:\u001b[m Need type annotation for \u001b[m\u001b[1m\"error_data_list\"\u001b[m (hint: \u001b[m\u001b[1m\"error_data_list: list[<type>] = ...\"\u001b[m)  \u001b[m\u001b[33m[var-annotated]\u001b[m\\n\u001b[1m\u001b[31mFound 3 errors in 1 file (checked 1 source file)\u001b[m\\n   \n",
       "\n",
       "        pyflakes_error_category  \n",
       "13                         None  \n",
       "15               Invalid Syntax  \n",
       "26               Invalid Syntax  \n",
       "41          imported but unused  \n",
       "69   assigned to but never used  \n",
       "72                         None  \n",
       "115              Invalid Syntax  \n",
       "146              Invalid Syntax  \n",
       "151              Invalid Syntax  \n",
       "157         imported but unused  \n",
       "160              Invalid Syntax  \n",
       "163              Invalid Syntax  \n",
       "164         imported but unused  \n",
       "166                        None  \n",
       "175         imported but unused  \n",
       "180              undefined name  \n",
       "191              undefined name  \n",
       "219              undefined name  \n",
       "229              Invalid Syntax  \n",
       "231         imported but unused  \n",
       "234                        None  \n",
       "240              undefined name  \n",
       "243              Invalid Syntax  \n",
       "244              undefined name  \n",
       "249                        None  \n",
       "259              undefined name  \n",
       "261                        None  \n",
       "292              Invalid Syntax  \n",
       "316                        None  \n",
       "321         imported but unused  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_codes[(python_codes.is_valid_python_with_mypy == False)][['mypy_error', 'pyflakes_error_category']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python_codes[python_codes.pyflakes_error_category == 'undefined name'][['pyflakes_error', 'mypy_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incomplete_code\n",
      "False    968\n",
      "True      32\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>pyflakes_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>import threading\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Function to process user sessions in parallel\\ndef process_session(session):\\n    # Analyze user behavior in real-time\\n    user_behavior = analyze_user_behavior(session)\\n\\n    # Detect signs of potential cart abandonment\\n    is_abandonment = detect_abandonment(user_behavior)\\n\\n    if is_abandonment:\\n        # Trigger appropriate interventions (e.g., sending a reminder email or push notification)\\n        trigger_intervention(session)\\n\\n# Function to analyze user behavior in real-time\\ndef analyze_user_behavior(session):\\n    # Implement logic to analyze user behavior\\n    # ...\\n\\n    return user_behavior\\n\\n# Function to detect signs of potential cart abandonment\\ndef detect_abandonment(user_behavior):\\n    # Implement logic to detect signs of potential cart abandonment\\n    # ...\\n\\n    return is_abandonment\\n\\n# Function to trigger appropriate interventions (e.g., sending a remi...</td>\n",
       "      <td>&lt;string&gt;:37:1: expected an indented block\\nuser_sessions = pd.read_csv('user_sessions.csv')\\n^\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nfrom multiprocessing import Pool\\n\\n# Preprocess the data\\ndef preprocess_data(data):\\n    # Perform data cleaning, feature engineering, and transformation\\n    # ...\\n\\n    return processed_data\\n\\n# Design a concurrent and parallel processing system\\ndef process_data_parallel(data_chunks):\\n    with Pool() as pool:\\n        processed_data = pool.map(preprocess_data, data_chunks)\\n\\n    return processed_data\\n\\n# Build the CLV prediction model\\ndef build_clv_model(processed_data):\\n    # Split the data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        processed_data.drop('CLV', axis=1),\\n        processed_data['CLV'],\\n        test_size=0.2,\\n        random_state=42\\n    )\\n\\n    # Train a random forest regression model\\n    model = RandomFor...</td>\n",
       "      <td>&lt;string&gt;:48:1: expected an indented block\\nsales_data = pd.read_csv('sales_data.csv')\\n^\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>import concurrent.futures\\nimport requests\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import IsolationForest\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Define a list of network protocols\\nprotocols = ['http', 'https', 'ftp', 'ssh', 'smtp']\\n\\n# Define a function to analyze network traffic for a given protocol\\ndef analyze_traffic(protocol):\\n    # Fetch network traffic data for the given protocol\\n    data = requests.get(f'https://api.example.com/traffic/{protocol}').json()\\n\\n    # Preprocess the data\\n    df = pd.DataFrame(data)\\n    scaler = StandardScaler()\\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\\n\\n    # Detect anomalies using Isolation Forest\\n    clf = IsolationForest(contamination=0.01)\\n    preds = clf.fit_predict(df)\\n    anomalies = df[preds == -1]\\n\\n    # Mitigate the detected anomalies\\n    # ...\\n\\n    return anomalies\\n\\n# Create a thread pool executor\\nwith concurrent.futures.ThreadPoolExecutor() as exec...</td>\n",
       "      <td>&lt;string&gt;:4:1: 'numpy as np' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>import threading\\nimport queue\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport scipy.stats as stats\\n\\n# Define a worker function to process data streams\\ndef worker(data_queue):\\n    while True:\\n        data = data_queue.get()\\n        # Perform analytics on the data\\n        # ...\\n        # Update network settings based on analytics results\\n        # ...\\n        data_queue.task_done()\\n\\n# Create a queue to hold data streams\\ndata_queue = queue.Queue()\\n\\n# Create and start multiple worker threads\\nfor i in range(4):\\n    t = threading.Thread(target=worker, args=(data_queue,))\\n    t.start()\\n\\n# Generate and process synthetic data\\nfor _ in range(100):\\n    data = pd.DataFrame({'signal_strength': stats.norm.rvs(size=1000),\\n                         'latency': stats.uniform.rvs(size=1000),\\n                         'packet_loss': stats.binom.rvs(100, 0.05, size=1000)})\\n    data_queue.put(data)\\n\\n# Wait for all tasks in the queue to be processed\\ndata_queue.joi...</td>\n",
       "      <td>&lt;string&gt;:10:9: local variable 'data' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport concurrent.futures\\nfrom scipy.optimize import minimize_scalar\\n\\n# Differential Privacy Mechanism: Laplace Mechanism\\ndef laplace_mechanism(data, epsilon):\\n    noise = np.random.laplace(0, 1 / epsilon, len(data))\\n    return data + noise\\n\\n# Process a subset of data\\ndef process_subset(subset, epsilon):\\n    # Add noise to the data\\n    noisy_data = laplace_mechanism(subset, epsilon)\\n    # Perform analytics or ML tasks on the noisy data\\n    # ...\\n    return result\\n\\n# Combine results while maintaining privacy\\ndef combine_results(results):\\n    # Perform post-processing on the results to ensure privacy\\n    # ...\\n    return combined_result\\n\\n# Main function to manage processes and combine results\\ndef main():\\n    # Read large dataset\\n    data = pd.read_csv('large_dataset.csv')\\n\\n    # Split data into subsets for parallel processing\\n    subsets = np.array_split(data, num_processes)\\n\\n    # Set epsilon value for differenti...</td>\n",
       "      <td>&lt;string&gt;:4:1: 'scipy.optimize.minimize_scalar' imported but unused\\n&lt;string&gt;:14:5: local variable 'noisy_data' is assigned to but never used\\n&lt;string&gt;:17:12: undefined name 'result'\\n&lt;string&gt;:23:12: undefined name 'combined_result'\\n&lt;string&gt;:31:36: undefined name 'num_processes'\\n&lt;string&gt;:38:74: undefined name 'num_processes'\\n&lt;string&gt;:41:5: local variable 'combined_result' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>import asyncio\\nimport pandas as pd\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Simulated supplier data feeds\\nsupplier_data_feeds = {\\n    'Supplier1': 'data1.csv',\\n    'Supplier2': 'data2.csv',\\n    'Supplier3': 'data3.csv'\\n}\\n\\n# Function to process data from a supplier\\ndef process_supplier_data(supplier, file):\\n    data = pd.read_csv(file)\\n    # Process data (e.g., update inventory database)\\n    # ...\\n    return data\\n\\n# Function to handle real-time updates from suppliers\\nasync def handle_supplier_updates():\\n    with ThreadPoolExecutor(max_workers=3) as executor:\\n        tasks = {executor.submit(process_supplier_data, supplier, file): supplier for supplier, file in supplier_data_feeds.items()}\\n        for future in asyncio.as_completed(tasks):\\n            supplier = tasks[future]\\n            try:\\n                data = await future\\n                # Process data (e.g., update inventory database)\\n                # ...\\n            except Exception as...</td>\n",
       "      <td>&lt;string&gt;:26:17: local variable 'data' is assigned to but never used\\n&lt;string&gt;:30:23: f-string is missing placeholders\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>import threading\\nimport queue\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom tensorflow.keras.applications import VGG16\\nfrom tensorflow.keras.models import Model\\n\\n# Thread-safe queue for handling video frames\\nframe_queue = queue.Queue()\\n\\n# Function to process video frames\\ndef process_frames(stream_id):\\n    while True:\\n        frame = frame_queue.get()\\n        # Process frame here\\n        # ...\\n        frame_queue.task_done()\\n\\n# Load pre-trained CNN model\\nbase_model = VGG16(weights='imagenet', include_top=False)\\n\\n# Define metaprogramming function for dynamic model loading and inference\\ndef load_and_infer(model_path):\\n    # Load custom model\\n    custom_model = load_model(model_path)\\n\\n    # Create a new model with the custom layers\\n    input_tensor = base_model.input\\n    output_tensor = custom_model(base_model.output)\\n    new_model = Model(inputs=input_tensor, outputs=output_tensor)\\n\\n    return new_model\\n\\n# Assign each video s...</td>\n",
       "      <td>&lt;string&gt;:3:1: 'numpy as np' imported but unused\\n&lt;string&gt;:4:1: 'sklearn.preprocessing.StandardScaler' imported but unused\\n&lt;string&gt;:14:9: local variable 'frame' is assigned to but never used\\n&lt;string&gt;:25:20: undefined name 'load_model'\\n&lt;string&gt;:51:23: undefined name 'preprocess_frame'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>import requests\\nimport pandas as pd\\nimport concurrent.futures\\n\\n# Function to monitor network traffic\\ndef monitor_traffic(url):\\n    response = requests.get(url)\\n    return response.status_code, url\\n\\n# Function to analyze network traffic data\\ndef analyze_traffic(data):\\n    df = pd.DataFrame(data, columns=['Status Code', 'URL'])\\n\\n    # Perform analysis using pandas\\n    # ...\\n\\n    # Return results\\n    return df\\n\\n# List of URLs to monitor\\nurls = ['https://example.com', 'https://example.org', 'https://example.net']\\n\\n# Use concurrent.futures to monitor network traffic concurrently\\nwith concurrent.futures.ThreadPoolExecutor() as executor:\\n    results = executor.map(monitor_traffic, urls)\\n\\n# Analyze the traffic data\\ndf = analyze_traffic(results)\\n\\n# Generate report\\nreport = df.to_string(index=False)\\nprint(report)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>import pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import classification_report\\n\\n# Load the healthcare data\\ndata = pd.read_csv('healthcare_data.csv')\\n\\n# Preprocessing function\\ndef preprocess_data(patient):\\n    # Data preprocessing steps\\n    # ...\\n    return processed_patient\\n\\n# Feature extraction function\\ndef extract_features(patient):\\n    # Feature extraction steps\\n    # ...\\n    return features\\n\\n# Model training function\\ndef train_model(features):\\n    # Model training steps\\n    # ...\\n    return model\\n\\n# Analyze results function\\ndef analyze_results(models):\\n    # Analyze results steps\\n    # ...\\n    return report\\n\\n# Process the data in parallel\\nprocessed_data = Parallel(n_jobs=-1)(delayed(preprocess_data)(patient) for _, patient in data.iterrows())\\n\\nfeatures = Parallel(n_jobs=-1)(delayed(extract_features)(patient) for pat...</td>\n",
       "      <td>&lt;string&gt;:3:1: 'sklearn.preprocessing.StandardScaler' imported but unused\\n&lt;string&gt;:4:1: 'sklearn.ensemble.RandomForestClassifier' imported but unused\\n&lt;string&gt;:5:1: 'sklearn.metrics.classification_report' imported but unused\\n&lt;string&gt;:14:12: undefined name 'processed_patient'\\n&lt;string&gt;:26:12: undefined name 'model'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>import multiprocessing as mp\\nimport numpy as np\\nimport sklearn.decomposition as skd\\nfrom sklearn.preprocessing import StandardScaler\\n\\ndef process_image(image):\\n    # Some image processing tasks like filtering, segmentation, or feature extraction\\n    # ...\\n    return processed_image\\n\\ndef apply_pca(image):\\n    flattened_image = image.flatten()\\n    pca = skd.PCA(n_components=2)\\n    pca.fit(flattened_image)\\n    return pca.transform(flattened_image)\\n\\nif __name__ == \"__main__\":\\n    # Assume we have a list of medical images\\n    images = [np.random.rand(100, 100) for _ in range(100)]\\n\\n    # Standardize the images\\n    scaler = StandardScaler()\\n    images = scaler.fit_transform(images)\\n\\n    # Create a pool of processes\\n    pool = mp.Pool()\\n\\n    # Apply image processing and PCA in parallel\\n    processed_images = pool.map(process_image, images)\\n    pca_images = pool.map(apply_pca, processed_images)\\n\\n    # Close the pool and wait for all processes to finish\\n    p...</td>\n",
       "      <td>&lt;string&gt;:9:12: undefined name 'processed_image'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>import multiprocessing\\nimport numpy as np\\nimport logging\\n\\nlogging.basicConfig(filename='game_log.txt', level=logging.DEBUG)\\n\\ndef game_instance(params):\\n    try:\\n        # Your game logic here\\n        # Use params to dynamically generate game instance\\n        logging.info(f'Game instance with params {params} started.')\\n\\n        # Simulate game instance\\n        # ...\\n\\n        logging.info(f'Game instance with params {params} completed successfully.')\\n    except Exception as e:\\n        logging.error(f'Game instance with params {params} failed with error: {str(e)}')\\n\\ndef run_game_instances(params_list):\\n    with multiprocessing.Pool() as pool:\\n        pool.map(game_instance, params_list)\\n\\n# Generate parameters for game instances\\nparams_list = [np.random.rand(10) for _ in range(100)]\\n\\nrun_game_instances(params_list)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load tax laws and regulations\\ntax_laws = pd.read_csv('tax_laws.csv')\\n\\n# Define a function to process a single tax scenario\\ndef process_tax_scenario(scenario):\\n    # Calculate tax planning strategy\\n    # ...\\n\\n    return result\\n\\n# Define a function to process multiple tax scenarios concurrently\\ndef process_tax_scenarios(scenarios):\\n    results = []\\n\\n    with ThreadPoolExecutor(max_workers=4) as executor:\\n        future_results = {executor.submit(process_tax_scenario, scenario): scenario for scenario in scenarios}\\n\\n        for future in concurrent.futures.as_completed(future_results):\\n            scenario = future_results[future]\\n\\n            try:\\n                result = future.result()\\n                results.append(result)\\n            except Exception as e:\\n                print(f'Exception occurred while processing tax scenario: {e}')\\n\\n    return results\\n\\n# L...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'numpy as np' imported but unused\\n&lt;string&gt;:13:12: undefined name 'result'\\n&lt;string&gt;:22:23: undefined name 'concurrent'\\n&lt;string&gt;:23:13: local variable 'scenario' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>import threading\\nimport queue\\nimport time\\nimport numpy as np\\nfrom sklearn import linear_model\\n\\n# Define a worker function that processes incoming data from vehicle sensors\\ndef process_data(q):\\n    while True:\\n        data = q.get()\\n        # Perform data processing here\\n        time.sleep(1)\\n        q.task_done()\\n\\n# Define a metaprogramming function that dynamically adapts to different vehicle models\\ndef adapt_to_model(model):\\n    # Use metaprogramming techniques here to dynamically adapt to the vehicle model\\n    regressor = linear_model.LinearRegression()\\n    # Train the regressor with data specific to the vehicle model\\n    # ...\\n    return regressor\\n\\n# Create a queue to hold incoming data from vehicle sensors\\nq = queue.Queue()\\n\\n# Create multiple worker threads to process incoming data in parallel\\nfor i in range(5):\\n    t = threading.Thread(target=process_data, args=(q,))\\n    t.daemon = True\\n    t.start()\\n\\n# Simulate incoming data from vehicle sensor...</td>\n",
       "      <td>&lt;string&gt;:10:9: local variable 'data' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>import concurrent.futures\\nimport pandas as pd\\nimport requests\\n\\n# Define loan application data\\nloan_applications = [\\n    {\"loan_type\": \"home_loan\", \"amount\": 200000, \"term\": 30},\\n    {\"loan_type\": \"auto_loan\", \"amount\": 30000, \"term\": 60},\\n    {\"loan_type\": \"personal_loan\", \"amount\": 5000, \"term\": 12},\\n]\\n\\n# Define function to process loan application\\ndef process_loan(loan):\\n    try:\\n        # Simulate API call to get loan details\\n        response = requests.get(f\"https://api.financial_services.com/loans/{loan['loan_type']}?amount={loan['amount']}&amp;term={loan['term']}\")\\n        loan_details = response.json()\\n\\n        # Simulate processing the loan application\\n        # ...\\n\\n        # Return processed loan data\\n        return {\\n            \"loan_type\": loan[\"loan_type\"],\\n            \"amount\": loan[\"amount\"],\\n            \"term\": loan[\"term\"],\\n            \"status\": \"approved\",\\n            \"details\": loan_details,\\n        }\\n    except Exception as e:\\n        ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>import cv2\\nimport numpy as np\\nfrom multiprocessing import Pool\\nimport concurrent.futures\\nfrom functools import partial\\n\\n# Load the YOLO model\\nnet = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\\n\\n# Define the function to process a single frame\\ndef process_frame(frame):\\n    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0, 0, 0), True, crop=False)\\n    net.setInput(blob)\\n    outs = net.forward(net.getUnconnectedOutLayersNames())\\n    # Post-process the output and draw bounding boxes on the frame\\n    # ...\\n\\n# Capture video from webcam\\ncap = cv2.VideoCapture(0)\\n\\n# Create a pool of processes\\nwith Pool(processes=4) as pool:\\n    while True:\\n        ret, frame = cap.read()\\n        if not ret:\\n            break\\n\\n        # Submit the frame for processing to the pool\\n        pool.apply_async(process_frame, (frame,))\\n\\n# Release resources\\ncap.release()\\ncv2.destroyAllWindows()</td>\n",
       "      <td>&lt;string&gt;:2:1: 'numpy as np' imported but unused\\n&lt;string&gt;:4:1: 'concurrent.futures' imported but unused\\n&lt;string&gt;:5:1: 'functools.partial' imported but unused\\n&lt;string&gt;:14:5: local variable 'outs' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>import random\\nimport threading\\nimport numpy as np\\nimport tensorflow as tf\\n\\nclass Game:\\n    def __init__(self):\\n        self.players = []\\n        self.levels = []\\n\\n    def add_player(self, player):\\n        self.players.append(player)\\n\\n    def generate_level(self):\\n        levels = ['Easy', 'Medium', 'Hard']\\n        level = random.choice(levels)\\n        self.levels.append(level)\\n        return level\\n\\nclass Player(threading.Thread):\\n    def __init__(self, game):\\n        threading.Thread.__init__(self)\\n        self.game = game\\n\\n    def run(self):\\n        level = self.game.generate_level()\\n        print(f\"Player {self.name} is playing on level: {level}\")\\n\\n        # Simulate player's actions within the level\\n        # ...\\n\\n        # Update game state based on player's actions\\n        # ...\\n\\n# Create game object\\ngame = Game()\\n\\n# Add players to the game\\nfor i in range(10):\\n    player = Player(game)\\n    player.start()\\n    game.add_player(player)\\n\\n#...</td>\n",
       "      <td>&lt;string&gt;:3:1: 'numpy as np' imported but unused\\n&lt;string&gt;:4:1: 'tensorflow as tf' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>import pandas as pd\\n\\nclass Patient:\\n    def __init__(self, age, gender, medical_history, current_symptoms, lab_test_results):\\n        self.age = age\\n        self.gender = gender\\n        self.medical_history = medical_history\\n        self.current_symptoms = current_symptoms\\n        self.lab_test_results = lab_test_results\\n\\nclass DecisionSupportEngine:\\n    def __init__(self, patient):\\n        self.patient = patient\\n\\n    def analyze_patient_data(self):\\n        try:\\n            patient_df = pd.DataFrame([self.patient.__dict__])\\n            # Perform analysis on patient_df\\n            # ...\\n            return \"Treatment Recommendation\"\\n        except Exception as e:\\n            return str(e)</td>\n",
       "      <td>&lt;string&gt;:17:13: local variable 'patient_df' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>import pandas as pd\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Data Ingestion\\ndef fetch_data(sources):\\n    data = pd.DataFrame()\\n    for source in sources:\\n        if source.endswith('.csv'):\\n            data = data.append(pd.read_csv(source))\\n        else:\\n            data = data.append(pd.read_sql_query('SELECT * FROM customers', source))\\n    return data\\n\\n# Data Preprocessing\\ndef preprocess_data(data):\\n    # Clean and transform data\\n    # ...\\n\\n    # Normalize data\\n    scaler = StandardScaler()\\n    normalized_data = scaler.fit_transform(data)\\n    return normalized_data\\n\\n# Feature Engineering\\ndef generate_features(data):\\n    # Generate relevant features\\n    # ...\\n    return features\\n\\n# Segmentation\\ndef perform_segmentation(features, num_clusters):\\n    kmeans = KMeans(n_clusters=num_clusters)\\n    kmeans.fit(features)\\n    return kmeans.labels_\\n\\n# Metaprogramming\\ndef configure_pipeline(config):\\n    sourc...</td>\n",
       "      <td>&lt;string&gt;:29:12: undefined name 'features'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>import pandas as pd\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load student performance metrics, learning styles, and curriculum details from CSV files\\nstudent_data = pd.read_csv('student_data.csv')\\nlearning_styles = pd.read_csv('learning_styles.csv')\\ncurriculum = pd.read_csv('curriculum.csv')\\n\\n# Define a function to generate a personalized learning path for a student\\ndef generate_learning_path(student):\\n    # Perform some processing on the student data, learning styles, and curriculum details\\n    # ...\\n\\n    # Generate the learning path based on the processed data\\n    learning_path = []\\n    # ...\\n\\n    return learning_path\\n\\n# Define a function to generate learning paths for all students using concurrency\\ndef generate_all_learning_paths(students):\\n    learning_paths = []\\n\\n    with ThreadPoolExecutor() as executor:\\n        # Use the executor.map function to apply the generate_learning_path function to all students concurrently\\n        learning_paths ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>import concurrent.futures\\nimport requests\\nimport pandas as pd\\nfrom sklearn.ensemble import IsolationForest\\n\\n# Sample user credentials\\ncredentials = {\\n    \"user1\": \"pass1\",\\n    \"user2\": \"pass2\",\\n    # ...\\n}\\n\\n# Security policies\\nsecurity_policies = {\\n    \"failed_attempts_threshold\": 3,\\n    \"lockout_duration\": 10,  # minutes\\n    # ...\\n}\\n\\n# User session management\\nuser_sessions = {}\\n\\n# Brute force detection\\ndef detect_brute_force(user):\\n    # Fetch authentication attempts from a database or log file\\n    attempts = pd.read_csv(\"attempts.csv\")\\n    failed_attempts = attempts[attempts[\"user\"] == user][\"status\"] == \"failed\"\\n\\n    if len(failed_attempts) &gt; security_policies[\"failed_attempts_threshold\"]:\\n        return True\\n    else:\\n        return False\\n\\n# Authenticate user\\ndef authenticate(user, password):\\n    if credentials[user] == password:\\n        # Check for brute force attacks\\n        if detect_brute_force(user):\\n            return False\\n        e...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'requests' imported but unused\\n&lt;string&gt;:4:1: 'sklearn.ensemble.IsolationForest' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nimport concurrent.futures\\nimport requests\\n\\n# Sample data of banking transactions\\ntransactions = [\\n    {\"transaction_id\": 1, \"account_id\": 1001, \"amount\": 5000},\\n    {\"transaction_id\": 2, \"account_id\": 1002, \"amount\": 3000},\\n    {\"transaction_id\": 3, \"account_id\": 1003, \"amount\": 2000},\\n    # ... more transactions\\n]\\n\\ndef process_transaction(transaction):\\n    try:\\n        # Simulate network connectivity delay\\n        response = requests.get(\"https://api.bank.com/process_transaction\", params=transaction)\\n        if response.status_code == 200:\\n            return f\"Transaction {transaction['transaction_id']} processed successfully\"\\n        else:\\n            return f\"Error processing transaction {transaction['transaction_id']}\"\\n    except Exception as e:\\n        return f\"Error processing transaction {transaction['transaction_id']}: {str(e)}\"\\n\\ndef process_transactions_concurrently(transactions):\\n    results = []\\n    with co...</td>\n",
       "      <td>&lt;string&gt;:1:1: 'pandas as pd' imported but unused\\n&lt;string&gt;:2:1: 'numpy as np' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>import pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load dataset\\ndf = pd.read_csv('patient_records.csv')\\n\\n# Define function for parallel processing\\ndef analyze_data(patient_data):\\n    # Analyze data and identify patterns or anomalies\\n    # ...\\n\\n    return results\\n\\n# Create a ThreadPoolExecutor\\nwith ThreadPoolExecutor() as executor:\\n    # Submit tasks to the executor\\n    futures = [executor.submit(analyze_data, data) for _, data in df.iterrows()]\\n\\n    # Get the results\\n    results = [future.result() for future in futures]\\n\\n# Create a heatmap using seaborn\\nsns.heatmap(pd.DataFrame(results).corr(), annot=True)\\n\\n# Save the plot\\nplt.savefig('patterns.png')</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Sure, here's some sample code that demonstrates the use of concurrency, parallel processing, and metaprogramming techniques to optimize the performance of a medication management system. This code uses the `multiprocessing` module to create a parallel processing pipeline that can handle large-scale medication data from different data sources. It also uses the `pandas` library to manipulate and analyze the data, and the `numpy` library to perform numerical operations on the data.\\n```\\nimport multiprocessing as mp\\nimport pandas as pd\\nimport numpy as np\\n\\n# Define a function to process data from a single data source\\ndef process_data(data):\\n    # Perform some data processing operations here\\n    # ...\\n    return processed_data\\n\\n# Define a function to handle data from multiple data sources\\ndef handle_data(sources):\\n    # Create a pool of worker processes\\n    pool = mp.Pool(processes=mp.cpu_count())\\n\\n    # Process data from each source in parallel\\n    processed_data = pool...</td>\n",
       "      <td>&lt;string&gt;:1:484: EOL while scanning string literal\\nSure, here's some sample code that demonstrates the use of concurrency, parallel processing, and metaprogramming techniques to optimize the performance of a medication management system. This code uses the `multiprocessing` module to create a parallel processing pipeline that can handle large-scale medication data from different data sources. It also uses the `pandas` library to manipulate and analyze the data, and the `numpy` library to perform numerical operations on the data.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>import concurrent.futures\\nimport pandas as pd\\nimport numpy as np\\nimport scikit_learn as sklearn\\nimport re\\n\\n# Function to parse log files\\ndef parse_log_file(file_path):\\n    log_data = []\\n    with open(file_path, 'r') as file:\\n        for line in file:\\n            log_entry = re.split(r'\\s+', line)\\n            log_data.append(log_entry)\\n    return log_data\\n\\n# Function to perform pattern matching and anomaly detection\\ndef detect_anomalies(log_data):\\n    # Implement pattern matching and anomaly detection algorithms here\\n    # ...\\n\\n    return anomalies\\n\\n# Function to create alert for potential security incidents\\ndef create_alert(anomaly):\\n    # Implement alerting system here\\n    # ...\\n\\n    return alert\\n\\n# Function to process log files concurrently\\ndef process_log_files(file_paths):\\n    with concurrent.futures.ThreadPoolExecutor() as executor:\\n        futures = [executor.submit(parse_log_file, file_path) for file_path in file_paths]\\n        log_data = [fu...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'pandas as pd' imported but unused\\n&lt;string&gt;:3:1: 'numpy as np' imported but unused\\n&lt;string&gt;:4:1: 'scikit_learn as sklearn' imported but unused\\n&lt;string&gt;:21:12: undefined name 'anomalies'\\n&lt;string&gt;:28:12: undefined name 'alert'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>import pandas as pd\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.metrics.pairwise import linear_kernel\\nfrom multiprocessing import Pool\\n\\n# Load user behavior data\\nuser_data = pd.read_csv('user_behavior.csv')\\n\\n# Function to recommend products based on user behavior\\ndef recommend_products(user):\\n    tfidf = TfidfVectorizer(stop_words='english')\\n    tfidf_matrix = tfidf.fit_transform(user['product_description'])\\n    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\\n    # ... (rest of the recommendation logic)\\n    return recommended_products\\n\\n# Parallel processing to recommend products for all users\\nwith Pool() as p:\\n    recommendations = p.map(recommend_products, user_data['user_id'])\\n\\n# Save recommendations to a file\\npd.DataFrame(recommendations).to_csv('recommendations.csv', index=False)</td>\n",
       "      <td>&lt;string&gt;:13:5: local variable 'cosine_sim' is assigned to but never used\\n&lt;string&gt;:15:12: undefined name 'recommended_products'\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>import asyncio\\nimport pandas as pd\\nfrom scipy.stats import norm\\n\\n# Simulated VoIP call data\\ncalls = [\\n    {\"call_id\": 1, \"latency\": 50, \"jitter\": 10, \"packet_loss\": 0.5},\\n    {\"call_id\": 2, \"latency\": 45, \"jitter\": 8, \"packet_loss\": 0.3},\\n    # ... more call data ...\\n]\\n\\n# Define SLAs\\nslas = {\\n    \"latency\": {\"mean\": 50, \"std_dev\": 10},\\n    \"jitter\": {\"mean\": 8, \"std_dev\": 2},\\n    \"packet_loss\": {\"mean\": 0.1, \"std_dev\": 0.05},\\n}\\n\\nasync def process_call(call):\\n    # Calculate metrics\\n    latency_anomaly = abs(call[\"latency\"] - slas[\"latency\"][\"mean\"]) &gt; slas[\"latency\"][\"std_dev\"]\\n    jitter_anomaly = abs(call[\"jitter\"] - slas[\"jitter\"][\"mean\"]) &gt; slas[\"jitter\"][\"std_dev\"]\\n    packet_loss_anomaly = abs(call[\"packet_loss\"] - slas[\"packet_loss\"][\"mean\"]) &gt; slas[\"packet_loss\"][\"std_dev\"]\\n\\n    # Generate alert if any anomaly detected\\n    if latency_anomaly or jitter_anomaly or packet_loss_anomaly:\\n        print(f\"Alert: Anomaly detected in call {call['call_id']}\"...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'pandas as pd' imported but unused\\n&lt;string&gt;:3:1: 'scipy.stats.norm' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>import multiprocessing as mp\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\ndef process_data(data):\\n    # Preprocessing steps\\n    # ...\\n    return processed_data\\n\\ndef train_model(data):\\n    X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\\n    model.fit(X_train, y_train)\\n    return model\\n\\ndef main():\\n    # Load data\\n    data = pd.read_csv('financial_data.csv')\\n\\n    # Create a pool of processes\\n    with mp.Pool(processes=mp.cpu_count()) as pool:\\n        # Process data in parallel\\n        processed_data = pool.map(process_data, np.array_split(data, mp.cpu_count()))\\n\\n        # Train models in parallel\\n        models = pool.map(train_model, processed_data)\\n\\nif __name__ == '__main__':\\n    main()</td>\n",
       "      <td>&lt;string&gt;:10:12: undefined name 'processed_data'\\n&lt;string&gt;:28:9: local variable 'models' is assigned to but never used\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>import re\\nimport requests\\nfrom Crypto.Cipher import AES\\n\\nclass InvalidURLException(Exception):\\n    pass\\n\\nclass SecurityScanner:\\n    def __init__(self, target_url):\\n        self.target_url = target_url\\n\\n    def validate_url(self):\\n        pattern = re.compile(\\n            r'^(?:http|ftp)s?://'  # http:// or https://\\n            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\\n            r'localhost|'  # localhost...\\n            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  # ...or ip\\n            r'(?::\\d+)?'  # optional port\\n            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\\n        if not re.match(pattern, self.target_url):\\n            raise InvalidURLException(\"Invalid URL\")\\n\\n    def find_vulnerabilities(self):\\n        vulnerabilities = []\\n        # Code to scan for vulnerabilities goes here\\n        # For demonstration, let's assume we found some vulnerabilities\\n        vulnerabilities.append(\"SQL Injection\")\\n     ...</td>\n",
       "      <td>&lt;string&gt;:2:1: 'requests' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nfrom multiprocessing import Pool\\n\\n# Simulated signal processing function\\ndef process_signal(signal):\\n    # Perform signal processing operations here\\n    # ...\\n    # Calculate signal strength, frequency, and duration\\n    signal_strength = np.random.uniform(0, 1)\\n    frequency = np.random.uniform(1e9, 2e9)\\n    duration = np.random.uniform(1, 10)\\n    return signal_strength, frequency, duration\\n\\n# Generate a large number of signals\\nsignals = [{'id': i} for i in range(10000)]\\n\\n# Create a pool of processes\\nwith Pool() as pool:\\n    # Process the signals in parallel\\n    results = pool.map(process_signal, signals)\\n\\n# Convert results to a pandas DataFrame\\ndf = pd.DataFrame(results, columns=['signal_strength', 'frequency', 'duration'])\\n\\n# Perform analytics on the processed signals\\n# ...\\n# Output detailed analytics\\nprint(df.describe())</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>import pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Load customer data\\ncustomer_data = pd.read_csv('customer_data.csv')\\n\\n# Preprocess data\\nscaler = StandardScaler()\\ncustomer_data_scaled = scaler.fit_transform(customer_data)\\n\\n# Define CLV calculation function\\ndef calculate_clv(customer):\\n    # Calculate CLV based on historical purchases, average order value, and purchase frequency\\n    # Include predicted future behavior and potential churn rate\\n    # Return CLV value\\n    pass\\n\\n# Parallel processing to calculate CLV for each customer\\nclv_values = Parallel(n_jobs=-1)(delayed(calculate_clv)(customer) for _, customer in customer_data_scaled.iterrows())\\n\\n# Store CLV values in a new column in the dataframe\\ncustomer_data['CLV'] = clv_values\\n\\n# Generate insights and trends report\\n# ...</td>\n",
       "      <td>&lt;string&gt;:3:1: 'sklearn.ensemble.RandomForestRegressor' imported but unused\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>import numpy as np\\nimport multiprocessing as mp\\n\\n# Define the control algorithm\\ndef control_algorithm(sensor_data, control_signals):\\n    # Perform some calculations on the sensor data and control signals\\n    # ...\\n\\n    # Dynamically adjust the control algorithm based on the vehicle's current state\\n    state = np.random.choice(['accelerating', 'cruising', 'braking'])\\n    if state == 'accelerating':\\n        # Adjust the control algorithm for accelerating state\\n        # ...\\n        pass\\n    elif state == 'cruising':\\n        # Adjust the control algorithm for cruising state\\n        # ...\\n        pass\\n    elif state == 'braking':\\n        # Adjust the control algorithm for braking state\\n        # ...\\n        pass\\n\\n    # Return the control signals\\n    return control_signals\\n\\n# Define the parallel processing function\\ndef process_data(sensor_data, control_signals):\\n    # Process the sensor data and control signals concurrently\\n    with mp.Pool() as pool:\\n     ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom concurrent.futures import ThreadPoolExecutor\\nimport matplotlib.pyplot as plt\\n\\n# Function to process student data and generate personalized learning paths\\ndef process_student_data(student_data):\\n    # Preprocess data, analyze strengths and weaknesses, and generate personalized learning paths\\n    # This is a placeholder function, replace with actual implementation\\n    personalized_paths = {}\\n    # ...\\n    return personalized_paths\\n\\n# Function to train and test a machine learning model for predicting student performance\\ndef train_and_test_model(student_data):\\n    # Split data into features and target\\n    X = student_data.drop('target', axis=1)\\n    y = student_data['target']\\n\\n    # Split data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_sp...</td>\n",
       "      <td>&lt;string&gt;:1:1: 'pandas as pd' imported but unused\\n&lt;string&gt;:2:1: 'numpy as np' imported but unused\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        code  \\\n",
       "15   import threading\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Function to process user sessions in parallel\\ndef process_session(session):\\n    # Analyze user behavior in real-time\\n    user_behavior = analyze_user_behavior(session)\\n\\n    # Detect signs of potential cart abandonment\\n    is_abandonment = detect_abandonment(user_behavior)\\n\\n    if is_abandonment:\\n        # Trigger appropriate interventions (e.g., sending a reminder email or push notification)\\n        trigger_intervention(session)\\n\\n# Function to analyze user behavior in real-time\\ndef analyze_user_behavior(session):\\n    # Implement logic to analyze user behavior\\n    # ...\\n\\n    return user_behavior\\n\\n# Function to detect signs of potential cart abandonment\\ndef detect_abandonment(user_behavior):\\n    # Implement logic to detect signs of potential cart abandonment\\n    # ...\\n\\n    return is_abandonment\\n\\n# Function to trigger appropriate interventions (e.g., sending a remi...   \n",
       "26   import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nfrom multiprocessing import Pool\\n\\n# Preprocess the data\\ndef preprocess_data(data):\\n    # Perform data cleaning, feature engineering, and transformation\\n    # ...\\n\\n    return processed_data\\n\\n# Design a concurrent and parallel processing system\\ndef process_data_parallel(data_chunks):\\n    with Pool() as pool:\\n        processed_data = pool.map(preprocess_data, data_chunks)\\n\\n    return processed_data\\n\\n# Build the CLV prediction model\\ndef build_clv_model(processed_data):\\n    # Split the data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        processed_data.drop('CLV', axis=1),\\n        processed_data['CLV'],\\n        test_size=0.2,\\n        random_state=42\\n    )\\n\\n    # Train a random forest regression model\\n    model = RandomFor...   \n",
       "41   import concurrent.futures\\nimport requests\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import IsolationForest\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Define a list of network protocols\\nprotocols = ['http', 'https', 'ftp', 'ssh', 'smtp']\\n\\n# Define a function to analyze network traffic for a given protocol\\ndef analyze_traffic(protocol):\\n    # Fetch network traffic data for the given protocol\\n    data = requests.get(f'https://api.example.com/traffic/{protocol}').json()\\n\\n    # Preprocess the data\\n    df = pd.DataFrame(data)\\n    scaler = StandardScaler()\\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\\n\\n    # Detect anomalies using Isolation Forest\\n    clf = IsolationForest(contamination=0.01)\\n    preds = clf.fit_predict(df)\\n    anomalies = df[preds == -1]\\n\\n    # Mitigate the detected anomalies\\n    # ...\\n\\n    return anomalies\\n\\n# Create a thread pool executor\\nwith concurrent.futures.ThreadPoolExecutor() as exec...   \n",
       "69   import threading\\nimport queue\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport scipy.stats as stats\\n\\n# Define a worker function to process data streams\\ndef worker(data_queue):\\n    while True:\\n        data = data_queue.get()\\n        # Perform analytics on the data\\n        # ...\\n        # Update network settings based on analytics results\\n        # ...\\n        data_queue.task_done()\\n\\n# Create a queue to hold data streams\\ndata_queue = queue.Queue()\\n\\n# Create and start multiple worker threads\\nfor i in range(4):\\n    t = threading.Thread(target=worker, args=(data_queue,))\\n    t.start()\\n\\n# Generate and process synthetic data\\nfor _ in range(100):\\n    data = pd.DataFrame({'signal_strength': stats.norm.rvs(size=1000),\\n                         'latency': stats.uniform.rvs(size=1000),\\n                         'packet_loss': stats.binom.rvs(100, 0.05, size=1000)})\\n    data_queue.put(data)\\n\\n# Wait for all tasks in the queue to be processed\\ndata_queue.joi...   \n",
       "103  import numpy as np\\nimport pandas as pd\\nimport concurrent.futures\\nfrom scipy.optimize import minimize_scalar\\n\\n# Differential Privacy Mechanism: Laplace Mechanism\\ndef laplace_mechanism(data, epsilon):\\n    noise = np.random.laplace(0, 1 / epsilon, len(data))\\n    return data + noise\\n\\n# Process a subset of data\\ndef process_subset(subset, epsilon):\\n    # Add noise to the data\\n    noisy_data = laplace_mechanism(subset, epsilon)\\n    # Perform analytics or ML tasks on the noisy data\\n    # ...\\n    return result\\n\\n# Combine results while maintaining privacy\\ndef combine_results(results):\\n    # Perform post-processing on the results to ensure privacy\\n    # ...\\n    return combined_result\\n\\n# Main function to manage processes and combine results\\ndef main():\\n    # Read large dataset\\n    data = pd.read_csv('large_dataset.csv')\\n\\n    # Split data into subsets for parallel processing\\n    subsets = np.array_split(data, num_processes)\\n\\n    # Set epsilon value for differenti...   \n",
       "203  import asyncio\\nimport pandas as pd\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Simulated supplier data feeds\\nsupplier_data_feeds = {\\n    'Supplier1': 'data1.csv',\\n    'Supplier2': 'data2.csv',\\n    'Supplier3': 'data3.csv'\\n}\\n\\n# Function to process data from a supplier\\ndef process_supplier_data(supplier, file):\\n    data = pd.read_csv(file)\\n    # Process data (e.g., update inventory database)\\n    # ...\\n    return data\\n\\n# Function to handle real-time updates from suppliers\\nasync def handle_supplier_updates():\\n    with ThreadPoolExecutor(max_workers=3) as executor:\\n        tasks = {executor.submit(process_supplier_data, supplier, file): supplier for supplier, file in supplier_data_feeds.items()}\\n        for future in asyncio.as_completed(tasks):\\n            supplier = tasks[future]\\n            try:\\n                data = await future\\n                # Process data (e.g., update inventory database)\\n                # ...\\n            except Exception as...   \n",
       "219  import threading\\nimport queue\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom tensorflow.keras.applications import VGG16\\nfrom tensorflow.keras.models import Model\\n\\n# Thread-safe queue for handling video frames\\nframe_queue = queue.Queue()\\n\\n# Function to process video frames\\ndef process_frames(stream_id):\\n    while True:\\n        frame = frame_queue.get()\\n        # Process frame here\\n        # ...\\n        frame_queue.task_done()\\n\\n# Load pre-trained CNN model\\nbase_model = VGG16(weights='imagenet', include_top=False)\\n\\n# Define metaprogramming function for dynamic model loading and inference\\ndef load_and_infer(model_path):\\n    # Load custom model\\n    custom_model = load_model(model_path)\\n\\n    # Create a new model with the custom layers\\n    input_tensor = base_model.input\\n    output_tensor = custom_model(base_model.output)\\n    new_model = Model(inputs=input_tensor, outputs=output_tensor)\\n\\n    return new_model\\n\\n# Assign each video s...   \n",
       "261                                                                                                                                                            import requests\\nimport pandas as pd\\nimport concurrent.futures\\n\\n# Function to monitor network traffic\\ndef monitor_traffic(url):\\n    response = requests.get(url)\\n    return response.status_code, url\\n\\n# Function to analyze network traffic data\\ndef analyze_traffic(data):\\n    df = pd.DataFrame(data, columns=['Status Code', 'URL'])\\n\\n    # Perform analysis using pandas\\n    # ...\\n\\n    # Return results\\n    return df\\n\\n# List of URLs to monitor\\nurls = ['https://example.com', 'https://example.org', 'https://example.net']\\n\\n# Use concurrent.futures to monitor network traffic concurrently\\nwith concurrent.futures.ThreadPoolExecutor() as executor:\\n    results = executor.map(monitor_traffic, urls)\\n\\n# Analyze the traffic data\\ndf = analyze_traffic(results)\\n\\n# Generate report\\nreport = df.to_string(index=False)\\nprint(report)   \n",
       "270  import pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import classification_report\\n\\n# Load the healthcare data\\ndata = pd.read_csv('healthcare_data.csv')\\n\\n# Preprocessing function\\ndef preprocess_data(patient):\\n    # Data preprocessing steps\\n    # ...\\n    return processed_patient\\n\\n# Feature extraction function\\ndef extract_features(patient):\\n    # Feature extraction steps\\n    # ...\\n    return features\\n\\n# Model training function\\ndef train_model(features):\\n    # Model training steps\\n    # ...\\n    return model\\n\\n# Analyze results function\\ndef analyze_results(models):\\n    # Analyze results steps\\n    # ...\\n    return report\\n\\n# Process the data in parallel\\nprocessed_data = Parallel(n_jobs=-1)(delayed(preprocess_data)(patient) for _, patient in data.iterrows())\\n\\nfeatures = Parallel(n_jobs=-1)(delayed(extract_features)(patient) for pat...   \n",
       "333  import multiprocessing as mp\\nimport numpy as np\\nimport sklearn.decomposition as skd\\nfrom sklearn.preprocessing import StandardScaler\\n\\ndef process_image(image):\\n    # Some image processing tasks like filtering, segmentation, or feature extraction\\n    # ...\\n    return processed_image\\n\\ndef apply_pca(image):\\n    flattened_image = image.flatten()\\n    pca = skd.PCA(n_components=2)\\n    pca.fit(flattened_image)\\n    return pca.transform(flattened_image)\\n\\nif __name__ == \"__main__\":\\n    # Assume we have a list of medical images\\n    images = [np.random.rand(100, 100) for _ in range(100)]\\n\\n    # Standardize the images\\n    scaler = StandardScaler()\\n    images = scaler.fit_transform(images)\\n\\n    # Create a pool of processes\\n    pool = mp.Pool()\\n\\n    # Apply image processing and PCA in parallel\\n    processed_images = pool.map(process_image, images)\\n    pca_images = pool.map(apply_pca, processed_images)\\n\\n    # Close the pool and wait for all processes to finish\\n    p...   \n",
       "349                                                                                                                                                         import multiprocessing\\nimport numpy as np\\nimport logging\\n\\nlogging.basicConfig(filename='game_log.txt', level=logging.DEBUG)\\n\\ndef game_instance(params):\\n    try:\\n        # Your game logic here\\n        # Use params to dynamically generate game instance\\n        logging.info(f'Game instance with params {params} started.')\\n\\n        # Simulate game instance\\n        # ...\\n\\n        logging.info(f'Game instance with params {params} completed successfully.')\\n    except Exception as e:\\n        logging.error(f'Game instance with params {params} failed with error: {str(e)}')\\n\\ndef run_game_instances(params_list):\\n    with multiprocessing.Pool() as pool:\\n        pool.map(game_instance, params_list)\\n\\n# Generate parameters for game instances\\nparams_list = [np.random.rand(10) for _ in range(100)]\\n\\nrun_game_instances(params_list)   \n",
       "373  import pandas as pd\\nimport numpy as np\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load tax laws and regulations\\ntax_laws = pd.read_csv('tax_laws.csv')\\n\\n# Define a function to process a single tax scenario\\ndef process_tax_scenario(scenario):\\n    # Calculate tax planning strategy\\n    # ...\\n\\n    return result\\n\\n# Define a function to process multiple tax scenarios concurrently\\ndef process_tax_scenarios(scenarios):\\n    results = []\\n\\n    with ThreadPoolExecutor(max_workers=4) as executor:\\n        future_results = {executor.submit(process_tax_scenario, scenario): scenario for scenario in scenarios}\\n\\n        for future in concurrent.futures.as_completed(future_results):\\n            scenario = future_results[future]\\n\\n            try:\\n                result = future.result()\\n                results.append(result)\\n            except Exception as e:\\n                print(f'Exception occurred while processing tax scenario: {e}')\\n\\n    return results\\n\\n# L...   \n",
       "377  import threading\\nimport queue\\nimport time\\nimport numpy as np\\nfrom sklearn import linear_model\\n\\n# Define a worker function that processes incoming data from vehicle sensors\\ndef process_data(q):\\n    while True:\\n        data = q.get()\\n        # Perform data processing here\\n        time.sleep(1)\\n        q.task_done()\\n\\n# Define a metaprogramming function that dynamically adapts to different vehicle models\\ndef adapt_to_model(model):\\n    # Use metaprogramming techniques here to dynamically adapt to the vehicle model\\n    regressor = linear_model.LinearRegression()\\n    # Train the regressor with data specific to the vehicle model\\n    # ...\\n    return regressor\\n\\n# Create a queue to hold incoming data from vehicle sensors\\nq = queue.Queue()\\n\\n# Create multiple worker threads to process incoming data in parallel\\nfor i in range(5):\\n    t = threading.Thread(target=process_data, args=(q,))\\n    t.daemon = True\\n    t.start()\\n\\n# Simulate incoming data from vehicle sensor...   \n",
       "378  import concurrent.futures\\nimport pandas as pd\\nimport requests\\n\\n# Define loan application data\\nloan_applications = [\\n    {\"loan_type\": \"home_loan\", \"amount\": 200000, \"term\": 30},\\n    {\"loan_type\": \"auto_loan\", \"amount\": 30000, \"term\": 60},\\n    {\"loan_type\": \"personal_loan\", \"amount\": 5000, \"term\": 12},\\n]\\n\\n# Define function to process loan application\\ndef process_loan(loan):\\n    try:\\n        # Simulate API call to get loan details\\n        response = requests.get(f\"https://api.financial_services.com/loans/{loan['loan_type']}?amount={loan['amount']}&term={loan['term']}\")\\n        loan_details = response.json()\\n\\n        # Simulate processing the loan application\\n        # ...\\n\\n        # Return processed loan data\\n        return {\\n            \"loan_type\": loan[\"loan_type\"],\\n            \"amount\": loan[\"amount\"],\\n            \"term\": loan[\"term\"],\\n            \"status\": \"approved\",\\n            \"details\": loan_details,\\n        }\\n    except Exception as e:\\n        ...   \n",
       "394                                                                                     import cv2\\nimport numpy as np\\nfrom multiprocessing import Pool\\nimport concurrent.futures\\nfrom functools import partial\\n\\n# Load the YOLO model\\nnet = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\\n\\n# Define the function to process a single frame\\ndef process_frame(frame):\\n    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0, 0, 0), True, crop=False)\\n    net.setInput(blob)\\n    outs = net.forward(net.getUnconnectedOutLayersNames())\\n    # Post-process the output and draw bounding boxes on the frame\\n    # ...\\n\\n# Capture video from webcam\\ncap = cv2.VideoCapture(0)\\n\\n# Create a pool of processes\\nwith Pool(processes=4) as pool:\\n    while True:\\n        ret, frame = cap.read()\\n        if not ret:\\n            break\\n\\n        # Submit the frame for processing to the pool\\n        pool.apply_async(process_frame, (frame,))\\n\\n# Release resources\\ncap.release()\\ncv2.destroyAllWindows()   \n",
       "402  import random\\nimport threading\\nimport numpy as np\\nimport tensorflow as tf\\n\\nclass Game:\\n    def __init__(self):\\n        self.players = []\\n        self.levels = []\\n\\n    def add_player(self, player):\\n        self.players.append(player)\\n\\n    def generate_level(self):\\n        levels = ['Easy', 'Medium', 'Hard']\\n        level = random.choice(levels)\\n        self.levels.append(level)\\n        return level\\n\\nclass Player(threading.Thread):\\n    def __init__(self, game):\\n        threading.Thread.__init__(self)\\n        self.game = game\\n\\n    def run(self):\\n        level = self.game.generate_level()\\n        print(f\"Player {self.name} is playing on level: {level}\")\\n\\n        # Simulate player's actions within the level\\n        # ...\\n\\n        # Update game state based on player's actions\\n        # ...\\n\\n# Create game object\\ngame = Game()\\n\\n# Add players to the game\\nfor i in range(10):\\n    player = Player(game)\\n    player.start()\\n    game.add_player(player)\\n\\n#...   \n",
       "431                                                                                                                                                                                                                                                                                             import pandas as pd\\n\\nclass Patient:\\n    def __init__(self, age, gender, medical_history, current_symptoms, lab_test_results):\\n        self.age = age\\n        self.gender = gender\\n        self.medical_history = medical_history\\n        self.current_symptoms = current_symptoms\\n        self.lab_test_results = lab_test_results\\n\\nclass DecisionSupportEngine:\\n    def __init__(self, patient):\\n        self.patient = patient\\n\\n    def analyze_patient_data(self):\\n        try:\\n            patient_df = pd.DataFrame([self.patient.__dict__])\\n            # Perform analysis on patient_df\\n            # ...\\n            return \"Treatment Recommendation\"\\n        except Exception as e:\\n            return str(e)   \n",
       "453  import pandas as pd\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Data Ingestion\\ndef fetch_data(sources):\\n    data = pd.DataFrame()\\n    for source in sources:\\n        if source.endswith('.csv'):\\n            data = data.append(pd.read_csv(source))\\n        else:\\n            data = data.append(pd.read_sql_query('SELECT * FROM customers', source))\\n    return data\\n\\n# Data Preprocessing\\ndef preprocess_data(data):\\n    # Clean and transform data\\n    # ...\\n\\n    # Normalize data\\n    scaler = StandardScaler()\\n    normalized_data = scaler.fit_transform(data)\\n    return normalized_data\\n\\n# Feature Engineering\\ndef generate_features(data):\\n    # Generate relevant features\\n    # ...\\n    return features\\n\\n# Segmentation\\ndef perform_segmentation(features, num_clusters):\\n    kmeans = KMeans(n_clusters=num_clusters)\\n    kmeans.fit(features)\\n    return kmeans.labels_\\n\\n# Metaprogramming\\ndef configure_pipeline(config):\\n    sourc...   \n",
       "461  import pandas as pd\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load student performance metrics, learning styles, and curriculum details from CSV files\\nstudent_data = pd.read_csv('student_data.csv')\\nlearning_styles = pd.read_csv('learning_styles.csv')\\ncurriculum = pd.read_csv('curriculum.csv')\\n\\n# Define a function to generate a personalized learning path for a student\\ndef generate_learning_path(student):\\n    # Perform some processing on the student data, learning styles, and curriculum details\\n    # ...\\n\\n    # Generate the learning path based on the processed data\\n    learning_path = []\\n    # ...\\n\\n    return learning_path\\n\\n# Define a function to generate learning paths for all students using concurrency\\ndef generate_all_learning_paths(students):\\n    learning_paths = []\\n\\n    with ThreadPoolExecutor() as executor:\\n        # Use the executor.map function to apply the generate_learning_path function to all students concurrently\\n        learning_paths ...   \n",
       "543  import concurrent.futures\\nimport requests\\nimport pandas as pd\\nfrom sklearn.ensemble import IsolationForest\\n\\n# Sample user credentials\\ncredentials = {\\n    \"user1\": \"pass1\",\\n    \"user2\": \"pass2\",\\n    # ...\\n}\\n\\n# Security policies\\nsecurity_policies = {\\n    \"failed_attempts_threshold\": 3,\\n    \"lockout_duration\": 10,  # minutes\\n    # ...\\n}\\n\\n# User session management\\nuser_sessions = {}\\n\\n# Brute force detection\\ndef detect_brute_force(user):\\n    # Fetch authentication attempts from a database or log file\\n    attempts = pd.read_csv(\"attempts.csv\")\\n    failed_attempts = attempts[attempts[\"user\"] == user][\"status\"] == \"failed\"\\n\\n    if len(failed_attempts) > security_policies[\"failed_attempts_threshold\"]:\\n        return True\\n    else:\\n        return False\\n\\n# Authenticate user\\ndef authenticate(user, password):\\n    if credentials[user] == password:\\n        # Check for brute force attacks\\n        if detect_brute_force(user):\\n            return False\\n        e...   \n",
       "564  import pandas as pd\\nimport numpy as np\\nimport concurrent.futures\\nimport requests\\n\\n# Sample data of banking transactions\\ntransactions = [\\n    {\"transaction_id\": 1, \"account_id\": 1001, \"amount\": 5000},\\n    {\"transaction_id\": 2, \"account_id\": 1002, \"amount\": 3000},\\n    {\"transaction_id\": 3, \"account_id\": 1003, \"amount\": 2000},\\n    # ... more transactions\\n]\\n\\ndef process_transaction(transaction):\\n    try:\\n        # Simulate network connectivity delay\\n        response = requests.get(\"https://api.bank.com/process_transaction\", params=transaction)\\n        if response.status_code == 200:\\n            return f\"Transaction {transaction['transaction_id']} processed successfully\"\\n        else:\\n            return f\"Error processing transaction {transaction['transaction_id']}\"\\n    except Exception as e:\\n        return f\"Error processing transaction {transaction['transaction_id']}: {str(e)}\"\\n\\ndef process_transactions_concurrently(transactions):\\n    results = []\\n    with co...   \n",
       "592                                                                                                                                                                                                                                                import pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\n# Load dataset\\ndf = pd.read_csv('patient_records.csv')\\n\\n# Define function for parallel processing\\ndef analyze_data(patient_data):\\n    # Analyze data and identify patterns or anomalies\\n    # ...\\n\\n    return results\\n\\n# Create a ThreadPoolExecutor\\nwith ThreadPoolExecutor() as executor:\\n    # Submit tasks to the executor\\n    futures = [executor.submit(analyze_data, data) for _, data in df.iterrows()]\\n\\n    # Get the results\\n    results = [future.result() for future in futures]\\n\\n# Create a heatmap using seaborn\\nsns.heatmap(pd.DataFrame(results).corr(), annot=True)\\n\\n# Save the plot\\nplt.savefig('patterns.png')   \n",
       "618  Sure, here's some sample code that demonstrates the use of concurrency, parallel processing, and metaprogramming techniques to optimize the performance of a medication management system. This code uses the `multiprocessing` module to create a parallel processing pipeline that can handle large-scale medication data from different data sources. It also uses the `pandas` library to manipulate and analyze the data, and the `numpy` library to perform numerical operations on the data.\\n```\\nimport multiprocessing as mp\\nimport pandas as pd\\nimport numpy as np\\n\\n# Define a function to process data from a single data source\\ndef process_data(data):\\n    # Perform some data processing operations here\\n    # ...\\n    return processed_data\\n\\n# Define a function to handle data from multiple data sources\\ndef handle_data(sources):\\n    # Create a pool of worker processes\\n    pool = mp.Pool(processes=mp.cpu_count())\\n\\n    # Process data from each source in parallel\\n    processed_data = pool...   \n",
       "720  import concurrent.futures\\nimport pandas as pd\\nimport numpy as np\\nimport scikit_learn as sklearn\\nimport re\\n\\n# Function to parse log files\\ndef parse_log_file(file_path):\\n    log_data = []\\n    with open(file_path, 'r') as file:\\n        for line in file:\\n            log_entry = re.split(r'\\s+', line)\\n            log_data.append(log_entry)\\n    return log_data\\n\\n# Function to perform pattern matching and anomaly detection\\ndef detect_anomalies(log_data):\\n    # Implement pattern matching and anomaly detection algorithms here\\n    # ...\\n\\n    return anomalies\\n\\n# Function to create alert for potential security incidents\\ndef create_alert(anomaly):\\n    # Implement alerting system here\\n    # ...\\n\\n    return alert\\n\\n# Function to process log files concurrently\\ndef process_log_files(file_paths):\\n    with concurrent.futures.ThreadPoolExecutor() as executor:\\n        futures = [executor.submit(parse_log_file, file_path) for file_path in file_paths]\\n        log_data = [fu...   \n",
       "732                                                                                                                                                      import pandas as pd\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.metrics.pairwise import linear_kernel\\nfrom multiprocessing import Pool\\n\\n# Load user behavior data\\nuser_data = pd.read_csv('user_behavior.csv')\\n\\n# Function to recommend products based on user behavior\\ndef recommend_products(user):\\n    tfidf = TfidfVectorizer(stop_words='english')\\n    tfidf_matrix = tfidf.fit_transform(user['product_description'])\\n    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\\n    # ... (rest of the recommendation logic)\\n    return recommended_products\\n\\n# Parallel processing to recommend products for all users\\nwith Pool() as p:\\n    recommendations = p.map(recommend_products, user_data['user_id'])\\n\\n# Save recommendations to a file\\npd.DataFrame(recommendations).to_csv('recommendations.csv', index=False)   \n",
       "763  import asyncio\\nimport pandas as pd\\nfrom scipy.stats import norm\\n\\n# Simulated VoIP call data\\ncalls = [\\n    {\"call_id\": 1, \"latency\": 50, \"jitter\": 10, \"packet_loss\": 0.5},\\n    {\"call_id\": 2, \"latency\": 45, \"jitter\": 8, \"packet_loss\": 0.3},\\n    # ... more call data ...\\n]\\n\\n# Define SLAs\\nslas = {\\n    \"latency\": {\"mean\": 50, \"std_dev\": 10},\\n    \"jitter\": {\"mean\": 8, \"std_dev\": 2},\\n    \"packet_loss\": {\"mean\": 0.1, \"std_dev\": 0.05},\\n}\\n\\nasync def process_call(call):\\n    # Calculate metrics\\n    latency_anomaly = abs(call[\"latency\"] - slas[\"latency\"][\"mean\"]) > slas[\"latency\"][\"std_dev\"]\\n    jitter_anomaly = abs(call[\"jitter\"] - slas[\"jitter\"][\"mean\"]) > slas[\"jitter\"][\"std_dev\"]\\n    packet_loss_anomaly = abs(call[\"packet_loss\"] - slas[\"packet_loss\"][\"mean\"]) > slas[\"packet_loss\"][\"std_dev\"]\\n\\n    # Generate alert if any anomaly detected\\n    if latency_anomaly or jitter_anomaly or packet_loss_anomaly:\\n        print(f\"Alert: Anomaly detected in call {call['call_id']}\"...   \n",
       "850                         import multiprocessing as mp\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\ndef process_data(data):\\n    # Preprocessing steps\\n    # ...\\n    return processed_data\\n\\ndef train_model(data):\\n    X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\\n    model.fit(X_train, y_train)\\n    return model\\n\\ndef main():\\n    # Load data\\n    data = pd.read_csv('financial_data.csv')\\n\\n    # Create a pool of processes\\n    with mp.Pool(processes=mp.cpu_count()) as pool:\\n        # Process data in parallel\\n        processed_data = pool.map(process_data, np.array_split(data, mp.cpu_count()))\\n\\n        # Train models in parallel\\n        models = pool.map(train_model, processed_data)\\n\\nif __name__ == '__main__':\\n    main()   \n",
       "876  import re\\nimport requests\\nfrom Crypto.Cipher import AES\\n\\nclass InvalidURLException(Exception):\\n    pass\\n\\nclass SecurityScanner:\\n    def __init__(self, target_url):\\n        self.target_url = target_url\\n\\n    def validate_url(self):\\n        pattern = re.compile(\\n            r'^(?:http|ftp)s?://'  # http:// or https://\\n            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\\n            r'localhost|'  # localhost...\\n            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  # ...or ip\\n            r'(?::\\d+)?'  # optional port\\n            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\\n        if not re.match(pattern, self.target_url):\\n            raise InvalidURLException(\"Invalid URL\")\\n\\n    def find_vulnerabilities(self):\\n        vulnerabilities = []\\n        # Code to scan for vulnerabilities goes here\\n        # For demonstration, let's assume we found some vulnerabilities\\n        vulnerabilities.append(\"SQL Injection\")\\n     ...   \n",
       "901                                                                                                   import numpy as np\\nimport pandas as pd\\nfrom multiprocessing import Pool\\n\\n# Simulated signal processing function\\ndef process_signal(signal):\\n    # Perform signal processing operations here\\n    # ...\\n    # Calculate signal strength, frequency, and duration\\n    signal_strength = np.random.uniform(0, 1)\\n    frequency = np.random.uniform(1e9, 2e9)\\n    duration = np.random.uniform(1, 10)\\n    return signal_strength, frequency, duration\\n\\n# Generate a large number of signals\\nsignals = [{'id': i} for i in range(10000)]\\n\\n# Create a pool of processes\\nwith Pool() as pool:\\n    # Process the signals in parallel\\n    results = pool.map(process_signal, signals)\\n\\n# Convert results to a pandas DataFrame\\ndf = pd.DataFrame(results, columns=['signal_strength', 'frequency', 'duration'])\\n\\n# Perform analytics on the processed signals\\n# ...\\n# Output detailed analytics\\nprint(df.describe())   \n",
       "928                                                                                import pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Load customer data\\ncustomer_data = pd.read_csv('customer_data.csv')\\n\\n# Preprocess data\\nscaler = StandardScaler()\\ncustomer_data_scaled = scaler.fit_transform(customer_data)\\n\\n# Define CLV calculation function\\ndef calculate_clv(customer):\\n    # Calculate CLV based on historical purchases, average order value, and purchase frequency\\n    # Include predicted future behavior and potential churn rate\\n    # Return CLV value\\n    pass\\n\\n# Parallel processing to calculate CLV for each customer\\nclv_values = Parallel(n_jobs=-1)(delayed(calculate_clv)(customer) for _, customer in customer_data_scaled.iterrows())\\n\\n# Store CLV values in a new column in the dataframe\\ncustomer_data['CLV'] = clv_values\\n\\n# Generate insights and trends report\\n# ...   \n",
       "931  import numpy as np\\nimport multiprocessing as mp\\n\\n# Define the control algorithm\\ndef control_algorithm(sensor_data, control_signals):\\n    # Perform some calculations on the sensor data and control signals\\n    # ...\\n\\n    # Dynamically adjust the control algorithm based on the vehicle's current state\\n    state = np.random.choice(['accelerating', 'cruising', 'braking'])\\n    if state == 'accelerating':\\n        # Adjust the control algorithm for accelerating state\\n        # ...\\n        pass\\n    elif state == 'cruising':\\n        # Adjust the control algorithm for cruising state\\n        # ...\\n        pass\\n    elif state == 'braking':\\n        # Adjust the control algorithm for braking state\\n        # ...\\n        pass\\n\\n    # Return the control signals\\n    return control_signals\\n\\n# Define the parallel processing function\\ndef process_data(sensor_data, control_signals):\\n    # Process the sensor data and control signals concurrently\\n    with mp.Pool() as pool:\\n     ...   \n",
       "949  import pandas as pd\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom concurrent.futures import ThreadPoolExecutor\\nimport matplotlib.pyplot as plt\\n\\n# Function to process student data and generate personalized learning paths\\ndef process_student_data(student_data):\\n    # Preprocess data, analyze strengths and weaknesses, and generate personalized learning paths\\n    # This is a placeholder function, replace with actual implementation\\n    personalized_paths = {}\\n    # ...\\n    return personalized_paths\\n\\n# Function to train and test a machine learning model for predicting student performance\\ndef train_and_test_model(student_data):\\n    # Split data into features and target\\n    X = student_data.drop('target', axis=1)\\n    y = student_data['target']\\n\\n    # Split data into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_sp...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              pyflakes_error  \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          <string>:37:1: expected an indented block\\nuser_sessions = pd.read_csv('user_sessions.csv')\\n^\\n  \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <string>:48:1: expected an indented block\\nsales_data = pd.read_csv('sales_data.csv')\\n^\\n  \n",
       "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <string>:4:1: 'numpy as np' imported but unused\\n  \n",
       "69                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:10:9: local variable 'data' is assigned to but never used\\n  \n",
       "103                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:4:1: 'scipy.optimize.minimize_scalar' imported but unused\\n<string>:14:5: local variable 'noisy_data' is assigned to but never used\\n<string>:17:12: undefined name 'result'\\n<string>:23:12: undefined name 'combined_result'\\n<string>:31:36: undefined name 'num_processes'\\n<string>:38:74: undefined name 'num_processes'\\n<string>:41:5: local variable 'combined_result' is assigned to but never used\\n  \n",
       "203                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <string>:26:17: local variable 'data' is assigned to but never used\\n<string>:30:23: f-string is missing placeholders\\n  \n",
       "219                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <string>:3:1: 'numpy as np' imported but unused\\n<string>:4:1: 'sklearn.preprocessing.StandardScaler' imported but unused\\n<string>:14:9: local variable 'frame' is assigned to but never used\\n<string>:25:20: undefined name 'load_model'\\n<string>:51:23: undefined name 'preprocess_frame'\\n  \n",
       "261                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "270                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:3:1: 'sklearn.preprocessing.StandardScaler' imported but unused\\n<string>:4:1: 'sklearn.ensemble.RandomForestClassifier' imported but unused\\n<string>:5:1: 'sklearn.metrics.classification_report' imported but unused\\n<string>:14:12: undefined name 'processed_patient'\\n<string>:26:12: undefined name 'model'\\n  \n",
       "333                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <string>:9:12: undefined name 'processed_image'\\n  \n",
       "349                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "373                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <string>:2:1: 'numpy as np' imported but unused\\n<string>:13:12: undefined name 'result'\\n<string>:22:23: undefined name 'concurrent'\\n<string>:23:13: local variable 'scenario' is assigned to but never used\\n  \n",
       "377                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <string>:10:9: local variable 'data' is assigned to but never used\\n  \n",
       "378                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "394                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <string>:2:1: 'numpy as np' imported but unused\\n<string>:4:1: 'concurrent.futures' imported but unused\\n<string>:5:1: 'functools.partial' imported but unused\\n<string>:14:5: local variable 'outs' is assigned to but never used\\n  \n",
       "402                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <string>:3:1: 'numpy as np' imported but unused\\n<string>:4:1: 'tensorflow as tf' imported but unused\\n  \n",
       "431                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              <string>:17:13: local variable 'patient_df' is assigned to but never used\\n  \n",
       "453                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              <string>:29:12: undefined name 'features'\\n  \n",
       "461                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "543                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <string>:2:1: 'requests' imported but unused\\n<string>:4:1: 'sklearn.ensemble.IsolationForest' imported but unused\\n  \n",
       "564                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:1:1: 'pandas as pd' imported but unused\\n<string>:2:1: 'numpy as np' imported but unused\\n  \n",
       "592                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "618  <string>:1:484: EOL while scanning string literal\\nSure, here's some sample code that demonstrates the use of concurrency, parallel processing, and metaprogramming techniques to optimize the performance of a medication management system. This code uses the `multiprocessing` module to create a parallel processing pipeline that can handle large-scale medication data from different data sources. It also uses the `pandas` library to manipulate and analyze the data, and the `numpy` library to perform numerical operations on the data.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...  \n",
       "720                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <string>:2:1: 'pandas as pd' imported but unused\\n<string>:3:1: 'numpy as np' imported but unused\\n<string>:4:1: 'scikit_learn as sklearn' imported but unused\\n<string>:21:12: undefined name 'anomalies'\\n<string>:28:12: undefined name 'alert'\\n  \n",
       "732                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <string>:13:5: local variable 'cosine_sim' is assigned to but never used\\n<string>:15:12: undefined name 'recommended_products'\\n  \n",
       "763                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <string>:2:1: 'pandas as pd' imported but unused\\n<string>:3:1: 'scipy.stats.norm' imported but unused\\n  \n",
       "850                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <string>:10:12: undefined name 'processed_data'\\n<string>:28:9: local variable 'models' is assigned to but never used\\n  \n",
       "876                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <string>:2:1: 'requests' imported but unused\\n  \n",
       "901                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "928                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <string>:3:1: 'sklearn.ensemble.RandomForestRegressor' imported but unused\\n  \n",
       "931                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "949                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <string>:1:1: 'pandas as pd' imported but unused\\n<string>:2:1: 'numpy as np' imported but unused\\n  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_codes['incomplete_code']= python_codes.code.apply(lambda x: '# ...' in x)\n",
    "print(python_codes.incomplete_code.value_counts())\n",
    "python_codes[python_codes.incomplete_code == True][['code', 'pyflakes_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_quality_score(row):\n",
    "    if row['is_valid_python_with_compile'] == False:\n",
    "        return 0\n",
    "    if row['pyflakes_error_category'] == 'undefined name':\n",
    "        return 1\n",
    "    if row['incomplete_code']:\n",
    "        return 1\n",
    "    if row['pyflakes_error_category'] == 'assigned to but never used':\n",
    "        return 2\n",
    "    if row['pyflakes_error_category'] == 'imported but unused':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "python_codes['code_quality_score'] = python_codes.apply(get_code_quality_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.groupby('complexity').code_quality_score.mean()  \n",
    "# No correlation between complexity and code quality score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_codes.code_quality_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navhelpers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
